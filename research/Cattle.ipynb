{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths\n",
    "input_good_dir = '/Users/suzetteschulenburg/Desktop/Nuutse/Good'\n",
    "input_bad_dir = '/Users/suzetteschulenburg/Desktop/Nuutse/Bad'\n",
    "output_base_dir = '/Users/suzetteschulenburg/Desktop/Main2'\n",
    "\n",
    "# Number of folds\n",
    "num_folds = 5\n",
    "\n",
    "# Function to create directories for folds\n",
    "def create_directories(base_dir, num_folds):\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        for category in ['Good', 'Bad']:\n",
    "            os.makedirs(os.path.join(base_dir, f'Fold{fold}', category), exist_ok=True)\n",
    "\n",
    "create_directories(output_base_dir, num_folds)\n",
    "\n",
    "# Function to group images by base ID\n",
    "def collect_images_by_base_id(directory):\n",
    "    base_id_dict = defaultdict(list)\n",
    "    for fname in os.listdir(directory):\n",
    "        if fname.lower().endswith('.jpg'):\n",
    "            # Extract base ID (e.g., E2025 from E2025_IMG_8469_aug1.jpg)\n",
    "            base_id = fname.split('_')[0]\n",
    "            img_path = os.path.join(directory, fname)\n",
    "            base_id_dict[base_id].append(img_path)\n",
    "    return base_id_dict\n",
    "\n",
    "# Collect images by base ID\n",
    "good_images_by_base_id = collect_images_by_base_id(input_good_dir)\n",
    "bad_images_by_base_id = collect_images_by_base_id(input_bad_dir)\n",
    "\n",
    "# Combine all base IDs and shuffle\n",
    "all_base_ids = list(good_images_by_base_id.keys()) + list(bad_images_by_base_id.keys())\n",
    "random.seed(42)\n",
    "random.shuffle(all_base_ids)\n",
    "\n",
    "# Split base IDs into folds\n",
    "folds = [[] for _ in range(num_folds)]\n",
    "for i, base_id in enumerate(all_base_ids):\n",
    "    folds[i % num_folds].append(base_id)\n",
    "\n",
    "# Distribute images into folds\n",
    "for fold_idx, fold_base_ids in enumerate(folds, 1):\n",
    "    fold_dir = os.path.join(output_base_dir, f'Fold{fold_idx}')\n",
    "\n",
    "    for base_id in fold_base_ids:\n",
    "        # Check if the base ID belongs to Good or Bad\n",
    "        if base_id in good_images_by_base_id:\n",
    "            category = 'Good'\n",
    "            images = good_images_by_base_id[base_id]\n",
    "        elif base_id in bad_images_by_base_id:\n",
    "            category = 'Bad'\n",
    "            images = bad_images_by_base_id[base_id]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Copy images to the respective fold directory\n",
    "        for img_path in images:\n",
    "            shutil.copy(img_path, os.path.join(fold_dir, category, os.path.basename(img_path)))\n",
    "\n",
    "print(\"Data successfully split into folds with no overlapping base IDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths to your folds and test set\n",
    "fold_base_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_base_dir = '/Users/suzetteschulenburg/Desktop/Main/Test'\n",
    "\n",
    "# Function to collect base IDs from a directory\n",
    "def collect_base_ids(directory, categories=['Good', 'Bad']):\n",
    "    base_ids = defaultdict(list)\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(directory, category)\n",
    "        if not os.path.exists(category_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(category_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                base_id = fname.split('_')[0]  # Extract base ID\n",
    "                base_ids[base_id].append(os.path.join(category_dir, fname))\n",
    "    return base_ids\n",
    "\n",
    "# Collect base IDs from folds\n",
    "fold_base_ids = {}\n",
    "for fold in range(1, 6):  # Assuming 5 folds\n",
    "    fold_dir = os.path.join(fold_base_dir, f'Fold{fold}')\n",
    "    fold_base_ids[f'Fold{fold}'] = set(collect_base_ids(fold_dir).keys())\n",
    "\n",
    "# Collect base IDs from test set\n",
    "test_base_ids = set(collect_base_ids(test_base_dir).keys())\n",
    "\n",
    "# Check for overlaps between folds\n",
    "overlap_found = False\n",
    "print(\"Checking for overlaps between folds:\")\n",
    "for fold1 in fold_base_ids:\n",
    "    for fold2 in fold_base_ids:\n",
    "        if fold1 != fold2:\n",
    "            overlap = fold_base_ids[fold1].intersection(fold_base_ids[fold2])\n",
    "            if overlap:\n",
    "                overlap_found = True\n",
    "                print(f\"Overlap found between {fold1} and {fold2}: {overlap}\")\n",
    "\n",
    "if not overlap_found:\n",
    "    print(\"No overlap detected between folds!\")\n",
    "\n",
    "# Check for overlaps between test set and folds\n",
    "test_overlap_found = False\n",
    "print(\"\\nChecking for overlaps between test set and folds:\")\n",
    "for fold, fold_ids in fold_base_ids.items():\n",
    "    overlap = fold_ids.intersection(test_base_ids)\n",
    "    if overlap:\n",
    "        test_overlap_found = True\n",
    "        print(f\"Overlap found between test set and {fold}: {overlap}\")\n",
    "\n",
    "if not test_overlap_found:\n",
    "    print(\"No overlap detected between test set and any folds!\")\n",
    "\n",
    "# Example: Print a few base IDs from each fold and the test set\n",
    "print(\"\\nExample Base IDs from Each Fold and Test Set:\")\n",
    "for fold, base_ids in fold_base_ids.items():\n",
    "    print(f\"{fold}: {list(base_ids)[:5]}\")  # Print first 5 base IDs for each fold\n",
    "print(f\"Test Set: {list(test_base_ids)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count base ids per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "\n",
    "# Function to count unique base IDs in each class per fold\n",
    "def count_unique_base_ids_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):  # Iterate over folds 1 to 5\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_base_id_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:  # Check for 'Good' and 'Bad' classes\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                base_ids = set()\n",
    "                for filename in os.listdir(class_dir):\n",
    "                    if filename.lower().endswith('.jpg'):\n",
    "                        # Extract base ID (e.g., E2025 from E2025_IMG_8469_sharp.jpg)\n",
    "                        base_id = filename.split('_')[0]\n",
    "                        base_ids.add(base_id)\n",
    "                class_base_id_counts[class_name] = len(base_ids)\n",
    "            else:\n",
    "                class_base_id_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_base_id_counts\n",
    "    return folds_data\n",
    "\n",
    "# Get unique base ID counts per fold\n",
    "folds_data = count_unique_base_ids_per_fold(base_directory)\n",
    "\n",
    "# Print the results\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count total number of images per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# Function to count images in each class per fold\n",
    "def count_images_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):  # Iterate over folds 1 to 5\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:  # Check for 'Good' and 'Bad' classes\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                num_images = len([f for f in os.listdir(class_dir) if f.lower().endswith('.jpg')])\n",
    "                class_counts[class_name] = num_images\n",
    "            else:\n",
    "                class_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_counts\n",
    "    return folds_data\n",
    "\n",
    "# Get image counts per fold\n",
    "folds_data = count_images_per_fold(base_directory)\n",
    "\n",
    "# Print the results\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versprei beter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "source_folds_dir = '/Users/suzetteschulenburg/Desktop/Main2'  # Existing processed folds\n",
    "new_folds_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'  # New balanced folds directory\n",
    "categories = ['Good', 'Bad']  # Categories to process\n",
    "num_folds = 5  # Number of folds\n",
    "\n",
    "# Create new fold directories\n",
    "def create_new_folds(base_dir, num_folds, categories):\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        for category in categories:\n",
    "            os.makedirs(os.path.join(base_dir, f'Fold{fold}', category), exist_ok=True)\n",
    "\n",
    "# Collect all images grouped by base ID\n",
    "def collect_images_by_base_id(base_dir, num_folds, categories):\n",
    "    base_id_dict = defaultdict(list)\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        for category in categories:\n",
    "            category_dir = os.path.join(base_dir, f'Fold{fold}', category)\n",
    "            if not os.path.exists(category_dir):\n",
    "                print(f\"Directory not found: {category_dir}\")\n",
    "                continue\n",
    "            print(f\"Processing {category} in Fold{fold}\")  # Debugging log\n",
    "            for filename in os.listdir(category_dir):\n",
    "                if filename.lower().endswith('.jpg'):  # Ensure only .jpg files are processed\n",
    "                    base_id = filename.split('_')[0]  # Extract base ID\n",
    "                    img_path = os.path.join(category_dir, filename)\n",
    "                    base_id_dict[base_id].append(img_path)\n",
    "    return base_id_dict\n",
    "\n",
    "# Distribute base IDs across folds, prioritizing balance\n",
    "def distribute_base_ids_with_image_count(base_id_dict, num_folds):\n",
    "    base_ids = list(base_id_dict.keys())\n",
    "    random.shuffle(base_ids)\n",
    "    base_ids.sort(key=lambda x: len(base_id_dict[x]), reverse=True)\n",
    "\n",
    "    fold_image_counts = [0] * num_folds\n",
    "    base_id_folds = [[] for _ in range(num_folds)]\n",
    "\n",
    "    for base_id in base_ids:\n",
    "        least_images_fold = fold_image_counts.index(min(fold_image_counts))\n",
    "        base_id_folds[least_images_fold].append(base_id)\n",
    "        fold_image_counts[least_images_fold] += len(base_id_dict[base_id])\n",
    "\n",
    "    return base_id_folds\n",
    "\n",
    "# Move images to new folds\n",
    "def move_images_to_new_folds(base_id_dict, base_id_folds, new_folds_dir):\n",
    "    for fold_idx, base_ids in enumerate(base_id_folds, 1):\n",
    "        fold_dir = os.path.join(new_folds_dir, f'Fold{fold_idx}')\n",
    "        for base_id in base_ids:\n",
    "            for img_path in base_id_dict[base_id]:\n",
    "                category = 'Good' if 'Good' in img_path else 'Bad'\n",
    "                target_dir = os.path.join(fold_dir, category)\n",
    "                shutil.copy(img_path, os.path.join(target_dir, os.path.basename(img_path)))\n",
    "                print(f\"Copied {img_path} to {target_dir}\")  # Debugging log\n",
    "\n",
    "# Main logic\n",
    "def redistribute_data_with_balancing(source_folds_dir, new_folds_dir, num_folds, categories):\n",
    "    # Create new fold directories\n",
    "    create_new_folds(new_folds_dir, num_folds, categories)\n",
    "\n",
    "    # Collect images by base ID\n",
    "    base_id_dict = collect_images_by_base_id(source_folds_dir, num_folds, categories)\n",
    "\n",
    "    # Get all unique base IDs\n",
    "    all_base_ids = list(base_id_dict.keys())\n",
    "\n",
    "    # Distribute base IDs across folds\n",
    "    base_id_folds = distribute_base_ids_with_image_count(base_id_dict, num_folds)\n",
    "\n",
    "    # Move images to new folds\n",
    "    move_images_to_new_folds(base_id_dict, base_id_folds, new_folds_dir)\n",
    "\n",
    "    print(f\"Redistribution complete. New folds created at: {new_folds_dir}\")\n",
    "\n",
    "# Run the redistribution process\n",
    "redistribute_data_with_balancing(source_folds_dir, new_folds_dir, num_folds, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# Function to count unique base IDs in each class per fold\n",
    "def count_unique_base_ids_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):  # Iterate over folds 1 to 5\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_base_id_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:  # Check for 'Good' and 'Bad' classes\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                base_ids = set()\n",
    "                for filename in os.listdir(class_dir):\n",
    "                    if filename.lower().endswith('.jpg'):\n",
    "                        # Extract base ID (e.g., E2025 from E2025_IMG_8469_sharp.jpg)\n",
    "                        base_id = filename.split('_')[0]\n",
    "                        base_ids.add(base_id)\n",
    "                class_base_id_counts[class_name] = len(base_ids)\n",
    "            else:\n",
    "                class_base_id_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_base_id_counts\n",
    "    return folds_data\n",
    "\n",
    "# Get unique base ID counts per fold\n",
    "folds_data = count_unique_base_ids_per_fold(base_directory)\n",
    "\n",
    "# Print the results\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# Pattern: match only *_IMG_<digits>_processed.jpg (nothing else in between)\n",
    "pattern = re.compile(r'^.*IMG_\\d+_processed\\.jpg$', re.IGNORECASE)\n",
    "\n",
    "def is_original_img(filename):\n",
    "    \"\"\"\n",
    "    Return True if the filename matches IMG_<number>_processed.jpg exactly\n",
    "    \"\"\"\n",
    "    return bool(pattern.fullmatch(filename.strip()))\n",
    "\n",
    "def count_original_images_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                all_files = os.listdir(class_dir)\n",
    "                originals = [f for f in all_files if is_original_img(f)]\n",
    "                class_counts[class_name] = len(originals)\n",
    "            else:\n",
    "                class_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_counts\n",
    "    return folds_data\n",
    "\n",
    "# Run and print\n",
    "folds_data = count_original_images_per_fold(base_directory)\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# === Base directory ===\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# === Pattern for original image filenames (strict match) ===\n",
    "original_pattern = re.compile(r'^.*IMG_\\d+_processed\\.jpg$', re.IGNORECASE)\n",
    "\n",
    "def is_original_img(filename):\n",
    "    return bool(original_pattern.fullmatch(filename.strip()))\n",
    "\n",
    "def count_images_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_stats = {}\n",
    "\n",
    "        for class_name in ['Good', 'Bad']:\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "\n",
    "            if os.path.exists(class_dir):\n",
    "                all_files = [f for f in os.listdir(class_dir) if f.lower().endswith('.jpg')]\n",
    "                originals = [f for f in all_files if is_original_img(f)]\n",
    "\n",
    "                total = len(all_files)\n",
    "                original_count = len(originals)\n",
    "                augmentations = total - original_count\n",
    "                avg_aug_per_img = round(augmentations / original_count, 2) if original_count > 0 else 0\n",
    "\n",
    "                class_stats[class_name] = {\n",
    "                    'Originals': original_count,\n",
    "                    'Total': total,\n",
    "                    'Augmented': augmentations,\n",
    "                    'AvgAugPerOriginal': avg_aug_per_img\n",
    "                }\n",
    "            else:\n",
    "                class_stats[class_name] = {\n",
    "                    'Originals': 0,\n",
    "                    'Total': 0,\n",
    "                    'Augmented': 0,\n",
    "                    'AvgAugPerOriginal': 0.0\n",
    "                }\n",
    "\n",
    "        folds_data[f'Fold{fold}'] = class_stats\n",
    "\n",
    "    return folds_data\n",
    "\n",
    "# === Run and print nicely ===\n",
    "folds_data = count_images_per_fold(base_directory)\n",
    "\n",
    "for fold, stats in folds_data.items():\n",
    "    print(f\"\\n{fold}:\")\n",
    "    for cls, data in stats.items():\n",
    "        print(f\"  {cls}: Originals = {data['Originals']}, Total = {data['Total']}, \"\n",
    "              f\"Augmented = {data['Augmented']}, Avg Augmentations = {data['AvgAugPerOriginal']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "\n",
    "# Function to count images in each class per fold\n",
    "def count_images_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):  # Iterate over folds 1 to 5\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:  # Check for 'Good' and 'Bad' classes\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                num_images = len([f for f in os.listdir(class_dir) if f.lower().endswith('.jpg')])\n",
    "                class_counts[class_name] = num_images\n",
    "            else:\n",
    "                class_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_counts\n",
    "    return folds_data\n",
    "\n",
    "# Get image counts per fold\n",
    "folds_data = count_images_per_fold(base_directory)\n",
    "\n",
    "# Print the results\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# Pattern: match only *_IMG_<digits>_processed.jpg (nothing else in between)\n",
    "pattern = re.compile(r'^.*IMG_\\d+_processed\\.jpg$', re.IGNORECASE)\n",
    "\n",
    "def is_original_img(filename):\n",
    "    \"\"\"\n",
    "    Return True if the filename matches IMG_<number>_processed.jpg exactly\n",
    "    \"\"\"\n",
    "    return bool(pattern.fullmatch(filename.strip()))\n",
    "\n",
    "def count_original_images_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                all_files = os.listdir(class_dir)\n",
    "                originals = [f for f in all_files if is_original_img(f)]\n",
    "                class_counts[class_name] = len(originals)\n",
    "            else:\n",
    "                class_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_counts\n",
    "    return folds_data\n",
    "\n",
    "# Run and print\n",
    "folds_data = count_original_images_per_fold(base_directory)\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Martiens cows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make excel sheet better align with photo number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/Martiens.xlsx\"\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Create an empty list to store the processed data\n",
    "expanded_data = []\n",
    "\n",
    "# Determine the first photo number dynamically\n",
    "previous_end_photo_number = None\n",
    "\n",
    "# Loop through the DataFrame rows\n",
    "for i, row in df.iterrows():\n",
    "    base_id = row[\"Id\"]\n",
    "    last_photo_number = row[\"Photo number\"]  # The number in Excel is the last image\n",
    "    rating = row[\"Rating\"]\n",
    "    \n",
    "    # Determine the first photo number for this base ID\n",
    "    if previous_end_photo_number is None:\n",
    "        first_photo_number = last_photo_number - 2  # Start of the first ID (assuming 3 images)\n",
    "    else:\n",
    "        first_photo_number = previous_end_photo_number + 1  # Next image after previous base_id\n",
    "    \n",
    "    # Ensure the last image remains consistent\n",
    "    for j, photo_number in enumerate(range(first_photo_number, last_photo_number + 1)):\n",
    "        new_id = f\"{base_id}_{j+1}\"\n",
    "        expanded_data.append([new_id, photo_number, rating])\n",
    "\n",
    "    # Update previous end photo number\n",
    "    previous_end_photo_number = last_photo_number\n",
    "\n",
    "# Convert to a DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_data, columns=[\"ID\", \"Photo Number\", \"Rating\"])\n",
    "\n",
    "# Save to a new Excel file\n",
    "output_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/ProcessedExcel.xlsx\"\n",
    "expanded_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Processed Excel saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add gender to new excvel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the Excel files\n",
    "original_excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/Martiens.xlsx\"\n",
    "processed_excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/ProcessedExcel.xlsx\"\n",
    "output_excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/ProcessedExcel_WithGender.xlsx\"\n",
    "\n",
    "# Load the original and processed Excel files\n",
    "original_df = pd.read_excel(original_excel_path)\n",
    "processed_df = pd.read_excel(processed_excel_path)\n",
    "\n",
    "# Ensure column names are formatted correctly\n",
    "original_df = original_df.rename(columns={\"Photo number\": \"Photo Number\", \"Id\": \"Base_ID\"})\n",
    "processed_df = processed_df.rename(columns={\"ID\": \"Full_ID\"})\n",
    "\n",
    "# Extract base ID from Full_ID (before the underscore)\n",
    "processed_df[\"Base_ID\"] = processed_df[\"Full_ID\"].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "# Merge processed_df with original_df to add Gender using Base_ID\n",
    "merged_df = processed_df.merge(original_df[['Base_ID', 'Gender']], on=\"Base_ID\", how=\"left\")\n",
    "\n",
    "# Rename the columns back\n",
    "merged_df = merged_df.rename(columns={\"Base_ID\": \"ID\"})\n",
    "\n",
    "# Save the updated processed Excel file\n",
    "merged_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Updated processed file saved to: {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/ProcessedExcel_WithGender.xlsx\"\n",
    "image_dir = \"/Users/suzetteschulenburg/Desktop/Masters/Beeste/Backup/MARTIENS 2/MARTIENS VEILING\"\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Ensure column names are correctly formatted\n",
    "df = df.rename(columns={\"ID\": \"Base_ID\", \"Photo Number\": \"Photo_Number\"})\n",
    "\n",
    "# Function to rename images in the main folder while keeping \"IMG_\" in the name\n",
    "def rename_images(image_dir, df):\n",
    "    for _, row in df.iterrows():\n",
    "        base_id = row[\"Base_ID\"]  # The new base ID with numbering\n",
    "        photo_number = row[\"Photo_Number\"]  # The corresponding photo number\n",
    "        \n",
    "        # Construct the original and new filenames with the correct \"IMG_\" format\n",
    "        original_filename = f\"IMG_{str(photo_number).zfill(4)}.jpg\"  # Ensures leading zeros (e.g., IMG_0590)\n",
    "        new_filename = f\"{base_id}_IMG_{str(photo_number).zfill(4)}.jpg\"\n",
    "\n",
    "        # Define full paths\n",
    "        original_path = os.path.join(image_dir, original_filename)\n",
    "        new_path = os.path.join(image_dir, new_filename)\n",
    "\n",
    "        # Rename if the file exists\n",
    "        if os.path.exists(original_path):\n",
    "            os.rename(original_path, new_path)\n",
    "            print(f\"Renamed: {original_path} → {new_path}\")\n",
    "        else:\n",
    "            print(f\"Skipped (file not found): {original_path}\")\n",
    "\n",
    "# Execute renaming\n",
    "rename_images(image_dir, df)\n",
    "\n",
    "print(\"Image renaming completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split cows into good and bad folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/ProcessedExcel_WithGender.xlsx\"\n",
    "image_dir = \"/Users/suzetteschulenburg/Desktop/Masters/Beeste/Backup/MARTIENS 2/MARTIENS VEILING\"\n",
    "\n",
    "# New directories for classification\n",
    "good_dir = \"/Users/suzetteschulenburg/Desktop/Masters/Beeste/Backup/MARTIENS/Good\"\n",
    "bad_dir = \"/Users/suzetteschulenburg/Desktop/Masters/Beeste/Backup/MARTIENS/Bad\"\n",
    "\n",
    "# Create new directories if they don't exist\n",
    "os.makedirs(good_dir, exist_ok=True)\n",
    "os.makedirs(bad_dir, exist_ok=True)\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Ensure column names are correctly formatted\n",
    "df = df.rename(columns={\"ID\": \"Base_ID\", \"Photo Number\": \"Photo_Number\", \"Gender\": \"Gender\", \"Rating\": \"Rating\"})\n",
    "\n",
    "# Function to move images based on rating and gender\n",
    "def move_images(image_dir, df, good_dir, bad_dir):\n",
    "    for _, row in df.iterrows():\n",
    "        base_id = row[\"Base_ID\"]  # The renamed base ID\n",
    "        photo_number = row[\"Photo_Number\"]  # The corresponding photo number\n",
    "        gender = row[\"Gender\"]  # Gender of the cattle\n",
    "        rating = row[\"Rating\"]  # Rating score\n",
    "\n",
    "        # Only process female (\"F\") images\n",
    "        if gender == \"F\":\n",
    "            # Construct image filename\n",
    "            image_filename = f\"{base_id}_IMG_{str(photo_number).zfill(4)}.jpg\"\n",
    "            original_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "            # Determine destination folder\n",
    "            if rating in [2, 3, 4]:\n",
    "                target_path = os.path.join(bad_dir, image_filename)\n",
    "            elif rating in [8, 9]:\n",
    "                target_path = os.path.join(good_dir, image_filename)\n",
    "            else:\n",
    "                continue  # Skip ratings that are not in the specified range\n",
    "\n",
    "            # Move the file if it exists\n",
    "            if os.path.exists(original_path):\n",
    "                shutil.move(original_path, target_path)\n",
    "                print(f\"Moved: {original_path} → {target_path}\")\n",
    "            else:\n",
    "                print(f\"Skipped (file not found): {original_path}\")\n",
    "\n",
    "# Execute image moving\n",
    "move_images(image_dir, df, good_dir, bad_dir)\n",
    "\n",
    "print(\"Image classification into 'Good' and 'Bad' completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add augmentation to Martiens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
    "\n",
    "# Define source directories\n",
    "good_dir = '/Users/suzetteschulenburg/Desktop/Add martiens by main/Good'\n",
    "bad_dir = '/Users/suzetteschulenburg/Desktop/Add martiens by main/Bad'\n",
    "\n",
    "# Function to add Gaussian noise\n",
    "def add_gaussian_noise(img, mean=0, std=25):\n",
    "    np_img = np.array(img)\n",
    "    noise = np.random.normal(mean, std, np_img.shape).astype(np.uint8)\n",
    "    noisy_img = np_img + noise\n",
    "    noisy_img = np.clip(noisy_img, 0, 255)\n",
    "    return Image.fromarray(noisy_img)\n",
    "\n",
    "# Function to adjust gamma\n",
    "def adjust_gamma(img, gamma=1.5):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = [((i / 255.0) ** inv_gamma) * 255 for i in range(256)]\n",
    "    if img.mode == 'RGB':\n",
    "        return img.point(table * 3)  # RGB images have 3 channels\n",
    "    elif img.mode == 'L':\n",
    "        return img.point(table)  # Grayscale images have 1 channel\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported image mode: {img.mode}')\n",
    "\n",
    "# Function to adjust hue\n",
    "def adjust_hue(img, hue_factor=0.5):\n",
    "    img = np.array(img.convert('HSV'))\n",
    "    img[..., 0] = (img[..., 0].astype(int) + int(hue_factor * 255)) % 255\n",
    "    return Image.fromarray(img, 'HSV').convert('RGB')\n",
    "\n",
    "# Function to count images in a directory\n",
    "def count_images(directory):\n",
    "    return len([f for f in os.listdir(directory) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "# Function to augment each image to have 11 total variations\n",
    "def augment_images(source_dir):\n",
    "    for img_name in os.listdir(source_dir):\n",
    "        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(source_dir, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            base_name = os.path.splitext(img_name)[0]\n",
    "\n",
    "            # Check if there are already 11 images for this base ID\n",
    "            existing_images = [f for f in os.listdir(source_dir) if f.startswith(base_name)]\n",
    "            if len(existing_images) >= 11:\n",
    "                print(f\"Skipping {img_name}, already has {len(existing_images)} images.\")\n",
    "                continue  # Skip if already has 11 variations\n",
    "\n",
    "            augmentations_needed = 11 - len(existing_images)\n",
    "\n",
    "            for i in range(augmentations_needed):\n",
    "                img_aug = img.copy()\n",
    "\n",
    "                # Apply a random augmentation\n",
    "                augmentation_choice = np.random.choice([\n",
    "                    'flip', 'gray', 'noisy', 'sharp', 'contrast', 'blur', 'gamma', 'hue', 'saturation'\n",
    "                ])\n",
    "                if augmentation_choice == 'flip':\n",
    "                    img_aug = ImageOps.mirror(img_aug)\n",
    "                elif augmentation_choice == 'gray':\n",
    "                    img_aug = ImageOps.grayscale(img_aug)\n",
    "                elif augmentation_choice == 'noisy':\n",
    "                    img_aug = add_gaussian_noise(img_aug)\n",
    "                elif augmentation_choice == 'sharp':\n",
    "                    img_aug = ImageEnhance.Sharpness(img_aug).enhance(2.0)\n",
    "                elif augmentation_choice == 'contrast':\n",
    "                    img_aug = ImageEnhance.Contrast(img_aug).enhance(1.5)\n",
    "                elif augmentation_choice == 'blur':\n",
    "                    img_aug = img_aug.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "                elif augmentation_choice == 'gamma':\n",
    "                    img_aug = adjust_gamma(img_aug)\n",
    "                elif augmentation_choice == 'hue':\n",
    "                    img_aug = adjust_hue(img_aug)\n",
    "                elif augmentation_choice == 'saturation':\n",
    "                    img_aug = ImageEnhance.Color(img_aug).enhance(1.5)\n",
    "\n",
    "                # Save the augmented image\n",
    "                img_aug.save(os.path.join(source_dir, f\"{base_name}_aug{i}.jpg\"))\n",
    "\n",
    "    print(f\"Augmentation complete for {source_dir}\")\n",
    "\n",
    "# Perform augmentation on \"Good\" and \"Bad\" folders\n",
    "augment_images(good_dir)\n",
    "augment_images(bad_dir)\n",
    "\n",
    "print(\"Augmentation complete for all images in 'Good' and 'Bad' folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count base_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directories\n",
    "good_dir = \"/Users/suzetteschulenburg/Desktop/Masters/Beeste/Backup/MARTIENS/Good\"\n",
    "bad_dir = \"/Users/suzetteschulenburg/Desktop/Masters/Beeste/Backup/MARTIENS/Bad\"\n",
    "\n",
    "# Function to extract base IDs\n",
    "def count_unique_base_ids(directory):\n",
    "    base_id_set = set()\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(\".jpg\"):  # Ensure we only check image files\n",
    "            base_id = filename.split('_')[0]  # Extract base ID before first underscore\n",
    "            base_id_set.add(base_id)  # Add to set (ensures uniqueness)\n",
    "\n",
    "    return len(base_id_set), base_id_set  # Return count and base IDs\n",
    "\n",
    "# Count unique base IDs in Good and Bad folders\n",
    "good_count, good_base_ids = count_unique_base_ids(good_dir)\n",
    "bad_count, bad_base_ids = count_unique_base_ids(bad_dir)\n",
    "\n",
    "# Print results\n",
    "print(f\"Unique base IDs in Good folder: {good_count}\")\n",
    "print(f\"Unique base IDs in Bad folder: {bad_count}\")\n",
    "\n",
    "\n",
    "print(\"Base ID report saved as 'base_ids_report.txt'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best learning rate VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesGetBestLR'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesGetBestLR'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the VGG16-based model with improvements\n",
    "def create_vgg16_model(image_shape, learning_rate=1e-5):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)  # Added L2 Regularization\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)  # Increased dropout\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# List of learning rates to test\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "\n",
    "# Cross-validation loop\n",
    "validation_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTesting Learning Rate: {lr}\")\n",
    "\n",
    "    for val_fold_index in range(5):\n",
    "        print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set with LR = {lr}\")\n",
    "        \n",
    "        # Define training and validation sets\n",
    "        train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "        val_fold = fold_dirs[val_fold_index]\n",
    "        \n",
    "        # Load training data from the selected folds\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in train_folds:\n",
    "            images, labels = load_images_and_labels(train_fold)\n",
    "            X_train.append(images)\n",
    "            y_train.append(labels)\n",
    "        X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "        \n",
    "        # Load validation and test data\n",
    "        X_val, y_val = load_images_and_labels(val_fold)\n",
    "        X_test, y_test = load_images_and_labels(test_image_dir)\n",
    "        \n",
    "        # Train the model\n",
    "        model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, verbose=1, restore_best_weights=True),  # Increased patience\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, verbose=1, min_lr=1e-7),\n",
    "            ModelCheckpoint(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=70,  # Changed to 70 epochs\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Save training history\n",
    "        history_path = os.path.join(history_save_dir, f'history_fold{val_fold_index + 1}_lr{lr}.pkl')\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "        validation_metrics.append({'lr': lr, 'fold': val_fold_index + 1, 'accuracy': val_accuracy * 100, 'loss': val_loss})\n",
    "        print(f\"Validation Accuracy for Fold {val_fold_index + 1}: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        test_metrics.append({'lr': lr, 'fold': val_fold_index + 1, 'accuracy': test_accuracy * 100, 'loss': test_loss})\n",
    "        print(f\"Test Accuracy for Fold {val_fold_index + 1}: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        # Save the model\n",
    "        model.save(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}_lr{lr}.keras'))\n",
    "\n",
    "# Metrics summary\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric in validation_metrics:\n",
    "    print(f\"LR {metric['lr']} - Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for metric in test_metrics:\n",
    "    print(f\"LR {metric['lr']} - Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "# Compute averages and standard deviations\n",
    "val_accuracies = [m['accuracy'] for m in validation_metrics]\n",
    "test_accuracies = [m['accuracy'] for m in test_metrics]\n",
    "print(f\"\\nAverage Validation Accuracy: {np.mean(val_accuracies):.2f}%, Std Dev: {np.std(val_accuracies):.2f}\")\n",
    "print(f\"Average Test Accuracy: {np.mean(test_accuracies):.2f}%, Std Dev: {np.std(test_accuracies):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze LR graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesGetBestLR'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesGetBestLR'\n",
    "metrics_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Metrics'\n",
    "os.makedirs(metrics_save_dir, exist_ok=True)\n",
    "\n",
    "metrics_file = os.path.join(metrics_save_dir, 'metrics.pkl')\n",
    "\n",
    "# Learning rates tested\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5]\n",
    "num_folds = 5  # Number of folds used in cross-validation\n",
    "\n",
    "# Check if saved metrics exist\n",
    "if os.path.exists(metrics_file):\n",
    "    print(\"Loading saved metrics...\")\n",
    "    with open(metrics_file, 'rb') as f:\n",
    "        vgg16_results = pickle.load(f)\n",
    "else:\n",
    "    print(\"Processing metrics from scratch...\")\n",
    "    # Initialize dictionary\n",
    "    metrics = ['f1_score', 'precision', 'recall', 'auc', 'val_loss']\n",
    "    vgg16_results = {metric: {lr: [] for lr in learning_rates} for metric in metrics}\n",
    "\n",
    "    # Loop through learning rates and folds\n",
    "    for lr in learning_rates:\n",
    "        for fold in range(1, num_folds + 1):\n",
    "            model_path = os.path.join(model_save_dir, f'model_fold{fold}_lr{lr}.keras')\n",
    "            history_path = os.path.join(history_save_dir, f'history_fold{fold}_lr{lr}.pkl')\n",
    "            val_fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "\n",
    "            # Skip missing models\n",
    "            if not os.path.exists(model_path):\n",
    "                print(f\"Skipping: Model not found for LR={lr}, Fold={fold}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Loading model for LR={lr}, Fold={fold}...\")\n",
    "            model = load_model(model_path)\n",
    "\n",
    "            # Load validation data\n",
    "            X_val, y_val = [], []\n",
    "            if os.path.exists(val_fold_dir):\n",
    "                for subdir in ['Good', 'Bad']:\n",
    "                    full_image_dir = os.path.join(val_fold_dir, subdir)\n",
    "                    if not os.path.exists(full_image_dir):\n",
    "                        continue\n",
    "                    for fname in os.listdir(full_image_dir):\n",
    "                        if fname.endswith('.jpg'):\n",
    "                            image_path = os.path.join(full_image_dir, fname)\n",
    "                            image_array = load_img(image_path, target_size=(224, 224))\n",
    "                            X_val.append(img_to_array(image_array) / 255.0)\n",
    "                            y_val.append(1 if subdir == 'Good' else 0)\n",
    "                X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "            if len(X_val) == 0:\n",
    "                print(f\"Skipping: No validation images found for LR={lr}, Fold={fold}\")\n",
    "                continue\n",
    "\n",
    "            # Predict\n",
    "            val_probs = model.predict(X_val)\n",
    "            val_preds = (val_probs > 0.5).astype(int)\n",
    "\n",
    "            # Compute metrics\n",
    "            val_f1 = f1_score(y_val, val_preds)\n",
    "            val_precision = precision_score(y_val, val_preds)\n",
    "            val_recall = recall_score(y_val, val_preds)\n",
    "            val_auc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "            vgg16_results['f1_score'][lr].append(val_f1)\n",
    "            vgg16_results['precision'][lr].append(val_precision)\n",
    "            vgg16_results['recall'][lr].append(val_recall)\n",
    "            vgg16_results['auc'][lr].append(val_auc)\n",
    "\n",
    "            print(f\"Fold {fold} - Avg F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, AUC: {val_auc:.4f}\")\n",
    "\n",
    "            # Load val_loss\n",
    "            if os.path.exists(history_path):\n",
    "                with open(history_path, 'rb') as f:\n",
    "                    history = pickle.load(f)\n",
    "                if 'val_loss' in history:\n",
    "                    avg_val_loss = np.mean(history['val_loss'])\n",
    "                    vgg16_results['val_loss'][lr].append(avg_val_loss)\n",
    "            else:\n",
    "                print(f\"Skipping: History file not found for LR={lr}, Fold={fold}\")\n",
    "\n",
    "    # Save metrics\n",
    "    print(\"Saving extracted metrics...\")\n",
    "    with open(metrics_file, 'wb') as f:\n",
    "        pickle.dump(vgg16_results, f)\n",
    "\n",
    "# Average metrics per LR\n",
    "avg_vgg16_metrics = {\n",
    "    metric: {\n",
    "        lr: np.mean(vgg16_results[metric][lr]) if len(vgg16_results[metric][lr]) > 0 else np.nan\n",
    "        for lr in learning_rates\n",
    "    }\n",
    "    for metric in vgg16_results\n",
    "}\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Performance Metrics')\n",
    "\n",
    "# Learning rates (x) and Y values\n",
    "f1_vals = [avg_vgg16_metrics['f1_score'][lr] for lr in learning_rates]\n",
    "prec_vals = [avg_vgg16_metrics['precision'][lr] for lr in learning_rates]\n",
    "rec_vals = [avg_vgg16_metrics['recall'][lr] for lr in learning_rates]\n",
    "auc_vals = [avg_vgg16_metrics['auc'][lr] for lr in learning_rates]\n",
    "val_loss_vals = [avg_vgg16_metrics['val_loss'][lr] for lr in learning_rates]\n",
    "\n",
    "# Plot performance metrics\n",
    "f1_line, = ax1.plot(learning_rates, f1_vals, marker='o', linestyle='-', color='g', label='F1 Score')\n",
    "prec_line, = ax1.plot(learning_rates, prec_vals, marker='s', linestyle='-', color='r', label='Precision')\n",
    "rec_line, = ax1.plot(learning_rates, rec_vals, marker='D', linestyle='-', color='orange', label='Recall')\n",
    "auc_line, = ax1.plot(learning_rates, auc_vals, marker='^', linestyle='-', color='purple', label='AUC')\n",
    "\n",
    "# Add percentage text annotations on primary axis\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    if not np.isnan(f1_vals[i]):\n",
    "        ax1.text(lr, f1_vals[i], f\"{f1_vals[i]*100:.1f}%\", fontsize=9, color='g', ha='center', va='bottom')\n",
    "    if not np.isnan(prec_vals[i]):\n",
    "        ax1.text(lr, prec_vals[i], f\"{prec_vals[i]*100:.1f}%\", fontsize=9, color='r', ha='center', va='bottom')\n",
    "    if not np.isnan(rec_vals[i]):\n",
    "        ax1.text(lr, rec_vals[i], f\"{rec_vals[i]*100:.1f}%\", fontsize=9, color='orange', ha='center', va='bottom')\n",
    "    if not np.isnan(auc_vals[i]):\n",
    "        ax1.text(lr, auc_vals[i], f\"{auc_vals[i]*100:.1f}%\", fontsize=9, color='purple', ha='center', va='bottom')\n",
    "\n",
    "# Format x-axis with exact values\n",
    "ax1.set_xticks(learning_rates)\n",
    "ax1.get_xaxis().set_major_formatter(ticker.ScalarFormatter())\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Twin y-axis for validation loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='b')\n",
    "val_loss_line, = ax2.plot(learning_rates, val_loss_vals, marker='x', linestyle='--', color='b', label='Validation Loss')\n",
    "\n",
    "# Add validation loss text\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    if not np.isnan(val_loss_vals[i]):\n",
    "        ax2.text(lr, val_loss_vals[i], f\"{val_loss_vals[i]:.3f}\", fontsize=9, color='b', ha='center', va='bottom')\n",
    "\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Title and layout\n",
    "fig.suptitle('VGG16 Learning Rate Performance Metrics (Averaged)', fontsize=14)\n",
    "fig.tight_layout()\n",
    "fig.legend([f1_line, prec_line, rec_line, auc_line, val_loss_line],\n",
    "           ['F1 Score', 'Precision', 'Recall', 'AUC', 'Validation Loss'],\n",
    "           loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Set your directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesGetBestLR'\n",
    "metrics_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Metrics'\n",
    "metrics_file = os.path.join(metrics_save_dir, 'metrics.pkl')\n",
    "\n",
    "# Config\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "num_folds = 5\n",
    "\n",
    "# Load existing metrics\n",
    "if not os.path.exists(metrics_file):\n",
    "    raise FileNotFoundError(\"metrics.pkl not found. Run your main evaluation script first.\")\n",
    "\n",
    "with open(metrics_file, 'rb') as f:\n",
    "    vgg16_results = pickle.load(f)\n",
    "\n",
    "# Create average_precision key if missing\n",
    "if 'average_precision' not in vgg16_results:\n",
    "    vgg16_results['average_precision'] = {lr: [] for lr in learning_rates}\n",
    "\n",
    "# Patch: compute only average_precision\n",
    "for lr in learning_rates:\n",
    "    existing_folds = len(vgg16_results['average_precision'][lr])\n",
    "    for fold in range(existing_folds + 1, num_folds + 1):\n",
    "        model_path = os.path.join(model_save_dir, f'model_fold{fold}_lr{lr}.keras')\n",
    "        val_fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Skipping: Model not found for LR={lr}, Fold={fold}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Loading model for LR={lr}, Fold={fold}...\")\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Load validation images and labels\n",
    "        X_val, y_val = [], []\n",
    "        for subdir in ['Good', 'Bad']:\n",
    "            full_image_dir = os.path.join(val_fold_dir, subdir)\n",
    "            if not os.path.exists(full_image_dir):\n",
    "                continue\n",
    "            for fname in os.listdir(full_image_dir):\n",
    "                if fname.lower().endswith('.jpg'):\n",
    "                    image_path = os.path.join(full_image_dir, fname)\n",
    "                    img = load_img(image_path, target_size=(224, 224))\n",
    "                    X_val.append(img_to_array(img) / 255.0)\n",
    "                    y_val.append(1 if subdir == 'Good' else 0)\n",
    "\n",
    "        X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "        if len(X_val) == 0:\n",
    "            print(f\"Skipping: No validation data for LR={lr}, Fold={fold}\")\n",
    "            continue\n",
    "\n",
    "        val_probs = model.predict(X_val)\n",
    "        try:\n",
    "            val_ap = average_precision_score(y_val, val_probs)\n",
    "            vgg16_results['average_precision'][lr].append(val_ap)\n",
    "            print(f\"Fold {fold} LR={lr} → Average Precision: {val_ap:.4f}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute average precision for LR={lr}, Fold={fold}: {e}\")\n",
    "            vgg16_results['average_precision'][lr].append(None)\n",
    "\n",
    "# Save the updated metrics\n",
    "with open(metrics_file, 'wb') as f:\n",
    "    pickle.dump(vgg16_results, f)\n",
    "\n",
    "print(\"✅ metrics.pkl updated with average_precision.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Load saved metrics ===\n",
    "metrics_file = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Metrics/metrics.pkl'\n",
    "\n",
    "with open(metrics_file, 'rb') as f:\n",
    "    vgg16_results = pickle.load(f)\n",
    "\n",
    "# === Learning rates ===\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "\n",
    "# === Required metrics check ===\n",
    "required_metrics = ['f1_score', 'precision', 'recall', 'val_loss', 'average_precision']\n",
    "for metric in required_metrics:\n",
    "    if metric not in vgg16_results:\n",
    "        raise KeyError(f\"'{metric}' not found in metrics.pkl\")\n",
    "\n",
    "# === Compute average per learning rate ===\n",
    "avg_vgg16_metrics = {\n",
    "    metric: {\n",
    "        lr: np.mean([v for v in vgg16_results[metric][lr] if v is not None])\n",
    "        for lr in learning_rates\n",
    "    }\n",
    "    for metric in required_metrics\n",
    "}\n",
    "\n",
    "# === Plotting ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Performance Metrics')\n",
    "\n",
    "# Plot main metrics on left Y-axis\n",
    "ax1.plot(learning_rates, [avg_vgg16_metrics['f1_score'][lr] for lr in learning_rates], marker='o', linestyle='-', color='green', label='F1 Score')\n",
    "ax1.plot(learning_rates, [avg_vgg16_metrics['precision'][lr] for lr in learning_rates], marker='s', linestyle='-', color='red', label='Precision')\n",
    "ax1.plot(learning_rates, [avg_vgg16_metrics['recall'][lr] for lr in learning_rates], marker='D', linestyle='-', color='orange', label='Recall')\n",
    "ax1.plot(learning_rates, [avg_vgg16_metrics['average_precision'][lr] for lr in learning_rates], marker='^', linestyle='-', color='purple', label='PR AUC')\n",
    "\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Plot validation loss on secondary Y-axis\n",
    "valid_lrs = []\n",
    "valid_losses = []\n",
    "for lr in learning_rates:\n",
    "    val = avg_vgg16_metrics['val_loss'][lr]\n",
    "    if val is not None:\n",
    "        valid_lrs.append(lr)\n",
    "        valid_losses.append(val)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='blue')\n",
    "ax2.plot(valid_lrs, valid_losses, marker='x', linestyle='--', color='blue', label='Validation Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Title, legend, and layout\n",
    "fig.suptitle('VGG16 Learning Rate Performance Metrics (Using PR AUC)')\n",
    "fig.tight_layout()\n",
    "fig.legend(loc='upper right', bbox_to_anchor=(1, 1), bbox_transform=ax1.transAxes)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph loss and acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Directories and Config ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesGetBestLR'\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5]\n",
    "num_folds = 5\n",
    "\n",
    "# === Initialize storage for histories ===\n",
    "history_data = {lr: {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []} for lr in learning_rates}\n",
    "\n",
    "# === Load and verify histories ===\n",
    "for lr in learning_rates:\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        history_path = os.path.join(history_save_dir, f'history_fold{fold}_lr{lr}.pkl')\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "                missing_keys = []\n",
    "\n",
    "                if 'loss' in history:\n",
    "                    history_data[lr]['train_loss'].append(history['loss'])\n",
    "                else:\n",
    "                    missing_keys.append('loss')\n",
    "\n",
    "                if 'val_loss' in history:\n",
    "                    history_data[lr]['val_loss'].append(history['val_loss'])\n",
    "                else:\n",
    "                    missing_keys.append('val_loss')\n",
    "\n",
    "                if 'accuracy' in history:\n",
    "                    history_data[lr]['train_acc'].append(history['accuracy'])\n",
    "                else:\n",
    "                    missing_keys.append('accuracy')\n",
    "\n",
    "                if 'val_accuracy' in history:\n",
    "                    history_data[lr]['val_acc'].append(history['val_accuracy'])\n",
    "                else:\n",
    "                    missing_keys.append('val_accuracy')\n",
    "\n",
    "                if missing_keys:\n",
    "                    print(f\"⚠️ Missing keys in fold {fold}, LR={lr}: {missing_keys}\")\n",
    "        else:\n",
    "            print(f\"❌ Missing history file: Fold {fold}, LR={lr}\")\n",
    "\n",
    "# === Average across folds per epoch (truncate to shortest length) ===\n",
    "avg_history = {lr: {} for lr in learning_rates}\n",
    "for lr in learning_rates:\n",
    "    for key in ['train_loss', 'val_loss', 'train_acc', 'val_acc']:\n",
    "        fold_histories = history_data[lr][key]\n",
    "        if fold_histories:\n",
    "            min_len = min(len(h) for h in fold_histories)\n",
    "            trimmed = [h[:min_len] for h in fold_histories]\n",
    "            avg_history[lr][key] = np.mean(trimmed, axis=0)\n",
    "\n",
    "# === Plotting ===\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axs = axs.flatten()\n",
    "metric_titles = ['Training Loss', 'Validation Loss', 'Training Accuracy', 'Validation Accuracy']\n",
    "metric_keys = ['train_loss', 'val_loss', 'train_acc', 'val_acc']\n",
    "\n",
    "for idx, (title, key) in enumerate(zip(metric_titles, metric_keys)):\n",
    "    for lr in learning_rates:\n",
    "        if key in avg_history[lr]:\n",
    "            axs[idx].plot(avg_history[lr][key], label=f'LR={lr}')\n",
    "    axs[idx].set_title(title)\n",
    "    axs[idx].set_xlabel('Epoch')\n",
    "    axs[idx].set_ylabel('Value')\n",
    "    axs[idx].legend()\n",
    "    axs[idx].grid(True)\n",
    "\n",
    "fig.suptitle('Training vs Validation Metrics Across Learning Rates (Averaged over Folds)', fontsize=16)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do VGG with best lr 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLRMinus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the VGG16-based model with improvements\n",
    "def create_vgg16_model(image_shape, learning_rate=1e-4):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)  # Added L2 Regularization\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)  # Increased dropout\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Cross-validation loop\n",
    "validation_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "for val_fold_index in range(5):\n",
    "    print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "    \n",
    "    # Define training and validation sets\n",
    "    train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "    val_fold = fold_dirs[val_fold_index]\n",
    "    \n",
    "    # Load training data from the selected folds\n",
    "    X_train, y_train = [], []\n",
    "    for train_fold in train_folds:\n",
    "        images, labels = load_images_and_labels(train_fold)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "    \n",
    "    # Load validation and test data\n",
    "    X_val, y_val = load_images_and_labels(val_fold)\n",
    "    X_test, y_test = load_images_and_labels(test_image_dir)\n",
    "    \n",
    "    # Train the model\n",
    "    model = create_vgg16_model(X_train.shape[1:])\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True),  # Increased patience\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, verbose=1, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,  # Increased epochs\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold{val_fold_index + 1}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    validation_metrics.append({'fold': val_fold_index + 1, 'accuracy': val_accuracy * 100, 'loss': val_loss})\n",
    "    print(f\"Validation Accuracy for Fold {val_fold_index + 1}: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_metrics.append({'fold': val_fold_index + 1, 'accuracy': test_accuracy * 100, 'loss': test_loss})\n",
    "    print(f\"Test Accuracy for Fold {val_fold_index + 1}: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}.keras'))\n",
    "\n",
    "# Metrics summary\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric in validation_metrics:\n",
    "    print(f\"Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for metric in test_metrics:\n",
    "    print(f\"Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "# Compute averages and standard deviations\n",
    "val_accuracies = [m['accuracy'] for m in validation_metrics]\n",
    "test_accuracies = [m['accuracy'] for m in test_metrics]\n",
    "print(f\"\\nAverage Validation Accuracy: {np.mean(val_accuracies):.2f}%, Std Dev: {np.std(val_accuracies):.2f}\")\n",
    "print(f\"Average Test Accuracy: {np.mean(test_accuracies):.2f}%, Std Dev: {np.std(test_accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory where histories are saved\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLRMinus4'\n",
    "\n",
    "# Lists to store histories\n",
    "histories = []\n",
    "\n",
    "# Load all history files\n",
    "for fold in range(1, 6):\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold{fold}.pkl')\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            histories.append(pickle.load(f))\n",
    "    else:\n",
    "        print(f\"Warning: {history_path} not found!\")\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, history in enumerate(histories):\n",
    "    plt.plot(history['accuracy'], label=f'Fold {i+1} Train Acc')\n",
    "    plt.plot(history['val_accuracy'], linestyle='dashed', label=f'Fold {i+1} Val Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training & Validation Accuracy Across Folds')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, history in enumerate(histories):\n",
    "    plt.plot(history['loss'], label=f'Fold {i+1} Train Loss')\n",
    "    plt.plot(history['val_loss'], linestyle='dashed', label=f'Fold {i+1} Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss Across Folds')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus4/model_fold1.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Bad/JH1633_IMG_9233_contrast.jpg'  # Replace with your actual image\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === LOAD AND PREPROCESS IMAGE ===\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "\n",
    "# === GRAD-CAM SETUP (from last conv layer) ===\n",
    "last_conv_layer = 'block5_conv3'  # Best for VGG16\n",
    "grad_model = tf.keras.models.Model(\n",
    "    [model.inputs],\n",
    "    [model.get_layer(last_conv_layer).output, model.output]\n",
    ")\n",
    "\n",
    "# === GRADIENTS ===\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img_preprocessed)\n",
    "    loss = predictions[:, 0]  # for sigmoid output\n",
    "\n",
    "# Compute gradients wrt feature maps\n",
    "grads = tape.gradient(loss, conv_outputs)[0]  # shape: (14, 14, 512)\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1))  # shape: (512,)\n",
    "\n",
    "# Multiply each channel in feature map by gradient importance\n",
    "conv_outputs = conv_outputs[0]  # shape: (14, 14, 512)\n",
    "conv_outputs = conv_outputs * pooled_grads[tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "\n",
    "# Average to get heatmap\n",
    "heatmap = tf.reduce_mean(conv_outputs, axis=-1)\n",
    "\n",
    "# === NORMALIZE HEATMAP ===\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= (np.max(heatmap) + 1e-6)\n",
    "heatmap = cv2.resize(heatmap, (224, 224))\n",
    "\n",
    "# === COLORIZE AND OVERLAY ===\n",
    "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "img_uint8 = np.uint8(img_array)  # original image in uint8 for blending\n",
    "overlayed_img = cv2.addWeighted(img_uint8, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "# === DISPLAY ===\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(cv2.cvtColor(img_uint8, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(f\"Grad-CAM\\nPredicted Score: {predictions.numpy()[0][0]:.2f}\")\n",
    "plt.imshow(cv2.cvtColor(overlayed_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus4/model_fold1.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Bad/JH1633_IMG_9233_contrast.jpg'\n",
    "\n",
    "# === Load model and image ===\n",
    "model = load_model(model_path)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "# === Get outputs of convolutional layers only ===\n",
    "layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(img_array)\n",
    "conv_layer_names = [layer.name for layer in model.layers if 'conv' in layer.name]\n",
    "\n",
    "# === Display more filters and bigger plots ===\n",
    "def display_activations(activations, layer_names, max_images=10):\n",
    "    for layer_name, activation in zip(layer_names, activations):\n",
    "        n_features = activation.shape[-1]\n",
    "        size = activation.shape[1]\n",
    "\n",
    "        # Show up to max_images activations\n",
    "        n_cols = min(max_images, n_features)\n",
    "        display_grid = np.zeros((size, size * n_cols))\n",
    "\n",
    "        for col in range(n_cols):\n",
    "            feature_map = activation[0, :, :, col]\n",
    "            feature_map -= feature_map.mean()\n",
    "            feature_map /= (feature_map.std() + 1e-5)\n",
    "            feature_map *= 64\n",
    "            feature_map += 128\n",
    "            feature_map = np.clip(feature_map, 0, 255).astype('uint8')\n",
    "            display_grid[:, col * size:(col + 1) * size] = feature_map\n",
    "\n",
    "        # Larger figure size\n",
    "        plt.figure(figsize=(n_cols * 2, 2.5))  # Width x Height per filter\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='plasma')  # Try 'gray', 'viridis', or 'plasma'\n",
    "        plt.title(f'Activations from: {layer_name}', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# === Run visualization ===\n",
    "display_activations(activations, conv_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus4/model_fold1.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Bad/JH1633_IMG_9233_contrast.jpg'\n",
    "\n",
    "\n",
    "# === Load model and image ===\n",
    "model = load_model(model_path)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "\n",
    "# === Part 1: Grad-CAM from final conv layer ===\n",
    "last_conv_layer = 'block1_conv2'\n",
    "grad_model = Model(inputs=model.input, outputs=[model.get_layer(last_conv_layer).output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, prediction = grad_model(img_preprocessed)\n",
    "    loss = prediction[:, 0]\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "conv_outputs = conv_outputs[0] * pooled_grads[tf.newaxis, tf.newaxis, :]\n",
    "heatmap = tf.reduce_mean(conv_outputs, axis=-1).numpy()\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= (np.max(heatmap) + 1e-8)\n",
    "heatmap = cv2.resize(heatmap, (224, 224))\n",
    "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "overlay = cv2.addWeighted(heatmap_colored, 0.4, img_array.astype(np.uint8), 0.6, 0)\n",
    "\n",
    "# === Part 2: Raw activation maps from earlier layers ===\n",
    "layer_names = ['block1_conv2', 'block3_conv3', 'block5_conv3']\n",
    "activation_model = Model(inputs=model.input, outputs=[model.get_layer(name).output for name in layer_names])\n",
    "activations = activation_model.predict(img_preprocessed)\n",
    "\n",
    "def show_activation_grid(activation, layer_name, max_features=8):\n",
    "    num_features = min(max_features, activation.shape[-1])\n",
    "    fig, axes = plt.subplots(1, num_features, figsize=(num_features * 2, 2))\n",
    "    fig.suptitle(f\"{layer_name} Activation Maps\", fontsize=12)\n",
    "    for i in range(num_features):\n",
    "        ax = axes[i]\n",
    "        feature_map = activation[0, :, :, i]\n",
    "        feature_map -= feature_map.mean()\n",
    "        feature_map /= (feature_map.std() + 1e-6)\n",
    "        feature_map = np.clip(feature_map * 64 + 128, 0, 255).astype('uint8')\n",
    "        ax.imshow(feature_map, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Display results ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(f\"Grad-CAM - block5_conv3 (Score: {prediction.numpy()[0][0]:.2f})\")\n",
    "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Show activation maps from 3 layers ===\n",
    "for act, name in zip(activations, layer_names):\n",
    "    show_activation_grid(act, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus4/model_fold1.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse/Fold2/Bad/E17203_IMG_8551.jpg'\n",
    "\n",
    "# === Load model and image ===\n",
    "model = load_model(model_path)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "\n",
    "# === Part 1: Grad-CAM from final conv layer ===\n",
    "last_conv_layer = 'block1_conv2'\n",
    "grad_model = Model(inputs=model.input, outputs=[model.get_layer(last_conv_layer).output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, prediction = grad_model(img_preprocessed)\n",
    "    loss = prediction[:, 0]\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "conv_outputs = conv_outputs[0] * pooled_grads[tf.newaxis, tf.newaxis, :]\n",
    "heatmap = tf.reduce_mean(conv_outputs, axis=-1).numpy()\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= (np.max(heatmap) + 1e-8)\n",
    "heatmap = cv2.resize(heatmap, (224, 224))\n",
    "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "overlay = cv2.addWeighted(heatmap_colored, 0.4, img_array.astype(np.uint8), 0.6, 0)\n",
    "\n",
    "# === Part 2: Raw activation maps from earlier layers ===\n",
    "layer_names = ['block1_conv2', 'block3_conv3', 'block5_conv3']\n",
    "activation_model = Model(inputs=model.input, outputs=[model.get_layer(name).output for name in layer_names])\n",
    "activations = activation_model.predict(img_preprocessed)\n",
    "\n",
    "def show_activation_grid(activation, layer_name, max_features=8):\n",
    "    num_features = min(max_features, activation.shape[-1])\n",
    "    fig, axes = plt.subplots(1, num_features, figsize=(num_features * 2, 2))\n",
    "    fig.suptitle(f\"{layer_name} Activation Maps\", fontsize=12)\n",
    "    for i in range(num_features):\n",
    "        ax = axes[i]\n",
    "        feature_map = activation[0, :, :, i]\n",
    "        feature_map -= feature_map.mean()\n",
    "        feature_map /= (feature_map.std() + 1e-6)\n",
    "        feature_map = np.clip(feature_map * 64 + 128, 0, 255).astype('uint8')\n",
    "        ax.imshow(feature_map, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Display results ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(f\"Grad-CAM - block5_conv3 (Score: {prediction.numpy()[0][0]:.2f})\")\n",
    "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Show activation maps from 3 layers ===\n",
    "for act, name in zip(activations, layer_names):\n",
    "    show_activation_grid(act, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus4/model_fold1.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse/Fold3/Good/22?_IMG_9933.jpg'\n",
    "\n",
    "# === Load model and image ===\n",
    "model = load_model(model_path)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "\n",
    "# === Part 1: Grad-CAM from final conv layer ===\n",
    "last_conv_layer = 'block1_conv2'\n",
    "grad_model = Model(inputs=model.input, outputs=[model.get_layer(last_conv_layer).output, model.output])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, prediction = grad_model(img_preprocessed)\n",
    "    loss = prediction[:, 0]\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "conv_outputs = conv_outputs[0] * pooled_grads[tf.newaxis, tf.newaxis, :]\n",
    "heatmap = tf.reduce_mean(conv_outputs, axis=-1).numpy()\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= (np.max(heatmap) + 1e-8)\n",
    "heatmap = cv2.resize(heatmap, (224, 224))\n",
    "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "overlay = cv2.addWeighted(heatmap_colored, 0.4, img_array.astype(np.uint8), 0.6, 0)\n",
    "\n",
    "# === Part 2: Raw activation maps from earlier layers ===\n",
    "layer_names = ['block1_conv2', 'block3_conv3', 'block5_conv3']\n",
    "activation_model = Model(inputs=model.input, outputs=[model.get_layer(name).output for name in layer_names])\n",
    "activations = activation_model.predict(img_preprocessed)\n",
    "\n",
    "def show_activation_grid(activation, layer_name, max_features=8):\n",
    "    num_features = min(max_features, activation.shape[-1])\n",
    "    fig, axes = plt.subplots(1, num_features, figsize=(num_features * 2, 2))\n",
    "    fig.suptitle(f\"{layer_name} Activation Maps\", fontsize=12)\n",
    "    for i in range(num_features):\n",
    "        ax = axes[i]\n",
    "        feature_map = activation[0, :, :, i]\n",
    "        feature_map -= feature_map.mean()\n",
    "        feature_map /= (feature_map.std() + 1e-6)\n",
    "        feature_map = np.clip(feature_map * 64 + 128, 0, 255).astype('uint8')\n",
    "        ax.imshow(feature_map, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Display results ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(f\"Grad-CAM - block5_conv3 (Score: {prediction.numpy()[0][0]:.2f})\")\n",
    "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Show activation maps from 3 layers ===\n",
    "for act, name in zip(activations, layer_names):\n",
    "    show_activation_grid(act, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus4/model_fold1.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold3/Good/24?_IMG_9815_saturation.jpg'\n",
    "target_size = (224, 224)\n",
    "last_conv_layer_name = 'block5_conv3'  # Last conv layer in VGG16\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === LOAD IMAGE ===\n",
    "img = load_img(image_path, target_size=target_size)\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# === GRAD-CAM MODEL ===\n",
    "grad_model = tf.keras.models.Model(\n",
    "    [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    ")\n",
    "\n",
    "# === GRADIENT TAPE ===\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img_array)\n",
    "    pred_index = tf.argmax(predictions[0])\n",
    "    class_output = predictions[:, pred_index]\n",
    "\n",
    "# === GRADIENTS ===\n",
    "grads = tape.gradient(class_output, conv_outputs)\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "conv_outputs = conv_outputs[0]\n",
    "\n",
    "# === GENERATE HEATMAP ===\n",
    "heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "heatmap = tf.squeeze(heatmap)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= tf.math.reduce_max(heatmap) + 1e-8\n",
    "\n",
    "# === LOAD ORIGINAL IMAGE ===\n",
    "img_cv = cv2.imread(image_path)\n",
    "img_cv = cv2.resize(img_cv, target_size)\n",
    "heatmap = cv2.resize(heatmap.numpy(), (img_cv.shape[1], img_cv.shape[0]))\n",
    "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "overlay = cv2.addWeighted(img_cv, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "# === PLOT RESULTS ===\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap, cmap='jet')\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Overlay\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG 1-5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLR'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLR'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the VGG16-based model with improvements\n",
    "def create_vgg16_model(image_shape, learning_rate=1e-5):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)  # Added L2 Regularization\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)  # Increased dropout\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Cross-validation loop\n",
    "validation_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "for val_fold_index in range(5):\n",
    "    print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "    \n",
    "    # Define training and validation sets\n",
    "    train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "    val_fold = fold_dirs[val_fold_index]\n",
    "    \n",
    "    # Load training data from the selected folds\n",
    "    X_train, y_train = [], []\n",
    "    for train_fold in train_folds:\n",
    "        images, labels = load_images_and_labels(train_fold)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "    \n",
    "    # Load validation and test data\n",
    "    X_val, y_val = load_images_and_labels(val_fold)\n",
    "    X_test, y_test = load_images_and_labels(test_image_dir)\n",
    "    \n",
    "    # Train the model\n",
    "    model = create_vgg16_model(X_train.shape[1:])\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True),  # Increased patience\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, verbose=1, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,  # Increased epochs\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold{val_fold_index + 1}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    validation_metrics.append({'fold': val_fold_index + 1, 'accuracy': val_accuracy * 100, 'loss': val_loss})\n",
    "    print(f\"Validation Accuracy for Fold {val_fold_index + 1}: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_metrics.append({'fold': val_fold_index + 1, 'accuracy': test_accuracy * 100, 'loss': test_loss})\n",
    "    print(f\"Test Accuracy for Fold {val_fold_index + 1}: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}.keras'))\n",
    "\n",
    "# Metrics summary\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric in validation_metrics:\n",
    "    print(f\"Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for metric in test_metrics:\n",
    "    print(f\"Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "# Compute averages and standard deviations\n",
    "val_accuracies = [m['accuracy'] for m in validation_metrics]\n",
    "test_accuracies = [m['accuracy'] for m in test_metrics]\n",
    "print(f\"\\nAverage Validation Accuracy: {np.mean(val_accuracies):.2f}%, Std Dev: {np.std(val_accuracies):.2f}\")\n",
    "print(f\"Average Test Accuracy: {np.mean(test_accuracies):.2f}%, Std Dev: {np.std(test_accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# --- CONFIG ---\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLR/model_fold1.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "class_names = ['Bad', 'Good']\n",
    "\n",
    "# --- Load model ---\n",
    "model = load_model(model_path)\n",
    "\n",
    "# --- Load test data ---\n",
    "def load_images_with_paths(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(image_dir, class_name)\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img_path = os.path.join(class_dir, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_arr = img_to_array(img) / 255.0\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "                paths.append(img_path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, img_paths = load_images_with_paths(test_dir)\n",
    "\n",
    "# --- Predictions ---\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = (y_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# --- Separate correct and incorrect predictions ---\n",
    "correct_idxs = np.where(y_pred == y_test)[0]\n",
    "wrong_idxs = np.where(y_pred != y_test)[0]\n",
    "\n",
    "def plot_predictions(indices, title, n=5):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, idx in enumerate(indices[:n]):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        img = load_img(img_paths[idx])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        true_label = class_names[y_test[idx]]\n",
    "        pred_label = class_names[y_pred[idx]]\n",
    "        confidence = y_probs[idx][0]\n",
    "        color = 'green' if y_pred[idx] == y_test[idx] else 'red'\n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label} ({confidence:.2f})\", color=color)\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Show examples ---\n",
    "plot_predictions(correct_idxs, \"✅ Correct Predictions with Confidence\")\n",
    "plot_predictions(wrong_idxs, \"❌ Incorrect Predictions with Confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# --- CONFIG ---\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLR/model_fold1.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "class_names = ['Bad', 'Good']\n",
    "\n",
    "# --- Load model ---\n",
    "model = load_model(model_path)\n",
    "\n",
    "# --- Load test data ---\n",
    "def load_images_with_paths(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(image_dir, class_name)\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img_path = os.path.join(class_dir, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_arr = img_to_array(img) / 255.0\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "                paths.append(img_path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, img_paths = load_images_with_paths(test_dir)\n",
    "\n",
    "# --- Predictions ---\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = (y_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# --- Correct 'Good' predictions ---\n",
    "correct_good_idxs = [i for i in range(len(y_test)) if y_test[i] == 1 and y_pred[i] == 1]\n",
    "\n",
    "# --- Plot only 2 correct 'Good' predictions ---\n",
    "def plot_predictions(indices, title, n=2):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i, idx in enumerate(indices[:n]):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        img = load_img(img_paths[idx])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        true_label = class_names[y_test[idx]]\n",
    "        pred_label = class_names[y_pred[idx]]\n",
    "        confidence = y_probs[idx][0]\n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label} ({confidence:.2f})\", color='green')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(correct_good_idxs, \"\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLR'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLR'\n",
    "\n",
    "\n",
    "# Load test data\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_image_dir)\n",
    "\n",
    "# Track metrics\n",
    "all_metrics = []\n",
    "\n",
    "# Loop through folds\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\nEvaluating Fold {fold}...\")\n",
    "    model_path = os.path.join(model_save_dir, f'model_fold{fold}.keras')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    # Load model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    f1 = f1_score(y_test, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_test, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred_labels, zero_division=1)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, AUC-PR: {auc_pr:.4f}\")\n",
    "\n",
    "    all_metrics.append({\n",
    "        'fold': fold,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'AUC-PR': auc_pr\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for summary\n",
    "import pandas as pd\n",
    "df_metrics = pd.DataFrame(all_metrics)\n",
    "print(\"\\n### VGG16 Test Set Metrics Summary ###\")\n",
    "print(df_metrics)\n",
    "\n",
    "# Compute and print averages\n",
    "print(f\"\\nAverage F1 Score: {df_metrics['F1 Score'].mean():.4f}\")\n",
    "print(f\"Average Precision: {df_metrics['Precision'].mean():.4f}\")\n",
    "print(f\"Average Recall: {df_metrics['Recall'].mean():.4f}\")\n",
    "print(f\"Average AUC-PR: {df_metrics['AUC-PR'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Paths\n",
    "\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLR'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLR'\n",
    "\n",
    "\n",
    "# Load test data\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_image_dir)\n",
    "\n",
    "# Track metrics\n",
    "all_metrics = []\n",
    "\n",
    "# Loop through folds\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\nEvaluating Fold {fold}...\")\n",
    "    model_path = os.path.join(model_save_dir, f'model_fold{fold}.keras')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    # Load model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    f1 = f1_score(y_test, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_test, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred_labels, zero_division=1)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, AUC-PR: {auc_pr:.4f}\")\n",
    "\n",
    "    all_metrics.append({\n",
    "        'fold': fold,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'AUC-PR': auc_pr\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for summary\n",
    "import pandas as pd\n",
    "df_metrics = pd.DataFrame(all_metrics)\n",
    "print(\"\\n### VGG16 Test Set Metrics Summary ###\")\n",
    "print(df_metrics)\n",
    "\n",
    "# Compute and print averages\n",
    "print(f\"\\nAverage F1 Score: {df_metrics['F1 Score'].mean():.4f}\")\n",
    "print(f\"Average Precision: {df_metrics['Precision'].mean():.4f}\")\n",
    "print(f\"Average Recall: {df_metrics['Recall'].mean():.4f}\")\n",
    "print(f\"Average AUC-PR: {df_metrics['AUC-PR'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the history directory\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLR'\n",
    "\n",
    "# Collect metrics\n",
    "folds = []\n",
    "val_accs = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "# Loop over folds\n",
    "for fold in range(1, 6):\n",
    "    history_path = os.path.join(history_dir, f'history_fold{fold}.pkl')\n",
    "    \n",
    "    if not os.path.exists(history_path):\n",
    "        print(f\"History file not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    # Get best values\n",
    "    best_val_acc = max(history['val_accuracy'])\n",
    "    best_train_acc = max(history['accuracy'])\n",
    "    best_val_loss = min(history['val_loss'])\n",
    "    best_train_loss = min(history['loss'])\n",
    "\n",
    "    folds.append(fold)\n",
    "    val_accs.append(best_val_acc)\n",
    "    train_accs.append(best_train_acc)\n",
    "    val_losses.append(best_val_loss)\n",
    "    train_losses.append(best_train_loss)\n",
    "\n",
    "# Create DataFrame\n",
    "df_hist = pd.DataFrame({\n",
    "    'Fold': folds,\n",
    "    'Val Accuracy': val_accs,\n",
    "    'Train Accuracy': train_accs,\n",
    "    'Val Loss': val_losses,\n",
    "    'Train Loss': train_losses\n",
    "})\n",
    "\n",
    "print(df_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You can use df_hist from earlier\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bubble = plt.scatter(\n",
    "    df_hist['Fold'],\n",
    "    df_hist['Val Accuracy'],\n",
    "    s=(1 / df_hist['Val Loss']) * 2000,  # Bigger bubble for lower loss\n",
    "    c=df_hist['Val Loss'],\n",
    "    cmap='coolwarm',\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "# Labels and titles\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy Across Folds (Bubble Size ~ 1 / Val Loss)')\n",
    "cbar = plt.colorbar(bubble)\n",
    "cbar.set_label('Validation Loss')\n",
    "\n",
    "# Annotate\n",
    "for i, row in df_hist.iterrows():\n",
    "    plt.text(row['Fold'], row['Val Accuracy'] + 0.003, f\"Fold {int(row['Fold'])}\", ha='center')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.xticks(df_hist['Fold'])  # Ensure all fold numbers are shown\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bubble = plt.scatter(\n",
    "    df_metrics['fold'],\n",
    "    df_metrics['F1 Score'],\n",
    "    s=df_metrics['F1 Score'] * 1000,          # Bubble size ~ F1 Score\n",
    "    c=df_metrics['AUC-PR'],                   # Color ~ AUC-PR\n",
    "    cmap='viridis',\n",
    "    alpha=0.8,\n",
    "    edgecolors='black',\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score per Fold (Bubble Size ~ F1, Color ~ AUC-PR)')\n",
    "cbar = plt.colorbar(bubble)\n",
    "cbar.set_label('AUC-PR')\n",
    "\n",
    "# Annotate\n",
    "for i, row in df_metrics.iterrows():\n",
    "    plt.text(row['fold'], row['F1 Score'] + 0.01, f\"Fold {int(row['fold'])}\", ha='center')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.xticks(df_metrics['fold'])  # Show all fold numbers\n",
    "plt.ylim(0, 1.1)  # F1 Score range\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Your data\n",
    "df_metrics = pd.DataFrame({\n",
    "    'Fold': [1, 2, 3, 4, 5],\n",
    "    'F1 Score': [0.787879, 0.670588, 0.708075, 0.760000, 0.766355],\n",
    "    'Precision': [0.928571, 0.504425, 0.548077, 0.612903, 0.820000],\n",
    "    'Recall': [0.684211, 1.000000, 1.000000, 1.000000, 0.719298],\n",
    "    'AUC-PR': [0.908445, 0.774038, 0.845158, 0.805466, 0.845102]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bubble = plt.scatter(\n",
    "    df_metrics['Fold'],\n",
    "    df_metrics['F1 Score'],\n",
    "    s=df_metrics['AUC-PR'] * 1000,  # Bubble size ~ AUC-PR\n",
    "    c=df_metrics['Precision'],      # Color ~ Precision\n",
    "    cmap='coolwarm',\n",
    "    edgecolors='black',\n",
    "    alpha=0.8,\n",
    "    linewidth=1\n",
    ")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Across Folds (Size ~ AUC-PR, Color ~ Precision)')\n",
    "cbar = plt.colorbar(bubble)\n",
    "cbar.set_label('Precision')\n",
    "\n",
    "# Annotate fold numbers\n",
    "for i, row in df_metrics.iterrows():\n",
    "    plt.text(row['Fold'], row['F1 Score'] + 0.01, f\"Fold {int(row['Fold'])}\", ha='center')\n",
    "\n",
    "# Add average line\n",
    "avg_f1 = df_metrics['F1 Score'].mean()\n",
    "plt.axhline(avg_f1, color='gray', linestyle='--', label=f'Avg F1: {avg_f1:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(df_metrics['Fold'])\n",
    "plt.ylim(0.6, 0.85)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Your metrics data\n",
    "df_metrics = pd.DataFrame({\n",
    "    'Fold': [1, 2, 3, 4, 5],\n",
    "    'AUC-PR': [0.908445, 0.774038, 0.845158, 0.805466, 0.845102]\n",
    "})\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(data=df_metrics, y='AUC-PR', inner='point', linewidth=1.2, color='skyblue')\n",
    "\n",
    "# Labels and title\n",
    "plt.title('Distribution of AUC-PR Across Folds', fontsize=14)\n",
    "plt.ylabel('AUC-PR Score')\n",
    "plt.xticks([])  # Hides the x-axis since there's only one metric\n",
    "\n",
    "# Annotate average\n",
    "avg_aucpr = df_metrics['AUC-PR'].mean()\n",
    "plt.axhline(avg_aucpr, linestyle='--', color='gray', label=f'Avg: {avg_aucpr:.3f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory containing saved histories\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLR'\n",
    "\n",
    "# Load histories for all folds\n",
    "histories = []\n",
    "missing_folds = []\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold{fold}.pkl')\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            histories.append(pickle.load(f))\n",
    "    else:\n",
    "        print(f\"Warning: {history_path} not found.\")\n",
    "        missing_folds.append(fold)\n",
    "\n",
    "# Ensure we have at least one valid history to plot\n",
    "if not histories:\n",
    "    print(\"No valid history files found. Please check the file paths.\")\n",
    "else:\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for fold, history in enumerate(histories, start=1):\n",
    "        plt.plot(history['loss'], label=f'Train Loss Fold {fold}')\n",
    "        plt.plot(history['val_loss'], '--', label=f'Val Loss Fold {fold}')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Across 5 Folds')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for fold, history in enumerate(histories, start=1):\n",
    "        plt.plot(history['accuracy'], label=f'Train Acc Fold {fold}')\n",
    "        plt.plot(history['val_accuracy'], '--', label=f'Val Acc Fold {fold}')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy Across 5 Folds')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "if missing_folds:\n",
    "    print(f\"Missing history files for folds: {missing_folds}. Please check if they were saved correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLR'\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Initialize confusion matrices for validation and test sets\n",
    "all_conf_matrices_val = []\n",
    "all_conf_matrices_test = []\n",
    "\n",
    "for val_fold_index in range(5):\n",
    "    print(f\"\\nProcessing Fold {val_fold_index + 1} for Confusion Matrix\")\n",
    "\n",
    "    # Load validation and test data\n",
    "    X_val, y_val = load_images_and_labels(fold_dirs[val_fold_index])\n",
    "    X_test, y_test = load_images_and_labels(test_image_dir)\n",
    "\n",
    "    # Load trained model\n",
    "    model_path = os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found for Fold {val_fold_index + 1}: {model_path}\")\n",
    "        continue\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Predict on validation and test sets\n",
    "    y_val_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "    y_test_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Compute confusion matrices\n",
    "    conf_matrix_val = confusion_matrix(y_val, y_val_pred)\n",
    "    conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "    all_conf_matrices_val.append(conf_matrix_val)\n",
    "    all_conf_matrices_test.append(conf_matrix_test)\n",
    "\n",
    "    print(f\"Validation Set Classification Report for Fold {val_fold_index + 1}:\\n\", classification_report(y_val, y_val_pred))\n",
    "    print(f\"Test Set Classification Report for Fold {val_fold_index + 1}:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Plot confusion matrices for Validation Set\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, cm in enumerate(all_conf_matrices_val):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'], ax=axes[i])\n",
    "    axes[i].set_title(f'Validation Confusion Matrix Fold {i+1}')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrices for Test Set\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, cm in enumerate(all_conf_matrices_test):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'], ax=axes[i])\n",
    "    axes[i].set_title(f'Test Confusion Matrix Fold {i+1}')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Summed confusion matrices across all 5 folds\n",
    "conf_matrix_val = np.array([[1018, 277],\n",
    "                            [312,  983]])\n",
    "\n",
    "conf_matrix_test = np.array([[256,  24],\n",
    "                             [103, 182]])\n",
    "\n",
    "# Plot Validation Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix_val, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.title('Combined Confusion Matrix - Validation (All Folds)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Test Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.title('Combined Confusion Matrix - Test (All Folds)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Rounded averaged confusion matrices (no decimals, no commas)\n",
    "avg_conf_matrix_val = np.array([[204, 55],\n",
    "                                [62, 197]])\n",
    "\n",
    "avg_conf_matrix_test = np.array([[51, 5],\n",
    "                                 [21, 36]])\n",
    "\n",
    "# Plot Averaged Validation Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(avg_conf_matrix_val, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.title('Averaged Confusion Matrix - Validation (All Folds)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Averaged Test Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(avg_conf_matrix_test, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.title('Averaged Confusion Matrix - Test (All Folds)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try -6 lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Models_mainUse2MetNuweChangesBestLRMinus6'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLRMinus6'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the VGG16-based model with improvements\n",
    "def create_vgg16_model(image_shape, learning_rate=1e-6):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)  # Added L2 Regularization\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)  # Increased dropout\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Cross-validation loop\n",
    "validation_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "for val_fold_index in range(5):\n",
    "    print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "    \n",
    "    # Define training and validation sets\n",
    "    train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "    val_fold = fold_dirs[val_fold_index]\n",
    "    \n",
    "    # Load training data from the selected folds\n",
    "    X_train, y_train = [], []\n",
    "    for train_fold in train_folds:\n",
    "        images, labels = load_images_and_labels(train_fold)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "    \n",
    "    # Load validation and test data\n",
    "    X_val, y_val = load_images_and_labels(val_fold)\n",
    "    X_test, y_test = load_images_and_labels(test_image_dir)\n",
    "    \n",
    "    # Train the model\n",
    "    model = create_vgg16_model(X_train.shape[1:])\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True),  # Increased patience\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, verbose=1, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,  # Increased epochs\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold{val_fold_index + 1}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    validation_metrics.append({'fold': val_fold_index + 1, 'accuracy': val_accuracy * 100, 'loss': val_loss})\n",
    "    print(f\"Validation Accuracy for Fold {val_fold_index + 1}: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    test_metrics.append({'fold': val_fold_index + 1, 'accuracy': test_accuracy * 100, 'loss': test_loss})\n",
    "    print(f\"Test Accuracy for Fold {val_fold_index + 1}: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(os.path.join(model_save_dir, f'model_fold{val_fold_index + 1}.keras'))\n",
    "\n",
    "# Metrics summary\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric in validation_metrics:\n",
    "    print(f\"Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for metric in test_metrics:\n",
    "    print(f\"Fold {metric['fold']}: Accuracy: {metric['accuracy']:.2f}%, Loss: {metric['loss']:.4f}\")\n",
    "\n",
    "# Compute averages and standard deviations\n",
    "val_accuracies = [m['accuracy'] for m in validation_metrics]\n",
    "test_accuracies = [m['accuracy'] for m in test_metrics]\n",
    "print(f\"\\nAverage Validation Accuracy: {np.mean(val_accuracies):.2f}%, Std Dev: {np.std(val_accuracies):.2f}\")\n",
    "print(f\"Average Test Accuracy: {np.mean(test_accuracies):.2f}%, Std Dev: {np.std(test_accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ Corrected path to Fold 1 history\n",
    "history_path = '/Users/suzetteschulenburg/Desktop/MainUse/Saved_Histories_mainseetN2uweChnagesBestLRMinus6/history_fold1.pkl'\n",
    "\n",
    "# Load training history\n",
    "if not os.path.exists(history_path):\n",
    "    raise FileNotFoundError(f\"Could not find history file: {history_path}\")\n",
    "\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# Extract values\n",
    "train_loss = history.get('loss', [])\n",
    "val_loss = history.get('val_loss', [])\n",
    "train_acc = history.get('accuracy', [])\n",
    "val_acc = history.get('val_accuracy', [])\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, label='Train Loss', color='red')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss', color='blue')\n",
    "plt.title('Loss over Epochs (LR = 1e-6)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, label='Train Accuracy', color='green')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy', color='orange')\n",
    "plt.title('Accuracy over Epochs (LR = 1e-6)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Final formatting\n",
    "plt.suptitle('Training Performance for Fold 1 — Very Low LR = 1e-6 (Bad Learning Rate)')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths\n",
    "source_folds_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'  # Original folds directory\n",
    "categories = ['Good', 'Bad']  # Classes to balance\n",
    "\n",
    "# Collect all images grouped by base ID\n",
    "def collect_images_by_base_id(fold_dir, categories):\n",
    "    base_id_dict = {category: defaultdict(list) for category in categories}\n",
    "\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(fold_dir, category)\n",
    "        if not os.path.exists(category_dir):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(category_dir):\n",
    "            if filename.lower().endswith('.jpg'):\n",
    "                base_id = filename.split('_')[0]  # Extract base ID (e.g., E2025 from E2025_IMG_8469.jpg)\n",
    "                img_path = os.path.join(category_dir, filename)\n",
    "                base_id_dict[category][base_id].append(img_path)\n",
    "\n",
    "    return base_id_dict\n",
    "\n",
    "# Get the minimum count between `Good` and `Bad` for balancing\n",
    "def get_minimum_count(base_id_dict):\n",
    "    good_count = sum(len(images) for images in base_id_dict['Good'].values())\n",
    "    bad_count = sum(len(images) for images in base_id_dict['Bad'].values())\n",
    "    return min(good_count, bad_count)\n",
    "\n",
    "# Balance images directly in the source directory\n",
    "def balance_images_in_place(source_folds_dir, num_folds, categories):\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        print(f\"Processing Fold {fold}...\")\n",
    "\n",
    "        # Collect images by base ID\n",
    "        fold_dir = os.path.join(source_folds_dir, f'Fold{fold}')\n",
    "        base_id_dict = collect_images_by_base_id(fold_dir, categories)\n",
    "\n",
    "        # Determine target count for balancing\n",
    "        target_count = get_minimum_count(base_id_dict)\n",
    "        print(f\"Target count per class: {target_count}\")\n",
    "\n",
    "        # Balance each category\n",
    "        for category in categories:\n",
    "            category_dir = os.path.join(fold_dir, category)\n",
    "            all_base_ids = list(base_id_dict[category].keys())\n",
    "            random.shuffle(all_base_ids)  # Shuffle to ensure randomness\n",
    "\n",
    "            current_count = 0\n",
    "            for base_id in all_base_ids:\n",
    "                images = base_id_dict[category][base_id]\n",
    "\n",
    "                # If adding the entire base ID exceeds the target, remove excess images\n",
    "                if current_count + len(images) > target_count:\n",
    "                    excess_images = images[target_count - current_count:]\n",
    "                    for img_path in excess_images:\n",
    "                        os.remove(img_path)  # Remove the excess images\n",
    "                    print(f\"Removed {len(excess_images)} images from base ID {base_id} in {category}\")\n",
    "                    break\n",
    "                else:\n",
    "                    current_count += len(images)\n",
    "\n",
    "    print(\"Balancing complete. Original folds updated.\")\n",
    "\n",
    "# Run the balancing process\n",
    "balance_images_in_place(source_folds_dir, num_folds=5, categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Learning rate ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Experiments'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Learning rates to test\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the ResNet50 model\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze base ResNet layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {lr: {'accuracy': [], 'f1_score': []} for lr in learning_rates}\n",
    "\n",
    "# Cross-validation loop\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTesting Learning Rate: {lr}\")\n",
    "    for val_fold_index in range(5):\n",
    "        print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "        \n",
    "        train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "        val_fold = fold_dirs[val_fold_index]\n",
    "        \n",
    "        # Load training data\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in train_folds:\n",
    "            images, labels = load_images_and_labels(train_fold)\n",
    "            X_train.append(images)\n",
    "            y_train.append(labels)\n",
    "        X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "        \n",
    "        # Load validation data\n",
    "        X_val, y_val = load_images_and_labels(val_fold)\n",
    "        \n",
    "        # Train the model\n",
    "        model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7),\n",
    "            ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold{val_fold_index + 1}.keras'), save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=30,  # Reduced for efficiency\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Save history\n",
    "        history_path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold{val_fold_index + 1}.pkl')\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_preds = model.predict(X_val) > 0.5\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "        val_accuracy = np.mean(val_preds.flatten() == y_val)\n",
    "        \n",
    "        results[lr]['accuracy'].append(val_accuracy * 100)\n",
    "        results[lr]['f1_score'].append(val_f1)\n",
    "        \n",
    "        print(f\"Fold {val_fold_index + 1} - Accuracy: {val_accuracy:.2%}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # Free up memory after each fold\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "# Compute average accuracy and F1-score per learning rate\n",
    "avg_results = {lr: {'accuracy': np.mean(results[lr]['accuracy']), 'f1_score': np.mean(results[lr]['f1_score'])} for lr in learning_rates}\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, [avg_results[lr]['accuracy'] for lr in learning_rates], marker='o', label='Accuracy (%)')\n",
    "plt.plot(learning_rates, [avg_results[lr]['f1_score'] for lr in learning_rates], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Learning Rate vs Performance - ResNet50')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze models LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Experiments'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories'\n",
    "\n",
    "# Learning rates tested\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "num_folds = 5  # Number of folds used in cross-validation\n",
    "\n",
    "# Function to load validation images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Dictionaries to store F1 scores and Validation Loss per learning rate\n",
    "f1_scores = {lr: [] for lr in learning_rates}\n",
    "val_losses = {lr: [] for lr in learning_rates}\n",
    "\n",
    "# Loop through learning rates and folds\n",
    "for lr in learning_rates:\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        model_path = os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold{fold}.keras')\n",
    "        history_path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold{fold}.pkl')\n",
    "        val_fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading model for LR={lr}, Fold={fold}...\")\n",
    "            model = load_model(model_path)  # Load saved model\n",
    "            \n",
    "            # Load validation data\n",
    "            X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "            if len(X_val) == 0:\n",
    "                print(f\"Warning: No validation images found for LR={lr}, Fold={fold}\")\n",
    "                continue\n",
    "            \n",
    "            # Compute predictions\n",
    "            val_preds = (model.predict(X_val) > 0.5).astype(int)  # Convert to binary\n",
    "            \n",
    "            # Compute F1-score\n",
    "            val_f1 = f1_score(y_val, val_preds, zero_division=1)\n",
    "            f1_scores[lr].append(val_f1)\n",
    "            \n",
    "            print(f\"Fold {fold} - F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Model not found for LR={lr}, Fold={fold}\")\n",
    "\n",
    "        # Load Validation Loss from History File\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "\n",
    "            # Get best (minimum) validation loss\n",
    "            if 'val_loss' in history:\n",
    "                min_val_loss = min(history['val_loss'])\n",
    "                val_losses[lr].append(min_val_loss)\n",
    "            else:\n",
    "                print(f\"Warning: val_loss missing in history for LR={lr}, Fold={fold}\")\n",
    "                val_losses[lr].append(None)\n",
    "        else:\n",
    "            print(f\"Warning: History file not found for LR={lr}, Fold={fold}\")\n",
    "            val_losses[lr].append(None)\n",
    "\n",
    "# Compute the average F1-score and Validation Loss per learning rate\n",
    "avg_f1_scores = {lr: np.mean(f1_scores[lr]) if f1_scores[lr] else 0 for lr in learning_rates}\n",
    "avg_val_losses = {lr: np.mean([x for x in val_losses[lr] if x is not None]) if val_losses[lr] else None for lr in learning_rates}\n",
    "\n",
    "# Plot F1-score and Validation Loss per Learning Rate\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot F1 Score\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('F1 Score', color='g')\n",
    "ax1.plot(learning_rates, [avg_f1_scores[lr] for lr in learning_rates], marker='o', linestyle='-', color='g', label='Avg F1 Score')\n",
    "ax1.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# Twin axis for Validation Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='b')\n",
    "ax2.plot(learning_rates, [avg_val_losses[lr] for lr in learning_rates], marker='s', linestyle='--', color='b', label='Avg Val Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Title and Legend\n",
    "fig.suptitle('F1 Score & Validation Loss per Learning Rate - ResNet50')\n",
    "fig.tight_layout()\n",
    "fig.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Experiments'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories'\n",
    "\n",
    "# Learning rates tested\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "num_folds = 5  # Number of folds used in cross-validation\n",
    "\n",
    "# Function to load validation images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Initialize metric dictionaries\n",
    "metrics = {\n",
    "    \"f1\": {lr: [] for lr in learning_rates},\n",
    "    \"precision\": {lr: [] for lr in learning_rates},\n",
    "    \"recall\": {lr: [] for lr in learning_rates},\n",
    "    \"accuracy\": {lr: [] for lr in learning_rates},\n",
    "    \"auc_pr\": {lr: [] for lr in learning_rates},\n",
    "    \"val_loss\": {lr: [] for lr in learning_rates}\n",
    "}\n",
    "\n",
    "# Loop through learning rates and folds\n",
    "for lr in learning_rates:\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        model_path = os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold{fold}.keras')\n",
    "        history_path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold{fold}.pkl')\n",
    "        val_fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading model for LR={lr}, Fold={fold}...\")\n",
    "            model = load_model(model_path)  # Load saved model\n",
    "            \n",
    "            # Load validation data\n",
    "            X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "            if len(X_val) == 0:\n",
    "                print(f\"Warning: No validation images found for LR={lr}, Fold={fold}\")\n",
    "                continue\n",
    "            \n",
    "            # Compute predictions\n",
    "            y_pred_probs = model.predict(X_val)  # Get probabilities\n",
    "            y_pred_labels = (y_pred_probs > 0.5).astype(int)  # Convert to binary\n",
    "\n",
    "            # Compute metrics\n",
    "            f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "            precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "            recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "            accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "            # Compute Precision-Recall AUC\n",
    "            precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "            auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "            # Store metrics\n",
    "            metrics[\"f1\"][lr].append(f1)\n",
    "            metrics[\"precision\"][lr].append(precision)\n",
    "            metrics[\"recall\"][lr].append(recall)\n",
    "            metrics[\"accuracy\"][lr].append(accuracy)\n",
    "            metrics[\"auc_pr\"][lr].append(auc_pr)\n",
    "\n",
    "            print(f\"Fold {fold} - LR {lr}: F1={f1:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, AUC-PR={auc_pr:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Model not found for LR={lr}, Fold={fold}\")\n",
    "\n",
    "        # Load Validation Loss from History File\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "\n",
    "            if 'val_loss' in history:\n",
    "                min_val_loss = min(history['val_loss'])\n",
    "                metrics[\"val_loss\"][lr].append(min_val_loss)\n",
    "            else:\n",
    "                print(f\"Warning: val_loss missing in history for LR={lr}, Fold={fold}\")\n",
    "                metrics[\"val_loss\"][lr].append(None)\n",
    "        else:\n",
    "            print(f\"Warning: History file not found for LR={lr}, Fold={fold}\")\n",
    "            metrics[\"val_loss\"][lr].append(None)\n",
    "\n",
    "# Compute averages per learning rate\n",
    "avg_metrics = {\n",
    "    metric: {lr: np.nanmean(metrics[metric][lr]) for lr in learning_rates} for metric in metrics\n",
    "}\n",
    "\n",
    "# Plot Metrics\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot F1 Score\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('F1 Score', color='g')\n",
    "ax1.plot(learning_rates, [avg_metrics[\"f1\"][lr] for lr in learning_rates], marker='o', linestyle='-', color='g', label='Avg F1 Score')\n",
    "ax1.tick_params(axis='y', labelcolor='g')\n",
    "\n",
    "# Twin axis for Validation Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='b')\n",
    "ax2.plot(learning_rates, [avg_metrics[\"val_loss\"][lr] for lr in learning_rates], marker='s', linestyle='--', color='b', label='Avg Val Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Add Accuracy plot\n",
    "fig, ax3 = plt.subplots(figsize=(12, 6))\n",
    "ax3.set_xlabel('Learning Rate')\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_ylabel('Accuracy', color='r')\n",
    "ax3.plot(learning_rates, [avg_metrics[\"accuracy\"][lr] for lr in learning_rates], marker='^', linestyle='-', color='r', label='Avg Accuracy')\n",
    "ax3.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Titles and Legends\n",
    "fig.suptitle('Performance Metrics per Learning Rate - ResNet50')\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.legend(loc=\"upper right\")\n",
    "ax3.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print Results\n",
    "print(\"\\n### Summary Metrics Per Learning Rate ###\")\n",
    "for lr in learning_rates:\n",
    "    print(f\"LR: {lr:.0e} | F1: {avg_metrics['f1'][lr]:.4f} | Precision: {avg_metrics['precision'][lr]:.4f} | Recall: {avg_metrics['recall'][lr]:.4f} | AUC-PR: {avg_metrics['auc_pr'][lr]:.4f} | Accuracy: {avg_metrics['accuracy'][lr]:.4f} | Val Loss: {avg_metrics['val_loss'][lr]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === Settings ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories'\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "num_folds = 5\n",
    "\n",
    "# === Containers for averaged metrics ===\n",
    "avg_train_acc = {}\n",
    "avg_val_acc = {}\n",
    "avg_train_loss = {}\n",
    "avg_val_loss = {}\n",
    "\n",
    "# === Load and average histories ===\n",
    "for lr in learning_rates:\n",
    "    # Dynamically format learning rate key\n",
    "    if lr >= 1e-4:\n",
    "        lr_key = f\"{lr:.4f}\".rstrip('0').rstrip('.')  # e.g. 0.001\n",
    "    else:\n",
    "        lr_key = f\"{lr:.0e}\".replace('E', 'e')         # e.g. 5e-05\n",
    "\n",
    "    train_acc_all, val_acc_all = [], []\n",
    "    train_loss_all, val_loss_all = [], []\n",
    "\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        filename = f\"history_resnet_lr{lr_key}_fold{fold}.pkl\"\n",
    "        filepath = os.path.join(history_save_dir, filename)\n",
    "\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "\n",
    "            if all(k in history for k in ['accuracy', 'val_accuracy', 'loss', 'val_loss']):\n",
    "                train_acc_all.append(history['accuracy'])\n",
    "                val_acc_all.append(history['val_accuracy'])\n",
    "                train_loss_all.append(history['loss'])\n",
    "                val_loss_all.append(history['val_loss'])\n",
    "            else:\n",
    "                print(f\"⚠️ Missing keys in: {filename}\")\n",
    "        else:\n",
    "            print(f\"❌ File not found: {filename}\")\n",
    "\n",
    "    # Truncate sequences to same length\n",
    "    def truncate(histories):\n",
    "        min_len = min(len(h) for h in histories)\n",
    "        return np.array([h[:min_len] for h in histories])\n",
    "\n",
    "    if train_acc_all:\n",
    "        avg_train_acc[lr_key] = np.mean(truncate(train_acc_all), axis=0)\n",
    "        avg_val_acc[lr_key] = np.mean(truncate(val_acc_all), axis=0)\n",
    "        avg_train_loss[lr_key] = np.mean(truncate(train_loss_all), axis=0)\n",
    "        avg_val_loss[lr_key] = np.mean(truncate(val_loss_all), axis=0)\n",
    "        print(f\"✅ Averaged data loaded for LR={lr_key}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No data for LR={lr_key}\")\n",
    "\n",
    "# === Plotting ===\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Accuracy ---\n",
    "for lr_key in avg_train_acc:\n",
    "    axs[0].plot(avg_train_acc[lr_key], linestyle='--', label=f'Train LR={lr_key}')\n",
    "    axs[0].plot(avg_val_acc[lr_key], linestyle='-', label=f'Val LR={lr_key}')\n",
    "axs[0].set_title('Training and Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# --- Loss ---\n",
    "for lr_key in avg_train_loss:\n",
    "    axs[1].plot(avg_train_loss[lr_key], linestyle='--', label=f'Train LR={lr_key}')\n",
    "    axs[1].plot(avg_val_loss[lr_key], linestyle='-', label=f'Val LR={lr_key}')\n",
    "axs[1].set_title('Training and Validation Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "fig.suptitle('ResNet50 - Learning Rate Comparison (Accuracy & Loss)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Patience 2 best learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsBest2'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesBest2'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Learning rates to test\n",
    "learning_rates = [5e-6, 1e-5]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the ResNet50 model\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze base ResNet layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {lr: {'accuracy': [], 'f1_score': []} for lr in learning_rates}\n",
    "\n",
    "# Cross-validation loop\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTesting Learning Rate: {lr}\")\n",
    "    for val_fold_index in range(5):\n",
    "        print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "        \n",
    "        train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "        val_fold = fold_dirs[val_fold_index]\n",
    "        \n",
    "        # Load training data\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in train_folds:\n",
    "            images, labels = load_images_and_labels(train_fold)\n",
    "            X_train.append(images)\n",
    "            y_train.append(labels)\n",
    "        X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "        \n",
    "        # Load validation data\n",
    "        X_val, y_val = load_images_and_labels(val_fold)\n",
    "        \n",
    "        # Train the model\n",
    "        model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-7),\n",
    "            ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold{val_fold_index + 1}.keras'), save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=70,  \n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Save history\n",
    "        history_path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold{val_fold_index + 1}.pkl')\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_preds = model.predict(X_val) > 0.5\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "        val_accuracy = np.mean(val_preds.flatten() == y_val)\n",
    "        \n",
    "        results[lr]['accuracy'].append(val_accuracy * 100)\n",
    "        results[lr]['f1_score'].append(val_f1)\n",
    "        \n",
    "        print(f\"Fold {val_fold_index + 1} - Accuracy: {val_accuracy:.2%}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # Free up memory after each fold\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "# Compute average accuracy and F1-score per learning rate\n",
    "avg_results = {lr: {'accuracy': np.mean(results[lr]['accuracy']), 'f1_score': np.mean(results[lr]['f1_score'])} for lr in learning_rates}\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, [avg_results[lr]['accuracy'] for lr in learning_rates], marker='o', label='Accuracy (%)')\n",
    "plt.plot(learning_rates, [avg_results[lr]['f1_score'] for lr in learning_rates], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Learning Rate vs Performance - ResNet50')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesBest2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsBest2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "learning_rates = [5e-5, 1e-5]\n",
    "num_folds = 5\n",
    "\n",
    "# === Load test data ===\n",
    "def load_test_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        class_path = os.path.join(image_dir, subdir)\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(class_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                path = os.path.join(class_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "                paths.append(path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, test_paths = load_test_images_and_labels(test_image_dir)\n",
    "\n",
    "# === Plot histories and test metrics ===\n",
    "for lr in learning_rates:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    val_accuracies, val_losses, train_accuracies, train_losses = [], [], [], []\n",
    "\n",
    "    print(f\"\\n🔍 Results for Learning Rate = {lr}\")\n",
    "    f1s, precisions, recalls, auprcs = [], [], [], []\n",
    "\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        # === Load history ===\n",
    "        history_path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold{fold}.pkl')\n",
    "        with open(history_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "\n",
    "        train_acc = history['accuracy']\n",
    "        val_acc = history['val_accuracy']\n",
    "        train_loss = history['loss']\n",
    "        val_loss = history['val_loss']\n",
    "        \n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # === Load model and predict on test set ===\n",
    "        model_path = os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold{fold}.keras')\n",
    "        model = load_model(model_path)\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "        f1s.append(f1_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred))\n",
    "        recalls.append(recall_score(y_test, y_pred))\n",
    "        auprcs.append(average_precision_score(y_test, y_pred))\n",
    "\n",
    "    # === Plot Accuracy ===\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i in range(num_folds):\n",
    "        plt.plot(val_accuracies[i], label=f'Fold {i+1} Val Acc')\n",
    "        plt.plot(train_accuracies[i], linestyle='--', label=f'Fold {i+1} Train Acc')\n",
    "    plt.title(f'Accuracy (LR={lr})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # === Plot Loss ===\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i in range(num_folds):\n",
    "        plt.plot(val_losses[i], label=f'Fold {i+1} Val Loss')\n",
    "        plt.plot(train_losses[i], linestyle='--', label=f'Fold {i+1} Train Loss')\n",
    "    plt.title(f'Loss (LR={lr})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.suptitle(f\"Training Curves for LR = {lr}\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # === Print Test Metrics ===\n",
    "    print(f\"🧪 Test Set Metrics (Average Across Folds) for LR = {lr}:\")\n",
    "    print(f\"🔹 F1 Score:  {np.mean(f1s):.4f}\")\n",
    "    print(f\"🔹 Precision: {np.mean(precisions):.4f}\")\n",
    "    print(f\"🔹 Recall:    {np.mean(recalls):.4f}\")\n",
    "    print(f\"🔹 AUC-PR:    {np.mean(auprcs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    average_precision_score, confusion_matrix\n",
    ")\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "learning_rate = 1e-5\n",
    "num_folds = 5\n",
    "\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesBest2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsBest2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "\n",
    "# === Load test data ===\n",
    "def load_test_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        class_path = os.path.join(image_dir, subdir)\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(class_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                path = os.path.join(class_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "                paths.append(path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, test_paths = load_test_images_and_labels(test_image_dir)\n",
    "\n",
    "# === Plot histories and test metrics ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "val_accuracies, val_losses, train_accuracies, train_losses = [], [], [], []\n",
    "\n",
    "print(f\"\\n🔍 Results for Learning Rate = {learning_rate}\")\n",
    "f1s, precisions, recalls, auprcs = [], [], [], []\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    print(f\"\\n📁 Fold {fold}\")\n",
    "    \n",
    "    # === Load history ===\n",
    "    history_path = os.path.join(history_save_dir, f'history_resnet_lr{learning_rate}_fold{fold}.pkl')\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    train_acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # === Load model and predict on test set ===\n",
    "    model_path = os.path.join(model_save_dir, f'model_resnet_lr{learning_rate}_fold{fold}.keras')\n",
    "    model = load_model(model_path)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "    # === Metrics per fold ===\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auprc = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    f1s.append(f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    auprcs.append(auprc)\n",
    "\n",
    "    print(f\"🔹 F1 Score:  {f1:.4f}\")\n",
    "    print(f\"🔹 Precision: {precision:.4f}\")\n",
    "    print(f\"🔹 Recall:    {recall:.4f}\")\n",
    "    print(f\"🔹 AUC-PR:    {auprc:.4f}\")\n",
    "\n",
    "    # === Confusion Matrix ===\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "    plt.title(f\"Confusion Matrix - Fold {fold}\")\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Plot Accuracy ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(num_folds):\n",
    "    plt.plot(val_accuracies[i], label=f'Fold {i+1} Val Acc')\n",
    "    plt.plot(train_accuracies[i], linestyle='--', label=f'Fold {i+1} Train Acc')\n",
    "plt.title(f'Accuracy (LR={learning_rate})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# === Plot Loss ===\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(num_folds):\n",
    "    plt.plot(val_losses[i], label=f'Fold {i+1} Val Loss')\n",
    "    plt.plot(train_losses[i], linestyle='--', label=f'Fold {i+1} Train Loss')\n",
    "plt.title(f'Loss (LR={learning_rate})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle(f\"Training Curves for LR = {learning_rate}\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# === Print Average Test Metrics ===\n",
    "print(f\"\\n📊 Average Test Set Metrics for LR = {learning_rate}\")\n",
    "print(f\"🔹 F1 Score:  {np.mean(f1s):.4f}\")\n",
    "print(f\"🔹 Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"🔹 Recall:    {np.mean(recalls):.4f}\")\n",
    "print(f\"🔹 AUC-PR:    {np.mean(auprcs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-5 with more patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_BestResNet'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_BestResNet'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Learning rates to test\n",
    "learning_rates = [1e-5]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the ResNet50 model\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze base ResNet layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {lr: {'accuracy': [], 'f1_score': []} for lr in learning_rates}\n",
    "\n",
    "# Cross-validation loop\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTesting Learning Rate: {lr}\")\n",
    "    for val_fold_index in range(5):\n",
    "        print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "        \n",
    "        train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "        val_fold = fold_dirs[val_fold_index]\n",
    "        \n",
    "        # Load training data\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in train_folds:\n",
    "            images, labels = load_images_and_labels(train_fold)\n",
    "            X_train.append(images)\n",
    "            y_train.append(labels)\n",
    "        X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "        \n",
    "        # Load validation data\n",
    "        X_val, y_val = load_images_and_labels(val_fold)\n",
    "        \n",
    "        # Train the model\n",
    "        model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-7),\n",
    "            ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold{val_fold_index + 1}.keras'), save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=150,  \n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Save history\n",
    "        history_path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold{val_fold_index + 1}.pkl')\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_preds = model.predict(X_val) > 0.5\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "        val_accuracy = np.mean(val_preds.flatten() == y_val)\n",
    "        \n",
    "        results[lr]['accuracy'].append(val_accuracy * 100)\n",
    "        results[lr]['f1_score'].append(val_f1)\n",
    "        \n",
    "        print(f\"Fold {val_fold_index + 1} - Accuracy: {val_accuracy:.2%}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # Free up memory after each fold\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "# Compute average accuracy and F1-score per learning rate\n",
    "avg_results = {lr: {'accuracy': np.mean(results[lr]['accuracy']), 'f1_score': np.mean(results[lr]['f1_score'])} for lr in learning_rates}\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, [avg_results[lr]['accuracy'] for lr in learning_rates], marker='o', label='Accuracy (%)')\n",
    "plt.plot(learning_rates, [avg_results[lr]['f1_score'] for lr in learning_rates], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Learning Rate vs Performance - ResNet50')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller learning rates and more epochs 1e-6 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsBest2Minus6Resnet'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesBest2Minus6Resnet'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Learning rates to test\n",
    "learning_rates = [6e-5, 1e-6]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the ResNet50 model\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze base ResNet layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {lr: {'accuracy': [], 'f1_score': []} for lr in learning_rates}\n",
    "\n",
    "# Cross-validation loop\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTesting Learning Rate: {lr}\")\n",
    "    for val_fold_index in range(5):\n",
    "        print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "        \n",
    "        train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "        val_fold = fold_dirs[val_fold_index]\n",
    "        \n",
    "        # Load training data\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in train_folds:\n",
    "            images, labels = load_images_and_labels(train_fold)\n",
    "            X_train.append(images)\n",
    "            y_train.append(labels)\n",
    "        X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "        \n",
    "        # Load validation data\n",
    "        X_val, y_val = load_images_and_labels(val_fold)\n",
    "        \n",
    "        # Train the model\n",
    "        model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-7),\n",
    "            ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold{val_fold_index + 1}.keras'), save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=150,  \n",
    "            batch_size=64,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Save history\n",
    "        history_path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold{val_fold_index + 1}.pkl')\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_preds = model.predict(X_val) > 0.5\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "        val_accuracy = np.mean(val_preds.flatten() == y_val)\n",
    "        \n",
    "        results[lr]['accuracy'].append(val_accuracy * 100)\n",
    "        results[lr]['f1_score'].append(val_f1)\n",
    "        \n",
    "        print(f\"Fold {val_fold_index + 1} - Accuracy: {val_accuracy:.2%}, F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "        # Free up memory after each fold\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "# Compute average accuracy and F1-score per learning rate\n",
    "avg_results = {lr: {'accuracy': np.mean(results[lr]['accuracy']), 'f1_score': np.mean(results[lr]['f1_score'])} for lr in learning_rates}\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, [avg_results[lr]['accuracy'] for lr in learning_rates], marker='o', label='Accuracy (%)')\n",
    "plt.plot(learning_rates, [avg_results[lr]['f1_score'] for lr in learning_rates], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Learning Rate vs Performance - ResNet50')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze 6e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "learning_rate = 6e-5\n",
    "num_folds = 5\n",
    "\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsBest2Minus6Resnet'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesBest2Minus6Resnet'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Load test data ===\n",
    "def load_test_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        class_path = os.path.join(image_dir, subdir)\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(class_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                path = os.path.join(class_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "                paths.append(path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, test_paths = load_test_images_and_labels(test_image_dir)\n",
    "\n",
    "# === Plot histories and test metrics ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "val_accuracies, val_losses, train_accuracies, train_losses = [], [], [], []\n",
    "\n",
    "print(f\"\\n🔍 Results for Learning Rate = {learning_rate}\")\n",
    "f1s, precisions, recalls, auprcs = [], [], [], []\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    # === Load history ===\n",
    "    history_path = os.path.join(history_save_dir, f'history_resnet_lr{learning_rate}_fold{fold}.pkl')\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    train_acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # === Load model and predict on test set ===\n",
    "    model_path = os.path.join(model_save_dir, f'model_resnet_lr{learning_rate}_fold{fold}.keras')\n",
    "    model = load_model(model_path)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    auprcs.append(average_precision_score(y_test, y_pred))\n",
    "\n",
    "# === Plot Accuracy ===\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(num_folds):\n",
    "    plt.plot(val_accuracies[i], label=f'Fold {i+1} Val Acc')\n",
    "    plt.plot(train_accuracies[i], linestyle='--', label=f'Fold {i+1} Train Acc')\n",
    "plt.title(f'Accuracy (LR={learning_rate})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# === Plot Loss ===\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(num_folds):\n",
    "    plt.plot(val_losses[i], label=f'Fold {i+1} Val Loss')\n",
    "    plt.plot(train_losses[i], linestyle='--', label=f'Fold {i+1} Train Loss')\n",
    "plt.title(f'Loss (LR={learning_rate})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle(f\"Training Curves for LR = {learning_rate}\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# === Print Test Metrics ===\n",
    "print(f\"🧪 Test Set Metrics (Average Across Folds) for LR = {learning_rate}:\")\n",
    "print(f\"🔹 F1 Score:  {np.mean(f1s):.4f}\")\n",
    "print(f\"🔹 Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"🔹 Recall:    {np.mean(recalls):.4f}\")\n",
    "print(f\"🔹 AUC-PR:    {np.mean(auprcs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do full run with MobileNetV2 with best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_Histories_MobileNet2_Stable'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the MobileNetV2 model\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Unfreeze the last 20 layers for fine-tuning\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:  \n",
    "        layer.trainable = False  \n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {'accuracy': [], 'f1_score': [], 'precision': [], 'recall': [], 'auc_pr': [], 'val_loss': []}\n",
    "\n",
    "# Cross-validation loop\n",
    "for val_fold_index in range(5):\n",
    "    print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "    \n",
    "    train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "    val_fold = fold_dirs[val_fold_index]\n",
    "    \n",
    "    # Load training data\n",
    "    X_train, y_train = [], []\n",
    "    for train_fold in train_folds:\n",
    "        images, labels = load_images_and_labels(train_fold)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "    \n",
    "    # Load validation data\n",
    "    X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "    # Adjust batch size for Fold 5 to prevent freezing\n",
    "    batch_size = 64 if val_fold_index != 4 else 32  \n",
    "\n",
    "    # Train the model\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),  # Increased patience\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6),  # Adjusted patience\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_mobilenet_fold{val_fold_index + 1}.keras'), save_best_only=True),\n",
    "        TerminateOnNaN(),  # Stop training if NaN loss is encountered\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  # Track training time\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time  # Compute elapsed time\n",
    "\n",
    "        # If training takes too long (e.g., > 2 hours), exit\n",
    "        if elapsed_time > 7200:\n",
    "            print(f\"Fold {val_fold_index + 1}: Training took too long (>2 hours). Stopping early.\")\n",
    "            break\n",
    "\n",
    "    except tf.errors.ResourceExhaustedError:\n",
    "        print(\"Resource exhausted error caught. Reducing batch size and restarting training.\")\n",
    "        batch_size = batch_size // 2\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "    \n",
    "    # Save history\n",
    "    history_path = os.path.join(history_save_dir, f'history_mobilenet_fold{val_fold_index + 1}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Compute final validation metrics\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    results['accuracy'].append(accuracy)\n",
    "    results['f1_score'].append(f1)\n",
    "    results['precision'].append(precision)\n",
    "    results['recall'].append(recall)\n",
    "    results['auc_pr'].append(auc_pr)\n",
    "    results['val_loss'].append(min(history.history['val_loss']))\n",
    "\n",
    "    print(f\"Fold {val_fold_index + 1} Results: Accuracy={accuracy:.4f}, F1={f1:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, AUC-PR={auc_pr:.4f}\")\n",
    "\n",
    "    # Free up memory\n",
    "    del model, X_train, y_train, X_val, y_val\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Save results\n",
    "df_results.to_csv(os.path.join(history_save_dir, \"training_results.csv\"), index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n### Final Results Per Fold ###\")\n",
    "print(df_results)\n",
    "\n",
    "# Compute and print averages\n",
    "print(f\"\\nAverage Accuracy: {df_results['accuracy'].mean():.4f}\")\n",
    "print(f\"Average F1 Score: {df_results['f1_score'].mean():.4f}\")\n",
    "print(f\"Average Precision: {df_results['precision'].mean():.4f}\")\n",
    "print(f\"Average Recall: {df_results['recall'].mean():.4f}\")\n",
    "print(f\"Average AUC-PR: {df_results['auc_pr'].mean():.4f}\")\n",
    "print(f\"Average Validation Loss: {df_results['val_loss'].mean():.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "num_folds = 5\n",
    "\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_Histories_MobileNet2_Stable'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Load test data ===\n",
    "def load_test_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        class_path = os.path.join(image_dir, subdir)\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(class_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                path = os.path.join(class_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "                paths.append(path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, test_paths = load_test_images_and_labels(test_image_dir)\n",
    "\n",
    "# === Plot histories and test metrics ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "val_accuracies, val_losses, train_accuracies, train_losses = [], [], [], []\n",
    "f1s, precisions, recalls, auprcs = [], [], [], []\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    # === Load history ===\n",
    "    history_path = os.path.join(history_save_dir, f'history_mobilenet_fold{fold}.pkl')\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    train_accuracies.append(history['accuracy'])\n",
    "    val_accuracies.append(history['val_accuracy'])\n",
    "    train_losses.append(history['loss'])\n",
    "    val_losses.append(history['val_loss'])\n",
    "\n",
    "    # === Load model and predict on test set ===\n",
    "    model_path = os.path.join(model_save_dir, f'model_mobilenet_fold{fold}.keras')\n",
    "    model = load_model(model_path)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    auprcs.append(average_precision_score(y_test, y_pred))\n",
    "\n",
    "# === Plot Accuracy ===\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(num_folds):\n",
    "    plt.plot(val_accuracies[i], label=f'Fold {i+1} Val Acc')\n",
    "    plt.plot(train_accuracies[i], linestyle='--', label=f'Fold {i+1} Train Acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# === Plot Loss ===\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(num_folds):\n",
    "    plt.plot(val_losses[i], label=f'Fold {i+1} Val Loss')\n",
    "    plt.plot(train_losses[i], linestyle='--', label=f'Fold {i+1} Train Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle(\"Training Curves - MobileNetV2 (All Folds)\")\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# === Print Test Metrics ===\n",
    "print(f\"\\n🧪 Test Set Metrics (Average Across Folds):\")\n",
    "print(f\"🔹 F1 Score:  {np.mean(f1s):.4f}\")\n",
    "print(f\"🔹 Precision: {np.mean(precisions):.4f}\")\n",
    "print(f\"🔹 Recall:    {np.mean(recalls):.4f}\")\n",
    "print(f\"🔹 AUC-PR:    {np.mean(auprcs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with MobileNetV2 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Experiments_MobileNet'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories_MobileNet'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Learning rates to test\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the MobileNetV2 model\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Unfreeze the last 20 layers for fine-tuning\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:  \n",
    "        layer.trainable = False  \n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)  \n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Learning rate warm-up function\n",
    "def lr_warmup(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return 5e-4  # Start with a higher LR for the first few epochs\n",
    "    return lr\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {lr: {'accuracy': [], 'f1_score': [], 'precision': [], 'recall': [], 'auc_pr': [], 'val_loss': []} for lr in learning_rates}\n",
    "\n",
    "# Cross-validation loop\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTesting Learning Rate: {lr}\")\n",
    "    for val_fold_index in range(5):\n",
    "        print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "        \n",
    "        train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "        val_fold = fold_dirs[val_fold_index]\n",
    "        \n",
    "        # Load training data\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in train_folds:\n",
    "            images, labels = load_images_and_labels(train_fold)\n",
    "            X_train.append(images)\n",
    "            y_train.append(labels)\n",
    "        X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "        \n",
    "        # Load validation data\n",
    "        X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "        # Adjust batch size for Fold 5 to prevent freezing\n",
    "        batch_size = 64 if val_fold_index != 4 else 32  # Reduce batch size only for fold 5\n",
    "\n",
    "        # Train the model\n",
    "        model = create_mobilenetv2_model(X_train.shape[1:], lr)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7),\n",
    "            ModelCheckpoint(os.path.join(model_save_dir, f'model_mobilenet_lr{lr}_fold{val_fold_index + 1}.keras'), save_best_only=True),\n",
    "            LearningRateScheduler(lr_warmup)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,  \n",
    "            batch_size=batch_size,  \n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Save history\n",
    "        history_path = os.path.join(history_save_dir, f'history_mobilenet_lr{lr}_fold{val_fold_index + 1}.pkl')\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_probs = model.predict(X_val)\n",
    "        val_preds = (val_probs > 0.5).astype(int)  \n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "        val_precision = precision_score(y_val, val_preds)\n",
    "        val_recall = recall_score(y_val, val_preds)\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_val, val_probs)\n",
    "        val_auc_pr = auc(recall_vals, precision_vals)\n",
    "        min_val_loss = min(history.history['val_loss']) if 'val_loss' in history.history else None\n",
    "\n",
    "        # Store results\n",
    "        results[lr]['accuracy'].append(np.mean(val_preds.flatten() == y_val) * 100)\n",
    "        results[lr]['f1_score'].append(val_f1)\n",
    "        results[lr]['precision'].append(val_precision)\n",
    "        results[lr]['recall'].append(val_recall)\n",
    "        results[lr]['auc_pr'].append(val_auc_pr)\n",
    "        results[lr]['val_loss'].append(min_val_loss)\n",
    "\n",
    "        print(f\"Fold {val_fold_index + 1} - Accuracy: {results[lr]['accuracy'][-1]:.2f}%, F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, AUC-PR: {val_auc_pr:.4f}, Val Loss: {min_val_loss}\")\n",
    "\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "df_avg_results = pd.DataFrame.from_dict({lr: {metric: np.mean(results[lr][metric]) for metric in results[lr]} for lr in learning_rates}, orient='index')\n",
    "df_avg_results.to_csv(os.path.join(history_save_dir, \"mobilenet_learning_rate_results.csv\"))\n",
    "print(f\"Results saved to {os.path.join(history_save_dir, 'mobilenet_learning_rate_results.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze MobilNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# === Settings ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories_MobileNet'\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "num_folds = 5\n",
    "\n",
    "# === Containers ===\n",
    "avg_train_acc = {}\n",
    "avg_val_acc = {}\n",
    "avg_train_loss = {}\n",
    "avg_val_loss = {}\n",
    "\n",
    "# === Pad histories to max length ===\n",
    "def pad_histories(histories):\n",
    "    max_len = max(len(h) for h in histories)\n",
    "    padded = np.array([h + [np.nan] * (max_len - len(h)) for h in histories])\n",
    "    return padded\n",
    "\n",
    "# === Load and process histories ===\n",
    "for lr in learning_rates:\n",
    "    lr_str = f\"{lr:.5f}\".rstrip('0').rstrip('.') if lr >= 1e-4 else f\"{lr:.0e}\".replace('E', 'e')\n",
    "\n",
    "    train_acc_all, val_acc_all = [], []\n",
    "    train_loss_all, val_loss_all = [], []\n",
    "\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        filename = f'history_mobilenet_lr{lr_str}_fold{fold}.pkl'\n",
    "        filepath = os.path.join(history_save_dir, filename)\n",
    "\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "\n",
    "            if all(k in history for k in ['accuracy', 'val_accuracy', 'loss', 'val_loss']):\n",
    "                train_acc_all.append(history['accuracy'])\n",
    "                val_acc_all.append(history['val_accuracy'])\n",
    "                train_loss_all.append(history['loss'])\n",
    "                val_loss_all.append(history['val_loss'])\n",
    "        else:\n",
    "            print(f\"❌ Missing: {filename}\")\n",
    "\n",
    "    if train_acc_all:\n",
    "        avg_train_acc[lr_str] = np.nanmean(pad_histories(train_acc_all), axis=0)\n",
    "        avg_val_acc[lr_str] = np.nanmean(pad_histories(val_acc_all), axis=0)\n",
    "        avg_train_loss[lr_str] = np.nanmean(pad_histories(train_loss_all), axis=0)\n",
    "        avg_val_loss[lr_str] = np.nanmean(pad_histories(val_loss_all), axis=0)\n",
    "        print(f\"✅ Loaded LR={lr_str}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No history data found for LR={lr_str}\")\n",
    "\n",
    "# === Plot Accuracy and Loss with Unique Colors per LR ===\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "cmap = get_cmap(\"tab10\")  # or 'Set1', 'tab20'\n",
    "\n",
    "# --- Accuracy ---\n",
    "for idx, lr_str in enumerate(avg_train_acc):\n",
    "    color = cmap(idx % 10)\n",
    "    axs[0].plot(avg_train_acc[lr_str], linestyle='--', color=color, label=f'Train LR={lr_str}')\n",
    "    axs[0].plot(avg_val_acc[lr_str], linestyle='-', color=color, label=f'Val LR={lr_str}')\n",
    "axs[0].set_title('Training and Validation Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].grid(True)\n",
    "axs[0].legend()\n",
    "\n",
    "# --- Loss ---\n",
    "for idx, lr_str in enumerate(avg_train_loss):\n",
    "    color = cmap(idx % 10)\n",
    "    axs[1].plot(avg_train_loss[lr_str], linestyle='--', color=color, label=f'Train LR={lr_str}')\n",
    "    axs[1].plot(avg_val_loss[lr_str], linestyle='-', color=color, label=f'Val LR={lr_str}')\n",
    "axs[1].set_title('Training and Validation Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].grid(True)\n",
    "axs[1].legend()\n",
    "\n",
    "fig.suptitle('MobileNetV2 - Accuracy & Loss per Epoch by Learning Rate', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Experiments_MobileNet'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories_MobileNet'\n",
    "\n",
    "# Learning rates tested\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "num_folds = 5  # Number of folds used in cross-validation\n",
    "\n",
    "# Function to load validation images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Dictionaries to store computed metrics\n",
    "metrics = ['f1_score', 'precision', 'recall', 'auc', 'val_loss']\n",
    "mobilenetv2_results = {metric: {lr: [] for lr in learning_rates} for metric in metrics}\n",
    "\n",
    "# Loop through learning rates and folds\n",
    "for lr in learning_rates:\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        model_path = os.path.join(model_save_dir, f'model_mobilenet_lr{lr}_fold{fold}.keras')\n",
    "        history_path = os.path.join(history_save_dir, f'history_mobilenet_lr{lr}_fold{fold}.pkl')\n",
    "        val_fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading MobileNetV2 model for LR={lr}, Fold={fold}...\")\n",
    "            model = load_model(model_path)  # Load saved model\n",
    "            \n",
    "            # Load validation data\n",
    "            X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "            if len(X_val) == 0:\n",
    "                print(f\"Warning: No validation images found for LR={lr}, Fold={fold}\")\n",
    "                continue\n",
    "            \n",
    "            # Compute predictions\n",
    "            val_probs = model.predict(X_val)\n",
    "            val_preds = (val_probs > 0.5).astype(int)  # Convert probabilities to binary\n",
    "            \n",
    "            # Compute metrics\n",
    "            val_f1 = f1_score(y_val, val_preds)\n",
    "            val_precision = precision_score(y_val, val_preds)\n",
    "            val_recall = recall_score(y_val, val_preds)\n",
    "            val_auc = roc_auc_score(y_val, val_probs)  # Use probabilities for AUC\n",
    "            \n",
    "            mobilenetv2_results['f1_score'][lr].append(val_f1)\n",
    "            mobilenetv2_results['precision'][lr].append(val_precision)\n",
    "            mobilenetv2_results['recall'][lr].append(val_recall)\n",
    "            mobilenetv2_results['auc'][lr].append(val_auc)\n",
    "            \n",
    "            print(f\"Fold {fold} - F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, AUC: {val_auc:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Model not found for LR={lr}, Fold={fold}\")\n",
    "\n",
    "        # Load Validation Loss from History File\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "\n",
    "            # Get best (minimum) validation loss\n",
    "            if 'val_loss' in history:\n",
    "                min_val_loss = min(history['val_loss'])\n",
    "                mobilenetv2_results['val_loss'][lr].append(min_val_loss)\n",
    "            else:\n",
    "                print(f\"Warning: val_loss missing for LR={lr}, Fold={fold}\")\n",
    "                mobilenetv2_results['val_loss'][lr].append(None)\n",
    "        else:\n",
    "            print(f\"Warning: History file not found for LR={lr}, Fold={fold}\")\n",
    "            mobilenetv2_results['val_loss'][lr].append(None)\n",
    "\n",
    "# Compute the average metrics per learning rate\n",
    "avg_mobilenetv2_metrics = {\n",
    "    metric: {lr: np.mean(mobilenetv2_results[metric][lr]) if len(mobilenetv2_results[metric][lr]) > 0 else None for lr in learning_rates}\n",
    "    for metric in metrics\n",
    "}\n",
    "\n",
    "# Plot all metrics in one graph\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot F1 Score, Precision, Recall, and AUC\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Performance Metrics')\n",
    "\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['f1_score'][lr] for lr in learning_rates], marker='o', linestyle='-', color='g', label='F1 Score')\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['precision'][lr] for lr in learning_rates], marker='s', linestyle='-', color='r', label='Precision')\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['recall'][lr] for lr in learning_rates], marker='D', linestyle='-', color='orange', label='Recall')\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['auc'][lr] for lr in learning_rates], marker='^', linestyle='-', color='purple', label='AUC')\n",
    "\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Twin axis for Validation Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='b')\n",
    "ax2.plot(learning_rates, [avg_mobilenetv2_metrics['val_loss'][lr] for lr in learning_rates], marker='x', linestyle='--', color='b', label='Validation Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Title and Legend\n",
    "fig.suptitle('MobileNetV2 Learning Rate Performance Metrics')\n",
    "fig.tight_layout()\n",
    "fig.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, average_precision_score\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Experiments_MobileNet'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories_MobileNet'\n",
    "\n",
    "# Learning rates tested\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "num_folds = 5  # Number of folds used in cross-validation\n",
    "\n",
    "# Function to load validation images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Dictionaries to store computed metrics\n",
    "metrics = ['f1_score', 'precision', 'recall', 'pr_auc', 'val_loss']\n",
    "mobilenetv2_results = {metric: {lr: [] for lr in learning_rates} for metric in metrics}\n",
    "\n",
    "# Loop through learning rates and folds\n",
    "for lr in learning_rates:\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        model_path = os.path.join(model_save_dir, f'model_mobilenet_lr{lr}_fold{fold}.keras')\n",
    "        history_path = os.path.join(history_save_dir, f'history_mobilenet_lr{lr}_fold{fold}.pkl')\n",
    "        val_fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading MobileNetV2 model for LR={lr}, Fold={fold}...\")\n",
    "            model = load_model(model_path)  # Load saved model\n",
    "            \n",
    "            # Load validation data\n",
    "            X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "            if len(X_val) == 0:\n",
    "                print(f\"Warning: No validation images found for LR={lr}, Fold={fold}\")\n",
    "                continue\n",
    "            \n",
    "            # Compute predictions\n",
    "            val_probs = model.predict(X_val)\n",
    "            val_preds = (val_probs > 0.5).astype(int)  # Convert probabilities to binary\n",
    "            \n",
    "            # Compute metrics\n",
    "            val_f1 = f1_score(y_val, val_preds)\n",
    "            val_precision = precision_score(y_val, val_preds)\n",
    "            val_recall = recall_score(y_val, val_preds)\n",
    "            val_pr_auc = average_precision_score(y_val, val_probs)  # Precision-Recall AUC\n",
    "            \n",
    "            mobilenetv2_results['f1_score'][lr].append(val_f1)\n",
    "            mobilenetv2_results['precision'][lr].append(val_precision)\n",
    "            mobilenetv2_results['recall'][lr].append(val_recall)\n",
    "            mobilenetv2_results['pr_auc'][lr].append(val_pr_auc)\n",
    "            \n",
    "            print(f\"Fold {fold} - F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, PR AUC: {val_pr_auc:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Model not found for LR={lr}, Fold={fold}\")\n",
    "\n",
    "        # Load Validation Loss from History File\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'rb') as f:\n",
    "                history = pickle.load(f)\n",
    "\n",
    "            # Get best (minimum) validation loss\n",
    "            if 'val_loss' in history:\n",
    "                min_val_loss = min(history['val_loss'])\n",
    "                mobilenetv2_results['val_loss'][lr].append(min_val_loss)\n",
    "            else:\n",
    "                print(f\"Warning: val_loss missing for LR={lr}, Fold={fold}\")\n",
    "                mobilenetv2_results['val_loss'][lr].append(None)\n",
    "        else:\n",
    "            print(f\"Warning: History file not found for LR={lr}, Fold={fold}\")\n",
    "            mobilenetv2_results['val_loss'][lr].append(None)\n",
    "\n",
    "# Compute the average metrics per learning rate\n",
    "avg_mobilenetv2_metrics = {\n",
    "    metric: {lr: np.mean(mobilenetv2_results[metric][lr]) if len(mobilenetv2_results[metric][lr]) > 0 else None for lr in learning_rates}\n",
    "    for metric in metrics\n",
    "}\n",
    "\n",
    "# Plot all metrics in one graph\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot F1 Score, Precision, Recall, and PR AUC\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Performance Metrics')\n",
    "\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['f1_score'][lr] for lr in learning_rates], marker='o', linestyle='-', color='g', label='F1 Score')\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['precision'][lr] for lr in learning_rates], marker='s', linestyle='-', color='r', label='Precision')\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['recall'][lr] for lr in learning_rates], marker='D', linestyle='-', color='orange', label='Recall')\n",
    "ax1.plot(learning_rates, [avg_mobilenetv2_metrics['pr_auc'][lr] for lr in learning_rates], marker='^', linestyle='-', color='purple', label='PR AUC')\n",
    "\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Twin axis for Validation Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='b')\n",
    "ax2.plot(learning_rates, [avg_mobilenetv2_metrics['val_loss'][lr] for lr in learning_rates], marker='x', linestyle='--', color='b', label='Validation Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Title and Legend\n",
    "fig.suptitle('MobileNetV2 Learning Rate Performance Metrics')\n",
    "fig.tight_layout()\n",
    "fig.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze metrics of full run one learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_Histories_MobileNet'\n",
    "\n",
    "num_folds = 5  # Number of folds used in cross-validation\n",
    "\n",
    "# Function to load validation images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Dictionary to store computed metrics\n",
    "metrics = ['f1_score', 'precision', 'recall', 'accuracy', 'val_loss']\n",
    "mobilenet_results = {metric: [] for metric in metrics}\n",
    "\n",
    "# Loop through folds\n",
    "for fold in range(1, num_folds + 1):\n",
    "    model_path = os.path.join(model_save_dir, f'model_mobilenet_fold{fold}.keras')\n",
    "    history_path = os.path.join(history_save_dir, f'history_mobilenet_fold{fold}.pkl')\n",
    "    val_fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading model for Fold {fold}...\")\n",
    "        model = load_model(model_path)  # Load saved model\n",
    "        \n",
    "        # Load validation data\n",
    "        X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "        if len(X_val) == 0:\n",
    "            print(f\"Warning: No validation images found for Fold {fold}\")\n",
    "            continue\n",
    "        \n",
    "        # Compute predictions\n",
    "        val_probs = model.predict(X_val)\n",
    "        val_preds = (val_probs > 0.5).astype(int)  # Convert probabilities to binary\n",
    "        \n",
    "        # Compute metrics\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "        val_precision = precision_score(y_val, val_preds)\n",
    "        val_recall = recall_score(y_val, val_preds)\n",
    "        val_accuracy = (val_preds == y_val).mean()  # Accuracy\n",
    "\n",
    "        mobilenet_results['f1_score'].append(val_f1)\n",
    "        mobilenet_results['precision'].append(val_precision)\n",
    "        mobilenet_results['recall'].append(val_recall)\n",
    "        mobilenet_results['accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold} - F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: Model not found for Fold {fold}\")\n",
    "\n",
    "    # Load Validation Loss from History File\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "\n",
    "        # Get best (minimum) validation loss\n",
    "        if 'val_loss' in history:\n",
    "            min_val_loss = min(history['val_loss'])\n",
    "            mobilenet_results['val_loss'].append(min_val_loss)\n",
    "        else:\n",
    "            print(f\"Warning: val_loss missing for Fold {fold}\")\n",
    "            mobilenet_results['val_loss'].append(None)\n",
    "    else:\n",
    "        print(f\"Warning: History file not found for Fold {fold}\")\n",
    "        mobilenet_results['val_loss'].append(None)\n",
    "\n",
    "# Compute the average metrics across folds\n",
    "avg_mobilenet_metrics = {\n",
    "    metric: np.mean(mobilenet_results[metric]) if len(mobilenet_results[metric]) > 0 else None\n",
    "    for metric in metrics\n",
    "}\n",
    "\n",
    "# Print results\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame.from_dict(mobilenet_results)\n",
    "df_results.loc['Average'] = df_results.mean()\n",
    "\n",
    "print(\"\\nFinal Results Across All Folds:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take 2 best learning rates and more patience DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Experiments_MobileNetBest2'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories_MobileNetBest2'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Learning rates to test\n",
    "learning_rates = [1e-3, 1e-2]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the MobileNetV2 model\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Unfreeze the last 20 layers for fine-tuning\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:  \n",
    "        layer.trainable = False  \n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)  # Reduced from 256 to 128\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)  # Lowered dropout slightly\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Learning rate warm-up function\n",
    "def lr_warmup(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return 5e-4  # Start with a higher LR for the first few epochs\n",
    "    return lr\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {lr: {'accuracy': [], 'f1_score': [], 'precision': [], 'recall': [], 'auc_pr': [], 'val_loss': []} for lr in learning_rates}\n",
    "\n",
    "# Cross-validation loop\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTesting Learning Rate: {lr}\")\n",
    "    for val_fold_index in range(5):\n",
    "        print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "        \n",
    "        train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "        val_fold = fold_dirs[val_fold_index]\n",
    "        \n",
    "        # Load training data\n",
    "        X_train, y_train = [], []\n",
    "        for train_fold in train_folds:\n",
    "            images, labels = load_images_and_labels(train_fold)\n",
    "            X_train.append(images)\n",
    "            y_train.append(labels)\n",
    "        X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "        \n",
    "        # Load validation data\n",
    "        X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "        # Adjust batch size for Fold 5 to prevent freezing\n",
    "        batch_size = 64 if val_fold_index != 4 else 32  # Reduce batch size only for fold 5\n",
    "\n",
    "        # Train the model\n",
    "        model = create_mobilenetv2_model(X_train.shape[1:], lr)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7),\n",
    "            ModelCheckpoint(os.path.join(model_save_dir, f'model_mobilenet_lr{lr}_fold{val_fold_index + 1}.keras'), save_best_only=True),\n",
    "            LearningRateScheduler(lr_warmup)\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,  # Lowered from 30 to prevent stalling\n",
    "            batch_size=batch_size,  \n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Save history\n",
    "        history_path = os.path.join(history_save_dir, f'history_mobilenet_lr{lr}_fold{val_fold_index + 1}.pkl')\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_probs = model.predict(X_val)\n",
    "        val_preds = (val_probs > 0.5).astype(int)  \n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        val_f1 = f1_score(y_val, val_preds)\n",
    "        val_precision = precision_score(y_val, val_preds)\n",
    "        val_recall = recall_score(y_val, val_preds)\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_val, val_probs)\n",
    "        val_auc_pr = auc(recall_vals, precision_vals)\n",
    "        min_val_loss = min(history.history['val_loss']) if 'val_loss' in history.history else None\n",
    "\n",
    "        # Store results\n",
    "        results[lr]['accuracy'].append(np.mean(val_preds.flatten() == y_val) * 100)\n",
    "        results[lr]['f1_score'].append(val_f1)\n",
    "        results[lr]['precision'].append(val_precision)\n",
    "        results[lr]['recall'].append(val_recall)\n",
    "        results[lr]['auc_pr'].append(val_auc_pr)\n",
    "        results[lr]['val_loss'].append(min_val_loss)\n",
    "\n",
    "        print(f\"Fold {val_fold_index + 1} - Accuracy: {results[lr]['accuracy'][-1]:.2f}%, F1 Score: {val_f1:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, AUC-PR: {val_auc_pr:.4f}, Val Loss: {min_val_loss}\")\n",
    "\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "df_avg_results = pd.DataFrame.from_dict({lr: {metric: np.mean(results[lr][metric]) for metric in results[lr]} for lr in learning_rates}, orient='index')\n",
    "df_avg_results.to_csv(os.path.join(history_save_dir, \"mobilenet_learning_rate_results.csv\"))\n",
    "print(f\"Results saved to {os.path.join(history_save_dir, 'mobilenet_learning_rate_results.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === CONFIG ===\n",
    "lr_to_plot = 1e-3\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_Histories_MobileNetBest2'\n",
    "num_folds = 5\n",
    "\n",
    "# === INIT PLOT STORAGE ===\n",
    "val_accuracies, train_accuracies = [], []\n",
    "val_losses, train_losses = [], []\n",
    "\n",
    "# === PLOT TRAINING CURVES ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    history_file = os.path.join(history_save_dir, f'history_mobilenet_lr{lr_to_plot}_fold{fold}.pkl')\n",
    "    if not os.path.exists(history_file):\n",
    "        print(f\"⚠️ Missing history file for Fold {fold} at LR {lr_to_plot}\")\n",
    "        continue\n",
    "\n",
    "    with open(history_file, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    train_acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # === Accuracy Plot ===\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_acc, linestyle='--', label=f'Fold {fold} Train Acc')\n",
    "    plt.plot(val_acc, label=f'Fold {fold} Val Acc')\n",
    "\n",
    "    # === Loss Plot ===\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_loss, linestyle='--', label=f'Fold {fold} Train Loss')\n",
    "    plt.plot(val_loss, label=f'Fold {fold} Val Loss')\n",
    "\n",
    "# === Finalize Accuracy Plot ===\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(f'Training vs Validation Accuracy (LR={lr_to_plot})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# === Finalize Loss Plot ===\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(f'Training vs Validation Loss (LR={lr_to_plot})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f\"Training Curves for MobileNetV2 (LR = {lr_to_plot})\", fontsize=14, y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make patience with lr less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# Prevent TensorFlow from freezing\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_Histories_MobileNet2_Stable'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# Folds\n",
    "fold_dirs = [os.path.join(base_fold_dir, f'Fold{i}') for i in range(1, 6)]\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_image_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_image_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(full_image_dir):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_image_dir, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to create the MobileNetV2 model\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Unfreeze the last 20 layers for fine-tuning\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:  \n",
    "        layer.trainable = False  \n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dictionary to track performance\n",
    "results = {'accuracy': [], 'f1_score': [], 'precision': [], 'recall': [], 'auc_pr': [], 'val_loss': []}\n",
    "\n",
    "# Cross-validation loop\n",
    "for val_fold_index in range(5):\n",
    "    print(f\"\\nProcessing Fold {val_fold_index + 1} as Validation Set\")\n",
    "    \n",
    "    train_folds = [fold for i, fold in enumerate(fold_dirs) if i != val_fold_index]\n",
    "    val_fold = fold_dirs[val_fold_index]\n",
    "    \n",
    "    # Load training data\n",
    "    X_train, y_train = [], []\n",
    "    for train_fold in train_folds:\n",
    "        images, labels = load_images_and_labels(train_fold)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train, y_train = np.concatenate(X_train), np.concatenate(y_train)\n",
    "    \n",
    "    # Load validation data\n",
    "    X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "    # Adjust batch size for Fold 5 to prevent freezing\n",
    "    batch_size = 64 if val_fold_index != 4 else 32  \n",
    "\n",
    "    # Train the model\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),  # Increased patience\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-6),  # Adjusted patience\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_mobilenet_fold{val_fold_index + 1}.keras'), save_best_only=True),\n",
    "        TerminateOnNaN(),  # Stop training if NaN loss is encountered\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  # Track training time\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time  # Compute elapsed time\n",
    "\n",
    "        # If training takes too long (e.g., > 2 hours), exit\n",
    "        if elapsed_time > 7200:\n",
    "            print(f\"Fold {val_fold_index + 1}: Training took too long (>2 hours). Stopping early.\")\n",
    "            break\n",
    "\n",
    "    except tf.errors.ResourceExhaustedError:\n",
    "        print(\"Resource exhausted error caught. Reducing batch size and restarting training.\")\n",
    "        batch_size = batch_size // 2\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "    \n",
    "    # Save history\n",
    "    history_path = os.path.join(history_save_dir, f'history_mobilenet_fold{val_fold_index + 1}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Compute final validation metrics\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    results['accuracy'].append(accuracy)\n",
    "    results['f1_score'].append(f1)\n",
    "    results['precision'].append(precision)\n",
    "    results['recall'].append(recall)\n",
    "    results['auc_pr'].append(auc_pr)\n",
    "    results['val_loss'].append(min(history.history['val_loss']))\n",
    "\n",
    "    print(f\"Fold {val_fold_index + 1} Results: Accuracy={accuracy:.4f}, F1={f1:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, AUC-PR={auc_pr:.4f}\")\n",
    "\n",
    "    # Free up memory\n",
    "    del model, X_train, y_train, X_val, y_val\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Save results\n",
    "df_results.to_csv(os.path.join(history_save_dir, \"training_results.csv\"), index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n### Final Results Per Fold ###\")\n",
    "print(df_results)\n",
    "\n",
    "# Compute and print averages\n",
    "print(f\"\\nAverage Accuracy: {df_results['accuracy'].mean():.4f}\")\n",
    "print(f\"Average F1 Score: {df_results['f1_score'].mean():.4f}\")\n",
    "print(f\"Average Precision: {df_results['precision'].mean():.4f}\")\n",
    "print(f\"Average Recall: {df_results['recall'].mean():.4f}\")\n",
    "print(f\"Average AUC-PR: {df_results['auc_pr'].mean():.4f}\")\n",
    "print(f\"Average Validation Loss: {df_results['val_loss'].mean():.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === CONFIG ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_Histories_MobileNet2_Stable'\n",
    "num_folds = 5\n",
    "\n",
    "# === INIT PLOT STORAGE ===\n",
    "val_accuracies, train_accuracies = [], []\n",
    "val_losses, train_losses = [], []\n",
    "\n",
    "# === PLOT TRAINING CURVES ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for fold in range(1, num_folds + 1):\n",
    "    history_file = os.path.join(history_save_dir, f'history_mobilenet_fold{fold}.pkl')\n",
    "    if not os.path.exists(history_file):\n",
    "        print(f\"⚠️ Missing history file for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    with open(history_file, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    train_acc = history.get('accuracy', [])\n",
    "    val_acc = history.get('val_accuracy', [])\n",
    "    train_loss = history.get('loss', [])\n",
    "    val_loss = history.get('val_loss', [])\n",
    "\n",
    "    if not train_acc or not val_acc:\n",
    "        print(f\"⚠️ Empty history for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    # === Accuracy Plot ===\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_acc, linestyle='--', label=f'Fold {fold} Train Acc')\n",
    "    plt.plot(val_acc, label=f'Fold {fold} Val Acc')\n",
    "\n",
    "    # === Loss Plot ===\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_loss, linestyle='--', label=f'Fold {fold} Train Loss')\n",
    "    plt.plot(val_loss, label=f'Fold {fold} Val Loss')\n",
    "\n",
    "# === Finalize Accuracy Plot ===\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# === Finalize Loss Plot ===\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Training Curves for MobileNetV2 (Final Stable Run)\", fontsize=14, y=1.03)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === CONFIG ===\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "class_names = ['Bad', 'Good']  # Label 0 = Bad, 1 = Good\n",
    "\n",
    "# === Load Test Images and Labels ===\n",
    "def load_test_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in class_names:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "                paths.append(path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, test_paths = load_test_images_and_labels(test_image_dir)\n",
    "\n",
    "# === Loop Through Folds and Plot Confusion Matrices ===\n",
    "for fold in range(1, 6):\n",
    "    model_path = os.path.join(model_save_dir, f'model_mobilenet_fold{fold}.keras')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Generating Confusion Matrix for Fold {fold}\")\n",
    "    model = load_model(model_path)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "    # === Compute Confusion Matrix ===\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - Fold {fold}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === CONFIG ===\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable'\n",
    "test_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "class_names = ['Bad', 'Good']  # Label 0 = Bad, 1 = Good\n",
    "\n",
    "# === Load Test Images and Labels ===\n",
    "def load_test_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in class_names:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "                paths.append(path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, test_paths = load_test_images_and_labels(test_image_dir)\n",
    "\n",
    "# === Loop Through Folds and Plot Confusion Matrices ===\n",
    "for fold in range(1, 6):\n",
    "    model_path = os.path.join(model_save_dir, f'model_mobilenet_fold{fold}.keras')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Generating Confusion Matrix for Fold {fold}\")\n",
    "    model = load_model(model_path)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "\n",
    "    # === Compute Confusion Matrix ===\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - Fold {fold}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Loop Through Folds and Compute Metrics + Plot Confusion Matrix ===\n",
    "for fold in range(1, 6):\n",
    "    model_path = os.path.join(model_save_dir, f'model_mobilenet_fold{fold}.keras')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Evaluation for Fold {fold}\")\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    # === Print Metrics ===\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "\n",
    "    # === Confusion Matrix ===\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - Fold {fold}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable/model_mobilenet_fold1.keras'\n",
    "image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test/Good'  # or 'Bad'\n",
    "layer_names = ['block_16_project', 'block_13_expand']  # Example layers to visualize\n",
    "image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith('.jpg')][:4]\n",
    "\n",
    "# === Load model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Grad-CAM Function ===\n",
    "def get_gradcam_heatmap(img_array, model, layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# === Overlay Heatmap on Image ===\n",
    "def overlay_heatmap(original_img, heatmap, alpha=0.4):\n",
    "    heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))\n",
    "    heatmap_rgb = np.uint8(255 * plt.cm.jet(heatmap_resized)[:, :, :3])\n",
    "    overlayed = cv2.addWeighted(original_img.astype('uint8'), 1 - alpha, heatmap_rgb, alpha, 0)\n",
    "    return overlayed\n",
    "\n",
    "# === Visualize for each image and layer ===\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    input_tensor = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(layer_names) + 1, figsize=(14, 4))\n",
    "    axes[0].imshow(img_array)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for j, layer in enumerate(layer_names):\n",
    "        heatmap = get_gradcam_heatmap(input_tensor, model, layer)\n",
    "        overlayed_img = overlay_heatmap((img_array * 255).astype(np.uint8), heatmap)\n",
    "        axes[j + 1].imshow(overlayed_img)\n",
    "        axes[j + 1].set_title(f'Grad-CAM\\n{layer}')\n",
    "        axes[j + 1].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Grad-CAM Visualization for {os.path.basename(img_path)}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable/model_mobilenet_fold1.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Bad/JH1633_IMG_9233_saturation.jpg'\n",
    "target_size = (224, 224)\n",
    "last_conv_layer_name = 'Conv_1'  # Last conv layer in MobileNetV2\n",
    "\n",
    "# === LOAD MODEL AND IMAGE ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "img = load_img(image_path, target_size=target_size)\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# === BUILD MODEL FOR GRAD-CAM ===\n",
    "grad_model = tf.keras.models.Model(\n",
    "    [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    ")\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img_array)\n",
    "    pred_index = tf.argmax(predictions[0])\n",
    "    class_output = predictions[:, pred_index]\n",
    "\n",
    "# === GRADIENTS AND FEATURE MAP ===\n",
    "grads = tape.gradient(class_output, conv_outputs)\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "conv_outputs = conv_outputs[0]\n",
    "\n",
    "# === GENERATE HEATMAP ===\n",
    "heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "heatmap = tf.squeeze(heatmap)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= tf.math.reduce_max(heatmap) + 1e-8  # Normalize\n",
    "\n",
    "# === LOAD ORIGINAL IMAGE WITH CV2 ===\n",
    "img_cv = cv2.imread(image_path)\n",
    "img_cv = cv2.resize(img_cv, target_size)\n",
    "heatmap = cv2.resize(heatmap.numpy(), (img_cv.shape[1], img_cv.shape[0]))\n",
    "heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "overlay = cv2.addWeighted(img_cv, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "# === SHOW RESULT ===\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap, cmap='jet')\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Overlay\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/Final_MobileNet2_Stable/model_mobilenet_fold1.keras'\n",
    "image_paths = [\n",
    "    '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Bad/JH1633_IMG_9234_flip.jpg',\n",
    "    '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Bad/E21169_IMG_8680.jpg',\n",
    "    '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Good/E1686_IMG_8413.jpg',\n",
    "    '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Good/JH1657_IMG_9769_sharp.jpg'\n",
    "]\n",
    "target_size = (224, 224)\n",
    "last_conv_layer_name = 'Conv_1'\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === PLOT SETUP ===\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # === LOAD AND PREPROCESS IMAGE ===\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array_exp = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "    # === BUILD GRAD-CAM MODEL ===\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array_exp)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        class_output = predictions[:, pred_index]\n",
    "\n",
    "    # === COMPUTE GRAD-CAM ===\n",
    "    grads = tape.gradient(class_output, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= tf.math.reduce_max(heatmap) + 1e-8\n",
    "\n",
    "    # === COMBINE WITH ORIGINAL IMAGE ===\n",
    "    img_cv = cv2.imread(image_path)\n",
    "    img_cv = cv2.resize(img_cv, target_size)\n",
    "    heatmap_resized = cv2.resize(heatmap.numpy(), (img_cv.shape[1], img_cv.shape[0]))\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(img_cv, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "    # === SHOW OVERLAY IMAGE ONLY ===\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "print(\"YOLO is ready! 🚀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load YOLOv8s (small and fast)\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Your image path\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold3/Good/11?_IMG_8450_flip.jpg'\n",
    "\n",
    "# Load and convert image\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Run detection\n",
    "results = model(image_rgb)\n",
    "\n",
    "# Plot detection results\n",
    "results[0].plot()\n",
    "plt.imshow(image_rgb)\n",
    "plt.title(\"YOLO Detection Output\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detected classes\n",
    "for box in results[0].boxes:\n",
    "    class_id = int(box.cls.item())\n",
    "    class_name = results[0].names[class_id]\n",
    "    conf = box.conf.item()\n",
    "    print(f\"Detected: {class_name} (Confidence: {conf:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load model and image\n",
    "model = YOLO('yolov8s.pt')\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Good/E1686_IMG_8412_saturation.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Run detection\n",
    "results = model(image_rgb)\n",
    "\n",
    "# Filter to cows only\n",
    "boxes = results[0].boxes\n",
    "scores = boxes.conf.cpu().numpy()\n",
    "class_ids = boxes.cls.cpu().numpy()\n",
    "xyxy_boxes = boxes.xyxy.cpu().numpy()\n",
    "\n",
    "# Get class names\n",
    "names = results[0].names\n",
    "\n",
    "# Find cow with the largest area instead of highest score\n",
    "best_index = None\n",
    "largest_area = 0\n",
    "\n",
    "for i, class_id in enumerate(class_ids):\n",
    "    class_name = names[int(class_id)]\n",
    "    if class_name in ['cow', 'animal', 'bull', 'cattle']:  # adapt as needed\n",
    "        x1, y1, x2, y2 = map(int, xyxy_boxes[i])\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            best_index = i\n",
    "\n",
    "\n",
    "# Proceed if a cow was found\n",
    "if best_index is not None:\n",
    "    x1, y1, x2, y2 = map(int, xyxy_boxes[best_index])\n",
    "\n",
    "    # Remove bottom 30%\n",
    "    height = y2 - y1\n",
    "    y2 = y1 + int(height * 0.7)\n",
    "\n",
    "    cropped = image_rgb[y1:y2, x1:x2]\n",
    "\n",
    "    # Show and save\n",
    "    plt.imshow(cropped)\n",
    "    plt.title(\"Top Cow (No Legs)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    save_path = '/Users/suzetteschulenburg/Desktop/CroppedCow_Top1.jpg'\n",
    "    cv2.imwrite(save_path, cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"✅ Saved to: {save_path}\")\n",
    "else:\n",
    "    print(\"❌ No cow detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Convert image to bytes\n",
    "image_pil = Image.fromarray(image_rgb)\n",
    "buffered = io.BytesIO()\n",
    "image_pil.save(buffered, format=\"PNG\")\n",
    "img_bytes = buffered.getvalue()\n",
    "\n",
    "# Remove background\n",
    "output_bytes = remove(img_bytes)\n",
    "output_image = Image.open(io.BytesIO(output_bytes))\n",
    "\n",
    "# Show and save\n",
    "output_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Load image and YOLO model ===\n",
    "model = YOLO('yolov8s.pt')\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold4/Bad/DVV1510_IMG_0610_aug0.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Run YOLO Detection ===\n",
    "results = model(image_rgb)\n",
    "boxes = results[0].boxes\n",
    "scores = boxes.conf.cpu().numpy()\n",
    "class_ids = boxes.cls.cpu().numpy()\n",
    "xyxy_boxes = boxes.xyxy.cpu().numpy()\n",
    "names = results[0].names\n",
    "\n",
    "# === Select Largest Cow Only ===\n",
    "best_index = None\n",
    "largest_area = 0\n",
    "\n",
    "for i, class_id in enumerate(class_ids):\n",
    "    class_name = names[int(class_id)]\n",
    "    if class_name in ['cow', 'animal', 'bull', 'cattle']:\n",
    "        x1, y1, x2, y2 = map(int, xyxy_boxes[i])\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            best_index = i\n",
    "\n",
    "if best_index is not None:\n",
    "    # === Crop the cow with padding and leg removal ===\n",
    "    x1, y1, x2, y2 = map(int, xyxy_boxes[best_index])\n",
    "\n",
    "    h, w, _ = image_rgb.shape\n",
    "    margin = 0.1  # 10% margin\n",
    "    x1 = max(0, x1 - int((x2 - x1) * margin))\n",
    "    x2 = min(w, x2 + int((x2 - x1) * margin))\n",
    "    y2 = y1 + int((y2 - y1) * 0.7)  # remove bottom 30%\n",
    "\n",
    "    cropped = image_rgb[y1:y2, x1:x2]\n",
    "\n",
    "    # === Convert to PNG and remove background ===\n",
    "    image_pil = Image.fromarray(cropped)\n",
    "    buffered = io.BytesIO()\n",
    "    image_pil.save(buffered, format=\"PNG\")\n",
    "    img_bytes = buffered.getvalue()\n",
    "\n",
    "    output_bytes = remove(img_bytes)\n",
    "    output_image = Image.open(io.BytesIO(output_bytes))\n",
    "\n",
    "    # === Show and Save ===\n",
    "    output_image.show()\n",
    "    print(f\"✅ Saved cropped cow with background removed: {save_path}\")\n",
    "else:\n",
    "    print(\"❌ No main cow detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped cow and removed bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load YOLOv8 segmentation model\n",
    "model = YOLO('yolov8s-seg.pt')\n",
    "\n",
    "# Load and preprocess image\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Good/E1686_IMG_8412_saturation.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Run YOLO segmentation\n",
    "results = model(image_rgb)\n",
    "\n",
    "# Visualize detections\n",
    "results[0].plot()\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"YOLOv8 Segmentation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === Load model and image ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "image_path = \"/Users/suzetteschulenburg/Desktop/MainUse2/Fold4/Bad/DVV1510_IMG_0612_aug0.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_h, image_w = image_rgb.shape[:2]\n",
    "\n",
    "# === Run detection ===\n",
    "results = model(image_rgb)\n",
    "masks = results[0].masks\n",
    "boxes = results[0].boxes\n",
    "names = results[0].names\n",
    "\n",
    "if masks is not None and len(masks.data) > 0:\n",
    "    # Select the largest cow\n",
    "    best_index = None\n",
    "    largest_area = 0\n",
    "    for i, cls in enumerate(boxes.cls.cpu().numpy()):\n",
    "        class_name = names[int(cls)]\n",
    "        if class_name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "            x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "            area = (x2 - x1) * (y2 - y1)\n",
    "            if area > largest_area:\n",
    "                best_index = i\n",
    "                largest_area = area\n",
    "\n",
    "    if best_index is not None:\n",
    "        # === Resize mask to full image size ===\n",
    "        raw_mask = masks.data[best_index].cpu().numpy()\n",
    "        resized_mask = cv2.resize(raw_mask, (image_w, image_h), interpolation=cv2.INTER_NEAREST)\n",
    "        mask_3ch = np.stack([resized_mask] * 3, axis=-1)\n",
    "\n",
    "        # === Apply mask to original image ===\n",
    "        masked_image = np.where(mask_3ch > 0.5, image_rgb, 255)\n",
    "\n",
    "        # === Get and expand crop box ===\n",
    "        x1, y1, x2, y2 = map(int, boxes.xyxy[best_index].cpu().numpy())\n",
    "        margin = 0.1\n",
    "        x1 = max(0, x1 - int((x2 - x1) * margin))\n",
    "        x2 = min(image_w, x2 + int((x2 - x1) * margin))\n",
    "        y2 = y1 + int((y2 - y1) * 0.8)  # remove bottom 30%\n",
    "\n",
    "        final_crop = masked_image[y1:y2, x1:x2]\n",
    "\n",
    "        # === Show and save ===\n",
    "        plt.imshow(final_crop.astype(np.uint8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Main Cow – Segmented and Cropped\")\n",
    "        plt.show()\n",
    "\n",
    "        save_path = \"/Users/suzetteschulenburg/Desktop/CroppedCow_Seg_NoLegs_Fixed.png\"\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(final_crop.astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
    "        print(f\"✅ Saved to: {save_path}\")\n",
    "    else:\n",
    "        print(\"❌ No main cow found.\")\n",
    "else:\n",
    "    print(\"❌ No mask found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO and MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop and remove Background Resize and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# === Function to resize with padding ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "\n",
    "    # Create new image and center the resized image on it\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    color = [255, 255, 255]  # White background\n",
    "    new_im = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return new_im\n",
    "\n",
    "# === Load YOLO segmentation model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "# === Paths ===\n",
    "input_base = \"/Users/suzetteschulenburg/Desktop/MainUse2/Fold1\"\n",
    "output_base = \"/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# === Subfolders to process ===\n",
    "classes = ['Good', 'Bad']\n",
    "\n",
    "for cls in classes:\n",
    "    input_folder = os.path.join(input_base, cls)\n",
    "    output_folder = os.path.join(output_base, cls)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.endswith('.jpg'):\n",
    "            continue\n",
    "\n",
    "        # === Load image ===\n",
    "        image_path = os.path.join(input_folder, fname)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"⚠️ Could not read: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_h, image_w = image_rgb.shape[:2]\n",
    "\n",
    "        # === Run YOLO segmentation ===\n",
    "        results = model(image_rgb)\n",
    "        masks = results[0].masks\n",
    "        boxes = results[0].boxes\n",
    "        names = results[0].names\n",
    "\n",
    "        if masks is None or len(masks.data) == 0:\n",
    "            print(f\"❌ No cow mask found in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Get largest cow ===\n",
    "        best_index = None\n",
    "        largest_area = 0\n",
    "        for i, cls_id in enumerate(boxes.cls.cpu().numpy()):\n",
    "            name = names[int(cls_id)]\n",
    "            if name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                if area > largest_area:\n",
    "                    best_index = i\n",
    "                    largest_area = area\n",
    "\n",
    "        if best_index is None:\n",
    "            print(f\"❌ No valid cow class in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Resize mask to image ===\n",
    "        mask = masks.data[best_index].cpu().numpy()\n",
    "        resized_mask = cv2.resize(mask, (image_w, image_h), interpolation=cv2.INTER_NEAREST)\n",
    "        mask_3ch = np.stack([resized_mask] * 3, axis=-1)\n",
    "\n",
    "        # === Apply mask to full image ===\n",
    "        masked_image = np.where(mask_3ch > 0.5, image_rgb, 255)\n",
    "\n",
    "        # === Crop, remove bottom 30%, add margin ===\n",
    "        x1, y1, x2, y2 = map(int, boxes.xyxy[best_index].cpu().numpy())\n",
    "        margin = 0.1\n",
    "        x1 = max(0, x1 - int((x2 - x1) * margin))\n",
    "        x2 = min(image_w, x2 + int((x2 - x1) * margin))\n",
    "        y2 = y1 + int((y2 - y1) * 0.7)  # remove bottom 30%\n",
    "\n",
    "        cropped = masked_image[y1:y2, x1:x2]\n",
    "\n",
    "        # === Resize with padding to 224x224 ===\n",
    "        resized = resize_with_padding(cropped, desired_size=224)\n",
    "\n",
    "        # === Save final image ===\n",
    "        output_path = os.path.join(output_folder, fname.replace(\".jpg\", \"_processed.jpg\"))\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        print(f\"✅ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# === Function to resize with padding ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "\n",
    "    # Create new image and center the resized image on it\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    color = [255, 255, 255]  # White background\n",
    "    new_im = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return new_im\n",
    "\n",
    "# === Load YOLO segmentation model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "# === Paths ===\n",
    "input_base = \"/Users/suzetteschulenburg/Desktop/MainUse/Test\"\n",
    "output_base = \"/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# === Subfolders to process ===\n",
    "classes = ['Good', 'Bad']\n",
    "\n",
    "for cls in classes:\n",
    "    input_folder = os.path.join(input_base, cls)\n",
    "    output_folder = os.path.join(output_base, cls)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.endswith('.jpg'):\n",
    "            continue\n",
    "\n",
    "        # === Load image ===\n",
    "        image_path = os.path.join(input_folder, fname)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"⚠️ Could not read: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_h, image_w = image_rgb.shape[:2]\n",
    "\n",
    "        # === Run YOLO segmentation ===\n",
    "        results = model(image_rgb)\n",
    "        masks = results[0].masks\n",
    "        boxes = results[0].boxes\n",
    "        names = results[0].names\n",
    "\n",
    "        if masks is None or len(masks.data) == 0:\n",
    "            print(f\"❌ No cow mask found in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Get largest cow ===\n",
    "        best_index = None\n",
    "        largest_area = 0\n",
    "        for i, cls_id in enumerate(boxes.cls.cpu().numpy()):\n",
    "            name = names[int(cls_id)]\n",
    "            if name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                if area > largest_area:\n",
    "                    best_index = i\n",
    "                    largest_area = area\n",
    "\n",
    "        if best_index is None:\n",
    "            print(f\"❌ No valid cow class in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Resize mask to image ===\n",
    "        mask = masks.data[best_index].cpu().numpy()\n",
    "        resized_mask = cv2.resize(mask, (image_w, image_h), interpolation=cv2.INTER_NEAREST)\n",
    "        mask_3ch = np.stack([resized_mask] * 3, axis=-1)\n",
    "\n",
    "        # === Apply mask to full image ===\n",
    "        masked_image = np.where(mask_3ch > 0.5, image_rgb, 255)\n",
    "\n",
    "        # === Crop, remove bottom 30%, add margin ===\n",
    "        x1, y1, x2, y2 = map(int, boxes.xyxy[best_index].cpu().numpy())\n",
    "        margin = 0.1\n",
    "        x1 = max(0, x1 - int((x2 - x1) * margin))\n",
    "        x2 = min(image_w, x2 + int((x2 - x1) * margin))\n",
    "        y2 = y1 + int((y2 - y1) * 0.7)  # remove bottom 30%\n",
    "\n",
    "        cropped = masked_image[y1:y2, x1:x2]\n",
    "\n",
    "        # === Resize with padding to 224x224 ===\n",
    "        resized = resize_with_padding(cropped, desired_size=224)\n",
    "\n",
    "        # === Save final image ===\n",
    "        output_path = os.path.join(output_folder, fname.replace(\".jpg\", \"_processed.jpg\"))\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        print(f\"✅ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare MobileNetV2 with images not using YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUse2'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_NOYOLO'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_NOYOLO'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2, 3, 4, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in [2, 3, 4, 5]:  # Fold1 will be validation\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=4e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold2345_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold2345_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2, 3, 4, 5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_NOYOLO/model_fold2345_val1_frozen.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUse2/Fold1/Good/E1686_IMG_8412_flip.jpg'  # replace with actual image path\n",
    "\n",
    "# === Load model and image ===\n",
    "model = load_model(model_path)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img) / 255.0\n",
    "input_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# === Grad-CAM function ===\n",
    "def get_gradcam_heatmap(model, img_array, last_conv_layer_name='Conv_1'):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# === Generate and display Grad-CAM ===\n",
    "heatmap = get_gradcam_heatmap(model, input_array, last_conv_layer_name='Conv_1')  # last conv layer in MobileNetV2\n",
    "\n",
    "# Superimpose on original image\n",
    "def superimpose_heatmap_transparent(img, heatmap, threshold=0.3):\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    mask = np.uint8(255 * heatmap)\n",
    "    heatmap_color = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Create binary mask where attention is strong\n",
    "    binary_mask = heatmap > threshold\n",
    "    binary_mask = binary_mask.astype(np.uint8)\n",
    "\n",
    "    overlay = img.copy()\n",
    "    overlay[binary_mask == 1] = heatmap_color[binary_mask == 1] / 255.0\n",
    "    return np.uint8(overlay * 255)\n",
    "\n",
    "\n",
    "\n",
    "overlay_img = superimpose_heatmap(img_array, heatmap)\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_array)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(overlay_img)\n",
    "plt.title(\"Grad-CAM Overlay\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1/Good/E1686_IMG_8412_flip_processed.jpg'  # Change if needed\n",
    "\n",
    "# === Load model and image ===\n",
    "model = load_model(model_path)\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img) / 255.0\n",
    "input_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# === Layer names to extract heatmaps from (deep to shallow) ===\n",
    "layer_names = [\n",
    "    'block_1_expand',     # shallow\n",
    "    'block_3_expand',     # mid-shallow\n",
    "    'block_6_expand',     # mid\n",
    "    'block_13_expand',    # mid-deep\n",
    "    'Conv_1'              # last conv layer\n",
    "]\n",
    "\n",
    "# === Grad-CAM function for multiple layers ===\n",
    "def generate_multiple_gradcam_heatmaps(model, img_array, layer_names):\n",
    "    heatmaps = {}\n",
    "    for layer_name in layer_names:\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            conv_outputs, predictions = grad_model(img_array)\n",
    "            loss = predictions[:, 0]\n",
    "\n",
    "        grads = tape.gradient(loss, conv_outputs)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "        conv_outputs = conv_outputs[0]\n",
    "        heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "\n",
    "        heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap + tf.keras.backend.epsilon())\n",
    "        heatmaps[layer_name] = heatmap.numpy()\n",
    "    return heatmaps\n",
    "\n",
    "# === Generate heatmaps ===\n",
    "heatmaps = generate_multiple_gradcam_heatmaps(model, input_array, layer_names)\n",
    "\n",
    "# === Plot heatmaps on original image ===\n",
    "plt.figure(figsize=(18, 10))\n",
    "for i, (layer_name, heatmap) in enumerate(heatmaps.items()):\n",
    "    resized = cv2.resize(heatmap, (img_array.shape[1], img_array.shape[0]))\n",
    "    heatmap_color = cv2.applyColorMap(np.uint8(255 * resized), cv2.COLORMAP_JET)\n",
    "    img_uint8 = np.uint8(img_array * 255)\n",
    "    overlay = cv2.addWeighted(heatmap_color, 0.5, img_uint8, 0.5, 0)\n",
    "\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(f'Grad-CAM: {layer_name}')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Show original image for reference\n",
    "plt.subplot(2, 3, len(heatmaps) + 1)\n",
    "plt.imshow(img_array)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train fold 1 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Output structure\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2–5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus6'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus6'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Output structure\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-6, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2–5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus6'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus6'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Output structure\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=5e-6, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2–5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus5'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus5'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Output structure\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=5e-5, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2–5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Output structure\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2–5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Output structure\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=5e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2–5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze val and train graphs per Lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Mapping of learning rates to their respective folders ===\n",
    "history_folders = {\n",
    "    '1e-06': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus6',\n",
    "    '5e-06': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus6',\n",
    "    '1e-05': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers',\n",
    "    '5e-05': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus5',\n",
    "    '1e-04': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4',\n",
    "    '5e-04': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus4',\n",
    "}\n",
    "\n",
    "colors = ['orange', 'purple', 'blue', 'green', 'red', 'black']\n",
    "\n",
    "# === Set up plot ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "print(\"📊 Plotting training and validation curves (up to epoch 400)...\\n\")\n",
    "\n",
    "# === Loop through each learning rate/folder and plot ===\n",
    "for (lr, folder), color in zip(history_folders.items(), colors):\n",
    "    history_path = os.path.join(folder, 'history_fold245_val1_frozen.pkl')\n",
    "    \n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        # Limit to first 400 epochs\n",
    "        acc = hist['accuracy'][:200]\n",
    "        val_acc = hist['val_accuracy'][:200]\n",
    "        loss = hist['loss'][:200]\n",
    "        val_loss = hist['val_loss'][:200]\n",
    "\n",
    "        # Accuracy\n",
    "        axes[0].plot(acc, linestyle='-', color=color, alpha=0.6, label=f'Train Acc (LR={lr})')\n",
    "        axes[0].plot(val_acc, linestyle='--', color=color, label=f'Val Acc (LR={lr})')\n",
    "\n",
    "        # Loss\n",
    "        axes[1].plot(loss, linestyle='-', color=color, alpha=0.6, label=f'Train Loss (LR={lr})')\n",
    "        axes[1].plot(val_loss, linestyle='--', color=color, label=f'Val Loss (LR={lr})')\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file for LR {lr}: {history_path}\")\n",
    "\n",
    "# === Final plot formatting ===\n",
    "axes[0].set_title('Training and Validation Accuracy')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_title('Training and Validation Loss')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph over metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Learning rates and history folders ===\n",
    "history_folders = {\n",
    "    '1e-06': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus6',\n",
    "    '5e-06': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus6',\n",
    "    '1e-05': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers',\n",
    "    '5e-05': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus5',\n",
    "    '1e-04': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4',\n",
    "    '5e-04': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus4',\n",
    "}\n",
    "\n",
    "learning_rates = []\n",
    "best_val_accuracies = []\n",
    "min_val_losses = [] \n",
    "\n",
    "# === Extract best metrics from history files ===\n",
    "for lr, folder in history_folders.items():\n",
    "    history_path = os.path.join(folder, 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        \n",
    "        best_acc = max(hist['val_accuracy'])\n",
    "        min_loss = min(hist['val_loss'])\n",
    "\n",
    "        learning_rates.append(float(lr))\n",
    "        best_val_accuracies.append(best_acc)\n",
    "        min_val_losses.append(min_loss)\n",
    "        print(f\"✅ LR={lr}: Best Val Acc={best_acc:.4f}, Min Val Loss={min_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file for LR {lr}: {history_path}\")\n",
    "\n",
    "# === Plot: Val Accuracy vs Learning Rate (U-shape expected) ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(learning_rates, best_val_accuracies, marker='o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate (log scale)')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.title('Validation Accuracy vs Learning Rate')\n",
    "plt.grid(True)\n",
    "\n",
    "# === Plot: Val Loss vs Learning Rate (inverse U-shape) ===\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(learning_rates, min_val_losses, marker='o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate (log scale)')\n",
    "plt.ylabel('Minimum Validation Loss')\n",
    "plt.title('Validation Loss vs Learning Rate')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === History folders per LR ===\n",
    "history_folders = {\n",
    "    '1e-06': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus6',\n",
    "    '5e-06': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus6',\n",
    "    '1e-05': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers',\n",
    "    '5e-05': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus5',\n",
    "    '1e-04': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4',\n",
    "    '5e-04': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus4',\n",
    "}\n",
    "\n",
    "# === Collect metrics ===\n",
    "learning_rates = []\n",
    "best_val_accuracies = []\n",
    "min_val_losses = []\n",
    "\n",
    "for lr_str, folder in history_folders.items():\n",
    "    history_path = os.path.join(folder, 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        best_val_accuracies.append(max(hist['val_accuracy']))\n",
    "        min_val_losses.append(min(hist['val_loss']))\n",
    "        learning_rates.append(float(lr_str))\n",
    "        print(f\"✅ LR={lr_str}: Val Acc={max(hist['val_accuracy']):.4f}, Val Loss={min(hist['val_loss']):.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file for LR={lr_str}: {history_path}\")\n",
    "\n",
    "# === Convert to log scale for smoothing ===\n",
    "x = np.log10(learning_rates)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, best_val_accuracies, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, min_val_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot smoothed dual-axis graph ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate (log scale)')\n",
    "ax1.set_ylabel('Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(learning_rates, best_val_accuracies, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(learning_rates, min_val_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs Learning Rate')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create better line graph per LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    5e-5,   # 0.00005\n",
    "    7e-5,   # 0.00007\n",
    "    1e-4,   # 0.0001\n",
    "    2e-4,   # 0.0002\n",
    "    3e-4,   # 0.0003\n",
    "    4e-4,   # 0.0004\n",
    "    5e-4,   # 0.0005\n",
    "    7e-4,   # 0.0007\n",
    "    1e-3    # 0.001\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"📊 Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Reload learning rates and set base history path ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "\n",
    "# === Gather metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(min(hist['val_loss']))\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for interpolation ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Interpolate smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate (log scale)')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Minimum Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('MobileNetV2 Validation Accuracy and Loss vs Learning Rate')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    2e-3,   # 0.002\n",
    "    3e-3,   # 0.003\n",
    "    5e-3,   # 0.005\n",
    "    7e-3,   # 0.007\n",
    "    1e-2,   # 0.01\n",
    "    2e-2,   # 0.02\n",
    "    5e-2,   # 0.05\n",
    "    1e-1    # 0.1\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"📊 Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 14,     # Axis label font size\n",
    "    'xtick.labelsize': 12,    # X-tick label font size\n",
    "    'ytick.labelsize': 12,    # Y-tick label font size\n",
    "    'legend.fontsize': 12     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Reload learning rates and set base history path ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "\n",
    "# === Gather metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))  # ⬅️ average instead of min\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for interpolation ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Interpolate smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 14,     # Axis label font size\n",
    "    'xtick.labelsize': 12,    # X-tick label font size\n",
    "    'ytick.labelsize': 12,    # Y-tick label font size\n",
    "    'legend.fontsize': 12     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Reload learning rates and set base history path ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "\n",
    "# === Gather metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))  # ⬅️ average instead of min\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for interpolation ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Interpolate smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import LogLocator, LogFormatterSciNotation\n",
    "\n",
    "# === Directory containing all history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "\n",
    "# === Collect best val acc and average val loss from each file ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))  # ⬅️ average instead of min\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for log-scale smoothing ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Validation Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.xaxis.set_major_locator(LogLocator(base=10.0, numticks=10))\n",
    "ax1.xaxis.set_minor_locator(LogLocator(base=10.0, subs='auto', numticks=50))\n",
    "ax1.xaxis.set_major_formatter(LogFormatterSciNotation())\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import LogLocator, LogFormatterSciNotation\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Directory containing all history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_LRExperiment_5e6_to_5e5'\n",
    "\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "\n",
    "# === Collect best val acc and average val loss from each file ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))  # ⬅️ average instead of min\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for log-scale smoothing ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Validation Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.xaxis.set_major_locator(LogLocator(base=10.0, numticks=10))\n",
    "ax1.xaxis.set_minor_locator(LogLocator(base=10.0, subs='auto', numticks=50))\n",
    "ax1.xaxis.set_major_formatter(LogFormatterSciNotation())\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Mapping: LR → history + model directories ===\n",
    "setup = {\n",
    "    '1e-06': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus6/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus6/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '5e-06': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus6/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus6/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '1e-05': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '5e-05': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus5/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus5/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '1e-04': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '5e-04': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus4/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus4/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "}\n",
    "\n",
    "# === Validation Data Loader (Fold 1) ===\n",
    "def load_validation_data(val_dir):\n",
    "    X_val, y_val = [], []\n",
    "    for label in ['Good', 'Bad']:\n",
    "        path = os.path.join(val_dir, label)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        for fname in os.listdir(path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img = load_img(os.path.join(path, fname), target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                X_val.append(arr)\n",
    "                y_val.append(1 if label == 'Good' else 0)\n",
    "    return np.array(X_val), np.array(y_val)\n",
    "\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "X_val, y_val = load_validation_data(val_dir)\n",
    "\n",
    "# === Evaluate ===\n",
    "print(\"📊 Evaluation Metrics per Learning Rate:\\n\")\n",
    "for lr, paths in setup.items():\n",
    "    try:\n",
    "        # Load history\n",
    "        with open(paths['history'], 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "        min_val_loss = min(hist['val_loss'])\n",
    "\n",
    "        # Load model and predict\n",
    "        model = load_model(paths['model'])\n",
    "        y_probs = model.predict(X_val).flatten()\n",
    "        y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        # Output\n",
    "        print(f\"🟢 LR {lr}\")\n",
    "        print(f\"   Avg Val Loss : {avg_val_loss:.4f}\")\n",
    "        print(f\"   Min Val Loss : {min_val_loss:.4f}\")\n",
    "        print(f\"   Accuracy      : {acc:.4f}\")\n",
    "        print(f\"   F1 Score      : {f1:.4f}\")\n",
    "        print(f\"   Precision     : {precision:.4f}\")\n",
    "        print(f\"   Recall        : {recall:.4f}\")\n",
    "        print(f\"   AUC-PR        : {auc_pr:.4f}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error evaluating LR {lr}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics on graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Learning Rate Setup ===\n",
    "setup = {\n",
    "    '1e-06': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus6/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus6/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '5e-06': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus6/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus6/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '1e-05': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '5e-05': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus5/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus5/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '1e-04': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "    '5e-04': {\n",
    "        'history': '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayers5Minus4/history_fold245_val1_frozen.pkl',\n",
    "        'model': '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayers5Minus4/model_fold245_val1_frozen.keras'\n",
    "    },\n",
    "}\n",
    "\n",
    "# === Load Validation Data ===\n",
    "def load_validation_data(val_dir):\n",
    "    X_val, y_val = [], []\n",
    "    for label in ['Good', 'Bad']:\n",
    "        path = os.path.join(val_dir, label)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        for fname in os.listdir(path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img = load_img(os.path.join(path, fname), target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                X_val.append(arr)\n",
    "                y_val.append(1 if label == 'Good' else 0)\n",
    "    return np.array(X_val), np.array(y_val)\n",
    "\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "X_val, y_val = load_validation_data(val_dir)\n",
    "\n",
    "# === Metrics Storage ===\n",
    "learning_rates = []\n",
    "accuracies, f1_scores, precisions, recalls, aucs, val_losses = [], [], [], [], [], []\n",
    "\n",
    "# === Evaluate Each LR ===\n",
    "for lr, paths in setup.items():\n",
    "    try:\n",
    "        with open(paths['history'], 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        model = load_model(paths['model'])\n",
    "        y_probs = model.predict(X_val).flatten()\n",
    "        y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        learning_rates.append(lr)\n",
    "        accuracies.append(acc)\n",
    "        f1_scores.append(f1)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        aucs.append(auc_pr)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error evaluating LR {lr}: {e}\")\n",
    "\n",
    "# === Plotting ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Left axis: Accuracy, F1, Precision, Recall, AUC\n",
    "ax1.plot(learning_rates, accuracies, marker='o', label='Accuracy')\n",
    "ax1.plot(learning_rates, f1_scores, marker='o', label='F1 Score')\n",
    "ax1.plot(learning_rates, precisions, marker='o', label='Precision')\n",
    "ax1.plot(learning_rates, recalls, marker='o', label='Recall')\n",
    "ax1.plot(learning_rates, aucs, marker='o', label='AUC-PR')\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Validation Metrics per Learning Rate')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Right axis: Validation Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(learning_rates, val_losses, marker='o', color='black', linestyle='--', label='Avg Val Loss')\n",
    "ax2.set_ylabel('Avg Validation Loss', color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Combine legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='center right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold245_val1_frozen.keras'\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "\n",
    "# === Load model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Load images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        folder = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.endswith('.jpg'):\n",
    "                path = os.path.join(folder, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "                paths.append(path)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_val, y_val, val_paths = load_images_and_labels(val_dir)\n",
    "y_probs = model.predict(X_val).flatten()\n",
    "y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Select first 10 images with predictions ===\n",
    "selected_samples = []\n",
    "for img, true, pred, path in zip(X_val, y_val, y_preds, val_paths):\n",
    "    if len(selected_samples) < 5:\n",
    "        selected_samples.append((img, true, pred, path))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# === Grad-CAM++ setup ===\n",
    "def score_function(output):\n",
    "    return output[:, 0]\n",
    "\n",
    "model_modifier = ReplaceToLinear()\n",
    "gradcam = GradcamPlusPlus(model, model_modifier=model_modifier)\n",
    "\n",
    "# === Plot function ===\n",
    "def plot_gradcam_plus(samples):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    for i, (img, true, pred, path) in enumerate(samples):\n",
    "        cam = gradcam(score_function, np.expand_dims(img, axis=0), penultimate_layer='Conv_1')[0]\n",
    "        heatmap = np.uint8(255 * cam)\n",
    "        heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        original = (img * 255).astype(np.uint8)\n",
    "        overlay = cv2.addWeighted(cv2.cvtColor(original, cv2.COLOR_RGB2BGR), 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "        fname = os.path.basename(path)\n",
    "        plt.title(f\"{fname}\\nTrue: {'Good' if true else 'Bad'} | Pred: {'Good' if pred else 'Bad'}\", fontsize=8)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Display Grad-CAM++ overlays ===\n",
    "plot_gradcam_plus(selected_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take best lr and train 5 folds 4e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras')\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2, 3, 4, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in [2, 3, 4, 5]:  # Fold1 will be validation\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=4e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold2345_val1_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold2345_val1_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold1:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 2, 3, 4, 5 with Fold 1 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (1, 3, 4, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in [1, 3, 4, 5]:  # Changed to exclude Fold2 from training\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold2) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold2')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=4e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold1345_val2_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold1345_val2_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold2:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 1, 3, 4, 5 with Fold 2 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (1, 2, 4, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in [1, 2, 4, 5]:  # Fold 3 is excluded\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold3) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold3')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=4e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold1245_val3_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold1245_val3_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold3:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 1, 2, 4, 5 with Fold 3 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (1, 2, 3, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in [1, 2, 3, 5]:  # Fold 4 is excluded\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold4) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold4')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=4e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold1235_val4_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold1235_val4_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold4:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 1, 2, 3, 5 with Fold 4 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (1, 2, 3, 4) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in [1, 2, 3, 4]:  # Fold 5 is excluded\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold5) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold5')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model (Fully Frozen) ===\n",
    "def create_mobilenetv2_model(image_shape):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    \n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=4e-4, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_mobilenetv2_model(X_train.shape[1:])\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, 'model_fold1234_val5_frozen.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"⏱️ Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# === Save History ===\n",
    "with open(os.path.join(history_save_dir, 'history_fold1234_val5_frozen.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"\\n🔍 Evaluation on Fold5:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete using Folds 1, 2, 3, 4 with Fold 5 as validation (All layers frozen).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Directory containing histories ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "\n",
    "# === History filenames for each fold ===\n",
    "history_files = {\n",
    "    'Fold 1': 'history_fold2345_val1_frozen.pkl',\n",
    "    'Fold 2': 'history_fold1345_val2_frozen.pkl',\n",
    "    'Fold 3': 'history_fold1245_val3_frozen.pkl',\n",
    "    'Fold 4': 'history_fold1235_val4_frozen.pkl',\n",
    "    'Fold 5': 'history_fold1234_val5_frozen.pkl'\n",
    "}\n",
    "\n",
    "# === Define consistent colors per fold ===\n",
    "fold_colors = {\n",
    "    'Fold 1': 'blue',\n",
    "    'Fold 2': 'green',\n",
    "    'Fold 3': 'orange',\n",
    "    'Fold 4': 'red',\n",
    "    'Fold 5': 'purple'\n",
    "}\n",
    "\n",
    "# === Setup side-by-side plots ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))  # One row, two columns\n",
    "\n",
    "# === Accuracy Plot (left) ===\n",
    "for fold, filename in history_files.items():\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    color = fold_colors[fold]\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        axes[0].plot(hist['accuracy'], color=color, linestyle='-', label=f'{fold} Train')\n",
    "        axes[0].plot(hist['val_accuracy'], color=color, linestyle='--', label=f'{fold} Val')\n",
    "\n",
    "axes[0].set_title('Training and Validation Accuracy per Fold')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# === Loss Plot (right) ===\n",
    "for fold, filename in history_files.items():\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    color = fold_colors[fold]\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        axes[1].plot(hist['loss'], color=color, linestyle='-', label=f'{fold} Train')\n",
    "        axes[1].plot(hist['val_loss'], color=color, linestyle='--', label=f'{fold} Val')\n",
    "\n",
    "axes[1].set_title('Training and Validation Loss per Fold')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# === Final Layout ===\n",
    "plt.suptitle('MobileNetV2: Accuracy and Loss per Fold', fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Directory where history files are saved ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/History_MobileNet2_Frozen_AllLayersMinus4'\n",
    "\n",
    "# === Fold numbers ===\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "def load_history(fold):\n",
    "    if fold == 1:\n",
    "        filename = 'history_fold2345_val1_frozen.pkl'\n",
    "    elif fold == 2:\n",
    "        filename = 'history_fold1345_val2_frozen.pkl'\n",
    "    elif fold == 3:\n",
    "        filename = 'history_fold1245_val3_frozen.pkl'\n",
    "    elif fold == 4:\n",
    "        filename = 'history_fold1235_val4_frozen.pkl'\n",
    "    elif fold == 5:\n",
    "        filename = 'history_fold1234_val5_frozen.pkl'\n",
    "    else:\n",
    "        print(f\"❌ Invalid fold: {fold}\")\n",
    "        return None\n",
    "\n",
    "    file_path = os.path.join(history_save_dir, filename)\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"❌ History file not found for Fold {fold}: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color='blue', alpha=0.6, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color='red', alpha=0.6, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Loss Across Folds (MobileNetV2)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'])\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], color='blue', alpha=0.6, label=f'Fold {fold} Train Acc' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', color='red', alpha=0.6, label=f'Fold {fold} Val Acc' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Accuracy Across Folds (MobileNetV2)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'])\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Load all histories ===\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    history = load_history(fold)\n",
    "    if history:\n",
    "        fold_histories[fold] = history\n",
    "\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"🚫 No valid history files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_accuracies, val_accuracies = [], []\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for fold, hist in fold_histories.items():\n",
    "    train_accuracies.append(hist['accuracy'][-1] * 100)\n",
    "    val_accuracies.append(hist['val_accuracy'][-1] * 100)\n",
    "    train_losses.append(hist['loss'][-1])\n",
    "    val_losses.append(hist['val_loss'][-1])\n",
    "    print(f\"📁 Fold {fold}:\")\n",
    "    print(f\"   ✅ Train Accuracy: {train_accuracies[-1]:.2f}%\")\n",
    "    print(f\"   ✅ Train Loss:     {train_losses[-1]:.4f}\")\n",
    "    print(f\"   ✅ Val Accuracy:   {val_accuracies[-1]:.2f}%\")\n",
    "    print(f\"   ✅ Val Loss:       {val_losses[-1]:.4f}\\n\")\n",
    "\n",
    "print(\"📈 Averages:\")\n",
    "print(f\"🔹 Train Accuracy: {np.mean(train_accuracies):.2f}% ± {np.std(train_accuracies):.2f}\")\n",
    "print(f\"🔹 Train Loss:     {np.mean(train_losses):.4f} ± {np.std(train_losses):.4f}\")\n",
    "print(f\"🔹 Val Accuracy:   {np.mean(val_accuracies):.2f}% ± {np.std(val_accuracies):.2f}\")\n",
    "print(f\"🔹 Val Loss:       {np.mean(val_losses):.4f} ± {np.std(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Val metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Directories ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# === Map folds to model and validation set\n",
    "folds = {\n",
    "    1: {'model': 'model_fold2345_val1_frozen.keras', 'val': 'Fold1'},\n",
    "    2: {'model': 'model_fold1345_val2_frozen.keras', 'val': 'Fold2'},\n",
    "    3: {'model': 'model_fold1245_val3_frozen.keras', 'val': 'Fold3'},\n",
    "    4: {'model': 'model_fold1235_val4_frozen.keras', 'val': 'Fold4'},\n",
    "    5: {'model': 'model_fold1234_val5_frozen.keras', 'val': 'Fold5'}\n",
    "}\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Evaluate each fold ===\n",
    "metrics = []\n",
    "for fold, paths in folds.items():\n",
    "    print(f\"\\n📂 Evaluating Fold {fold}\")\n",
    "    \n",
    "    model_path = os.path.join(model_dir, paths['model'])\n",
    "    val_dir = os.path.join(base_fold_dir, paths['val'])\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Predict\n",
    "    y_probs = model.predict(X_val, verbose=0).flatten()\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val, y_preds)\n",
    "    f1 = f1_score(y_val, y_preds)\n",
    "    prec = precision_score(y_val, y_preds)\n",
    "    rec = recall_score(y_val, y_preds)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'AUC-PR': auc_pr\n",
    "    })\n",
    "\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC-PR   : {auc_pr:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# === Print average metrics ===\n",
    "print(\"\\n📊 Average Validation Metrics Across Folds:\")\n",
    "avg = {k: np.mean([m[k] for m in metrics]) for k in metrics[0] if k != 'Fold'}\n",
    "for k, v in avg.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Directories ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# === Map folds to model and validation set\n",
    "folds = {\n",
    "    1: {'model': 'model_fold2345_val1_frozen.keras', 'val': 'Fold1'},\n",
    "    2: {'model': 'model_fold1345_val2_frozen.keras', 'val': 'Fold2'},\n",
    "    3: {'model': 'model_fold1245_val3_frozen.keras', 'val': 'Fold3'},\n",
    "    4: {'model': 'model_fold1235_val4_frozen.keras', 'val': 'Fold4'},\n",
    "    5: {'model': 'model_fold1234_val5_frozen.keras', 'val': 'Fold5'}\n",
    "}\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Evaluate each fold ===\n",
    "metrics = []\n",
    "for fold, paths in folds.items():\n",
    "    print(f\"\\n📂 Evaluating Fold {fold}\")\n",
    "    \n",
    "    model_path = os.path.join(model_dir, paths['model'])\n",
    "    val_dir = os.path.join(base_fold_dir, paths['val'])\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Predict\n",
    "    y_probs = model.predict(X_val, verbose=0).flatten()\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val, y_preds)\n",
    "    f1 = f1_score(y_val, y_preds)\n",
    "    prec = precision_score(y_val, y_preds)\n",
    "    rec = recall_score(y_val, y_preds)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'AUC-PR': auc_pr\n",
    "    })\n",
    "\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC-PR   : {auc_pr:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# === Compute Mean and Std Dev ===\n",
    "print(\"\\n📊 Average and Standard Deviation of Validation Metrics Across Folds:\")\n",
    "keys = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']\n",
    "for key in keys:\n",
    "    values = [m[key] for m in metrics]\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    print(f\"{key}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "base_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "# === Fold mapping\n",
    "folds = {\n",
    "    1: {'model': 'model_fold2345_val1_frozen.keras', 'val': 'Fold1'},\n",
    "    2: {'model': 'model_fold1345_val2_frozen.keras', 'val': 'Fold2'},\n",
    "    3: {'model': 'model_fold1245_val3_frozen.keras', 'val': 'Fold3'},\n",
    "    4: {'model': 'model_fold1235_val4_frozen.keras', 'val': 'Fold4'},\n",
    "    5: {'model': 'model_fold1234_val5_frozen.keras', 'val': 'Fold5'}\n",
    "}\n",
    "\n",
    "# === Load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = img_to_array(img) / 255.0\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Store predictions and labels\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "for fold, info in folds.items():\n",
    "    print(f\"📂 Evaluating Fold {fold}...\")\n",
    "\n",
    "    model_path = os.path.join(model_dir, info['model'])\n",
    "    val_dir = os.path.join(base_dir, info['val'])\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "    y_probs = model.predict(X_val, verbose=0).flatten()\n",
    "\n",
    "    all_probs.extend(y_probs)\n",
    "    all_labels.extend(y_val)\n",
    "\n",
    "# === Convert to arrays\n",
    "all_probs = np.array(all_probs)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# === Plot scatter\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(len(all_probs)):\n",
    "    color = 'green' if all_labels[i] == 1 else 'red'\n",
    "    plt.scatter(i, all_probs[i], color=color, alpha=0.6)\n",
    "\n",
    "plt.axhline(y=0.5, color='black', linestyle='--', label='Threshold = 0.5')\n",
    "plt.title('Scatter Plot of Predicted Probabilities on Validation Sets (All Folds)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Predicted Probability')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred = (all_probs >= threshold).astype(int)\n",
    "\n",
    "acc = accuracy_score(all_labels, y_pred)\n",
    "f1 = f1_score(all_labels, y_pred)\n",
    "prec = precision_score(all_labels, y_pred)\n",
    "rec = recall_score(all_labels, y_pred)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(all_labels, all_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "print(\"\\n📊 Average Metrics on All Validation Sets using Threshold = 0.5\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"AUC-PR   : {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Directories ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "\n",
    "# === Map folds to models (all evaluate on same test set)\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load test set once ===\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model on the test set ===\n",
    "metrics = []\n",
    "for fold, model_name in folds.items():\n",
    "    print(f\"\\n📂 Evaluating Fold {fold} Model on Test Set\")\n",
    "    \n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds)\n",
    "    prec = precision_score(y_test, y_preds)\n",
    "    rec = recall_score(y_test, y_preds)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'AUC-PR': auc_pr\n",
    "    })\n",
    "\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC-PR   : {auc_pr:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# === Print average and std metrics ===\n",
    "print(\"\\n📊 Average and Std Dev of Test Metrics Across Folds:\")\n",
    "keys = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']\n",
    "for key in keys:\n",
    "    values = [m[key] for m in metrics]\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    print(f\"{key}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pair excel with individual rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === Paths ===\n",
    "excel_path = '/Users/suzetteschulenburg/Desktop/Masters/Data/Publsih excel/CattleRecords.xlsx'\n",
    "good_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Good'\n",
    "bad_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Bad'\n",
    "\n",
    "# === Load Excel with proper header ===\n",
    "df = pd.read_excel(excel_path, header=1)\n",
    "df.columns = df.columns.str.strip()  # Clean up any whitespace\n",
    "\n",
    "# Keep only necessary columns\n",
    "df = df[['ID', 'Rating']]\n",
    "df['ID_Prefix'] = df['ID'].str.extract(r'(^[A-Z]+\\d+)')  # remove trailing _1 etc.\n",
    "\n",
    "# === Extract image info ===\n",
    "image_data = []\n",
    "for label, folder in [('Good', good_dir), ('Bad', bad_dir)]:\n",
    "    for fname in os.listdir(folder):\n",
    "        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            match_id = fname.split('_')[0]  # extract prefix from image filename\n",
    "            image_data.append({\n",
    "                'Filename': fname,\n",
    "                'Folder': label,\n",
    "                'ID_Prefix': match_id\n",
    "            })\n",
    "\n",
    "image_df = pd.DataFrame(image_data)\n",
    "\n",
    "# === Merge Excel and Image Data ===\n",
    "merged_df = pd.merge(image_df, df, on='ID_Prefix', how='left')\n",
    "merged_df = merged_df[['Filename', 'Folder', 'ID', 'Rating']]\n",
    "\n",
    "# === Show result ===\n",
    "print(merged_df.head())\n",
    "\n",
    "# === Optionally save\n",
    "# merged_df.to_csv(\"paired_image_rating_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === First 10 from each class ===\n",
    "first_10_good = merged_df[merged_df['Folder'] == 'Good'].head(10)\n",
    "first_10_bad = merged_df[merged_df['Folder'] == 'Bad'].head(10)\n",
    "\n",
    "# === Display\n",
    "print(\"🟢 First 10 GOOD Images:\")\n",
    "print(first_10_good.to_string(index=False))\n",
    "\n",
    "print(\"\\n🔴 First 10 BAD Images:\")\n",
    "print(first_10_bad.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Directories ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "excel_path = '/Users/suzetteschulenburg/Desktop/Masters/Data/Publsih excel/CattleRecords.xlsx'\n",
    "\n",
    "# === Map folds to models\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load ratings\n",
    "df = pd.read_excel(excel_path, header=1)  # Skip header row\n",
    "df.columns = ['ID', 'Photo Number', 'Rating']\n",
    "df['ID'] = df['ID'].astype(str)\n",
    "\n",
    "# === Load images and labels with filenames\n",
    "filenames, images, labels = [], [], []\n",
    "for label_folder in ['Good', 'Bad']:\n",
    "    label_path = os.path.join(test_dir, label_folder)\n",
    "    label = 1 if label_folder == 'Good' else 0\n",
    "    for fname in os.listdir(label_path):\n",
    "        if fname.endswith('.png') or fname.endswith('.jpg'):\n",
    "            path = os.path.join(label_path, fname)\n",
    "            img = load_img(path, target_size=(224, 224))\n",
    "            arr = img_to_array(img) / 255.0\n",
    "            images.append(arr)\n",
    "            labels.append(label)\n",
    "            filenames.append(fname)\n",
    "\n",
    "X_test = np.array(images)\n",
    "y_test = np.array(labels)\n",
    "\n",
    "# === Evaluate all folds and record predictions\n",
    "results = []\n",
    "\n",
    "for fold, model_name in folds.items():\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_test).flatten()\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    for fname, prob, true_label, pred_label in zip(filenames, y_probs, y_test, y_preds):\n",
    "        base_id = fname.split('_IMG_')[0] if '_IMG_' in fname else fname.split('_')[0]\n",
    "        rating_row = df[df['ID'].str.contains(base_id)]\n",
    "        rating = rating_row['Rating'].values[0] if not rating_row.empty else None\n",
    "        results.append({\n",
    "            'Fold': fold,\n",
    "            'Filename': fname,\n",
    "            'ID': base_id,\n",
    "            'Rating': rating,\n",
    "            'TrueLabel': true_label,\n",
    "            'PredProb': round(prob, 4),\n",
    "            'PredLabel': int(pred_label),\n",
    "            'Agreement': '✅' if true_label == pred_label else '❌'\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"fold_predictions_with_ratings.csv\", index=False)\n",
    "print(\"✅ Table saved to 'fold_predictions_with_ratings.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take highest prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# === Paths ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "excel_path = '/Users/suzetteschulenburg/Desktop/Masters/Data/Publsih excel/CattleRecords.xlsx'\n",
    "\n",
    "# === Model folds ===\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load ratings from Excel (headers in second row) ===\n",
    "df_ratings = pd.read_excel(excel_path, header=1)\n",
    "df_ratings = df_ratings.rename(columns={df_ratings.columns[0]: \"ID\", df_ratings.columns[2]: \"Rating\"})\n",
    "\n",
    "# === Load test set ===\n",
    "image_data = []\n",
    "for label_str, label_val in [('Good', 1), ('Bad', 0)]:\n",
    "    subdir = os.path.join(test_dir, label_str)\n",
    "    for fname in os.listdir(subdir):\n",
    "        if fname.lower().endswith(('.jpg', '.png')):\n",
    "            img_path = os.path.join(subdir, fname)\n",
    "            img = load_img(img_path, target_size=(224, 224))\n",
    "            img_arr = img_to_array(img) / 255.0\n",
    "            image_data.append({\n",
    "                'filename': fname,\n",
    "                'filepath': img_path,\n",
    "                'image': img_arr,\n",
    "                'true_label': label_val\n",
    "            })\n",
    "\n",
    "df_images = pd.DataFrame(image_data)\n",
    "df_images['ID'] = df_images['filename'].str.extract(r'(.*)_IMG')[0]\n",
    "df_images = df_images.merge(df_ratings[['ID', 'Rating']], on='ID', how='left')\n",
    "X = np.stack(df_images['image'].values)\n",
    "\n",
    "# === Evaluate models ===\n",
    "results = []\n",
    "all_cm = np.array([[0, 0], [0, 0]])\n",
    "\n",
    "for fold, model_name in folds.items():\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        continue\n",
    "    print(f\"Evaluating Fold {fold}...\")\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    y_probs = model.predict(X, verbose=0).flatten()\n",
    "    df_images['pred_prob'] = y_probs\n",
    "    df_images['pred_label'] = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    df_top = df_images.loc[df_images.groupby('ID')['pred_prob'].idxmax()]\n",
    "    y_true = df_top['true_label']\n",
    "    y_pred = df_top['pred_label']\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    all_cm += cm\n",
    "\n",
    "    results.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec\n",
    "    })\n",
    "\n",
    "# === Show results ===\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nFold-wise Metrics:\")\n",
    "print(df_results)\n",
    "\n",
    "print(\"\\nAverage ± Std:\")\n",
    "for col in ['Accuracy', 'F1 Score', 'Precision', 'Recall']:\n",
    "    avg = df_results[col].mean()\n",
    "    std = df_results[col].std()\n",
    "    print(f\"{col}: {avg:.4f} ± {std:.4f}\")\n",
    "\n",
    "# === Confusion matrix ===\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(all_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Cumulative Confusion Matrix Across All Folds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "fold1_model = 'model_fold2345_val1_frozen.keras'  # Fold 1 model\n",
    "image_path = '/Users/suzetteschulenburg/Desktop/18006865-b37c-40e9-abde-c11e2a496465.jpg'        # <-- put your image path here\n",
    "\n",
    "# === Settings ===\n",
    "target_size = (224, 224)\n",
    "threshold = 0.5  # decision threshold\n",
    "\n",
    "# === Load model ===\n",
    "model_path = os.path.join(model_dir, fold1_model)\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Preprocess single image ===\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "img = load_img(image_path, target_size=target_size)\n",
    "arr = img_to_array(img) / 255.0\n",
    "arr = np.expand_dims(arr, axis=0)  # (1, 224, 224, 3)\n",
    "\n",
    "# === Predict ===\n",
    "prob_good = float(model.predict(arr, verbose=0).squeeze())  # sigmoid output\n",
    "pred_label = 1 if prob_good > threshold else 0\n",
    "label_name = 'Good' if pred_label == 1 else 'Bad'\n",
    "\n",
    "print(f\"Image: {image_path}\")\n",
    "print(f\"P(Good) = {prob_good:.4f}\")\n",
    "print(f\"Predicted class: {label_name} (threshold={threshold})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Paths ===\n",
    "tflite_path = \"/Users/suzetteschulenburg/Desktop/Wag/cow_model.tflite\"\n",
    "image_path  =  '/Users/suzetteschulenburg/Desktop/18006865-b37c-40e9-abde-c11e2a496465.jpg'    \n",
    "# Optional: set your Keras model to compare (or leave None)\n",
    "keras_model_path = \"/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras\"\n",
    "\n",
    "# === Settings ===\n",
    "target_size = (224, 224)\n",
    "threshold = 0.5  # decision threshold\n",
    "\n",
    "def load_image_array(path, size=(224, 224)):\n",
    "    img = Image.open(path).convert(\"RGB\").resize(size, Image.BILINEAR)\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0  # [0,1] normalize\n",
    "    return np.expand_dims(arr, axis=0)  # (1, H, W, 3)\n",
    "\n",
    "def run_tflite(model_path, input_batch):\n",
    "    \"\"\"Returns a float probability in [0,1] for class 'Good'.\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details  = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Some TFLite models differ in size/dtype; adapt if needed\n",
    "    idx_in  = input_details[0][\"index\"]\n",
    "    idx_out = output_details[0][\"index\"]\n",
    "\n",
    "    # If the model expects uint8 (quantized), quantize the input\n",
    "    in_dtype = input_details[0][\"dtype\"]\n",
    "    x = input_batch\n",
    "    if in_dtype == np.uint8:\n",
    "        scale, zero_point = input_details[0][\"quantization\"]\n",
    "        if scale == 0:  # Safety for non-quantized metadata\n",
    "            scale, zero_point = 1.0, 0\n",
    "        x = (x / scale + zero_point).round().astype(np.uint8)\n",
    "    else:\n",
    "        x = x.astype(np.float32)\n",
    "\n",
    "    # Resize tensor if the model has a different input shape\n",
    "    expected_shape = input_details[0][\"shape\"]\n",
    "    if list(expected_shape) != list(x.shape):\n",
    "        interpreter.resize_tensor_input(idx_in, x.shape, strict=False)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "    interpreter.set_tensor(idx_in, x)\n",
    "    interpreter.invoke()\n",
    "    y = interpreter.get_tensor(idx_out)\n",
    "\n",
    "    # Dequantize output if needed\n",
    "    out_dtype = output_details[0][\"dtype\"]\n",
    "    if out_dtype == np.uint8:\n",
    "        scale, zero_point = output_details[0][\"quantization\"]\n",
    "        if scale == 0:\n",
    "            scale, zero_point = 1.0, 0\n",
    "        y = scale * (y.astype(np.float32) - zero_point)\n",
    "    else:\n",
    "        y = y.astype(np.float32)\n",
    "\n",
    "    # Flatten and cast to float\n",
    "    prob_good = float(np.squeeze(y))\n",
    "    # If your TFLite outputs logits, pass through sigmoid:\n",
    "    # prob_good = float(1 / (1 + np.exp(-prob_good)))\n",
    "    return prob_good\n",
    "\n",
    "def run_keras(model_path, input_batch):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    prob_good = float(np.squeeze(model.predict(input_batch, verbose=0)))\n",
    "    return prob_good\n",
    "\n",
    "# === Load image ===\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "x = load_image_array(image_path, target_size)\n",
    "\n",
    "# === TFLite ===\n",
    "if not os.path.exists(tflite_path):\n",
    "    raise FileNotFoundError(f\"TFLite model not found: {tflite_path}\")\n",
    "tflite_prob = run_tflite(tflite_path, x)\n",
    "tflite_pred = \"Good\" if tflite_prob > threshold else \"Bad\"\n",
    "\n",
    "print(\"—— TFLite ——————————————————————————\")\n",
    "print(f\"Image:      {image_path}\")\n",
    "print(f\"P(Good):    {tflite_prob:.4f}\")\n",
    "print(f\"Pred class: {tflite_pred} (thr={threshold})\")\n",
    "\n",
    "# === Optional: Keras comparison ===\n",
    "if keras_model_path and os.path.exists(keras_model_path):\n",
    "    keras_prob = run_keras(keras_model_path, x)\n",
    "    keras_pred = \"Good\" if keras_prob > threshold else \"Bad\"\n",
    "    print(\"\\n—— Keras ———————————————————————————\")\n",
    "    print(f\"P(Good):    {keras_prob:.4f}\")\n",
    "    print(f\"Pred class: {keras_pred} (thr={threshold})\")\n",
    "\n",
    "    # Quick diff\n",
    "    delta = tflite_prob - keras_prob\n",
    "    agree = (tflite_pred == keras_pred)\n",
    "    print(\"\\n—— Compare —————————————————————————\")\n",
    "    print(f\"Δ Prob (TFLite−Keras): {delta:+.4f}\")\n",
    "    print(f\"Agreement:             {agree}\")\n",
    "else:\n",
    "    print(\"\\n(Keras model not provided or not found; skipped comparison.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path  = '/Users/suzetteschulenburg/Desktop/Cow1.png'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# === Paths ===\n",
    "\n",
    "keras_model_path = \"/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras\"\n",
    "tflite_path = \"/Users/suzetteschulenburg/Desktop/Wag/cow_model.tflite\"\n",
    "\n",
    "# === Settings (shared) ===\n",
    "target_size = (224, 224)\n",
    "threshold = 0.5  # decision threshold, same for both\n",
    "\n",
    "def preprocess(path, size=(224, 224)):\n",
    "    \"\"\"Shared preprocessing: RGB -> resize -> float32 in [0,1] -> (1,H,W,3).\"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\").resize(size, Image.BILINEAR)\n",
    "    x = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def predict_keras(model_path, x_batch):\n",
    "    model = load_model(model_path)\n",
    "    prob = float(np.squeeze(model.predict(x_batch, verbose=0)))\n",
    "    return prob\n",
    "\n",
    "def predict_tflite(model_path, x_batch):\n",
    "    \"\"\"Feeds the SAME x_batch; adapts only to TFLite tensor dtype if needed.\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    in_det  = interpreter.get_input_details()[0]\n",
    "    out_det = interpreter.get_output_details()[0]\n",
    "\n",
    "    # Adapt dtype if model is quantized uint8 (not preprocessing—just dtype)\n",
    "    x = x_batch\n",
    "    if in_det[\"dtype\"] == np.uint8:\n",
    "        scale, zp = in_det[\"quantization\"]\n",
    "        if scale == 0: scale, zp = 1.0, 0\n",
    "        x = np.round(x / scale + zp).astype(np.uint8)\n",
    "    else:\n",
    "        x = x.astype(np.float32)\n",
    "\n",
    "    # Resize input tensor if needed (keeps SAME preprocessed data)\n",
    "    if list(in_det[\"shape\"]) != list(x.shape):\n",
    "        interpreter.resize_tensor_input(in_det[\"index\"], x.shape, strict=False)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "    interpreter.set_tensor(in_det[\"index\"], x)\n",
    "    interpreter.invoke()\n",
    "    y = interpreter.get_tensor(out_det[\"index\"]).astype(np.float32)\n",
    "\n",
    "    # Dequantize output if needed\n",
    "    if out_det[\"dtype\"] == np.uint8:\n",
    "        scale, zp = out_det[\"quantization\"]\n",
    "        if scale == 0: scale, zp = 1.0, 0\n",
    "        y = scale * (y - zp)\n",
    "\n",
    "    prob = float(np.squeeze(y))\n",
    "    # If your TFLite head outputs logits (rare in your setup), uncomment:\n",
    "    # prob = 1.0 / (1.0 + np.exp(-prob))\n",
    "    return prob\n",
    "\n",
    "# === Run ===\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(image_path)\n",
    "x = preprocess(image_path, target_size)\n",
    "\n",
    "# TFLite\n",
    "if not os.path.exists(tflite_path):\n",
    "    raise FileNotFoundError(tflite_path)\n",
    "tfl_prob = predict_tflite(tflite_path, x)\n",
    "tfl_pred = \"Good\" if tfl_prob > threshold else \"Bad\"\n",
    "\n",
    "# Keras\n",
    "if not os.path.exists(keras_model_path):\n",
    "    raise FileNotFoundError(keras_model_path)\n",
    "kr_prob = predict_keras(keras_model_path, x)\n",
    "kr_pred = \"Good\" if kr_prob > threshold else \"Bad\"\n",
    "\n",
    "# === Print side-by-side ===\n",
    "print(f\"Image: {image_path}\")\n",
    "print(\"—— TFLite ———————————————\")\n",
    "print(f\"P(Good): {tfl_prob:.4f} | Pred: {tfl_pred} (thr={threshold})\")\n",
    "print(\"—— Keras ————————————————\")\n",
    "print(f\"P(Good): {kr_prob:.4f} | Pred: {kr_pred} (thr={threshold})\")\n",
    "print(\"—— Compare ——————————————\")\n",
    "print(f\"Δ Prob (TFLite−Keras): {tfl_prob - kr_prob:+.4f}\")\n",
    "print(f\"Agreement: {tfl_pred == kr_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get YOLO too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path  = \"/Users/suzetteschulenburg/Desktop/MainUse/Test/Bad/E2120_IMG_8289.jpg\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === Paths ===\n",
    "keras_model_path = \"/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras\"\n",
    "tflite_path = \"/Users/suzetteschulenburg/Desktop/Wag/cow_model.tflite\"\n",
    "yolo_weights = \"/Users/suzetteschulenburg/Desktop/Wag/yolov8s-seg.pt\"  # or wherever your weights are\n",
    "\n",
    "\n",
    "# === Settings ===\n",
    "target_size = (224, 224)\n",
    "threshold = 0.5\n",
    "feet_ratio = 0.30      # remove bottom 30%\n",
    "margin_ratio = 0.05    # expand crop bbox by 5%\n",
    "pad_color = (0, 0, 0)  # black padding\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) YOLOv8 segmentation-based crop: largest cow, remove bottom 30%, pad+resize\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def yolo_crop_and_chop(image_path, yolo_weights, feet_ratio=0.30, margin_ratio=0.05,\n",
    "                       target_size=(224, 224), pad_color=(0,0,0)):\n",
    "    # Load original\n",
    "    orig = cv2.imread(image_path)\n",
    "    if orig is None:\n",
    "        raise FileNotFoundError(f\"Could not read image: {image_path}\")\n",
    "    h, w = orig.shape[:2]\n",
    "\n",
    "    # Run YOLOv8 segmentation\n",
    "    model = YOLO(yolo_weights)\n",
    "    res = model(orig, verbose=False)[0]\n",
    "\n",
    "    if (res.masks is None) or (len(res.boxes) == 0):\n",
    "        # Fallback: no masks found → just center-crop then chop feet\n",
    "        crop = orig\n",
    "    else:\n",
    "        # Filter to 'cow' if label names available\n",
    "        largest_idx = None\n",
    "        largest_area = -1\n",
    "        for i, box in enumerate(res.boxes):\n",
    "            cls_id = int(box.cls[0].item()) if hasattr(box.cls[0], \"item\") else int(box.cls[0])\n",
    "            name = res.names.get(cls_id, str(cls_id)) if hasattr(res, \"names\") else str(cls_id)\n",
    "            if name != \"cow\":\n",
    "                continue\n",
    "            # Prefer mask area; otherwise use bbox area\n",
    "            if res.masks is not None:\n",
    "                mask = res.masks.data[i].cpu().numpy().astype(np.uint8)  # (H', W') float->uint8\n",
    "                # Upsample mask to original size if needed\n",
    "                if mask.shape[0] != h or mask.shape[1] != w:\n",
    "                    mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "                area = int(mask.sum())\n",
    "            else:\n",
    "                xyxy = box.xyxy[0].cpu().numpy()\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_idx = i\n",
    "\n",
    "        # If no 'cow' label found, fallback to the largest detection\n",
    "        if largest_idx is None:\n",
    "            # choose largest by box area\n",
    "            for i, box in enumerate(res.boxes):\n",
    "                xyxy = box.xyxy[0].cpu().numpy()\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "                area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "                if area > largest_area:\n",
    "                    largest_area = area\n",
    "                    largest_idx = i\n",
    "\n",
    "        # Get bbox for largest detection (use mask bbox if available)\n",
    "        box = res.boxes[largest_idx]\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "        # Optional: tighten bbox to mask bounds if mask exists\n",
    "        if res.masks is not None:\n",
    "            mask = res.masks.data[largest_idx].cpu().numpy().astype(np.uint8)\n",
    "            if mask.shape[0] != h or mask.shape[1] != w:\n",
    "                mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "            ys, xs = np.where(mask > 0)\n",
    "            if len(xs) > 0 and len(ys) > 0:\n",
    "                x1, x2 = xs.min(), xs.max()\n",
    "                y1, y2 = ys.min(), ys.max()\n",
    "\n",
    "        # Expand bbox by margin\n",
    "        bw, bh = x2 - x1, y2 - y1\n",
    "        mx, my = int(bw * margin_ratio), int(bh * margin_ratio)\n",
    "        x1 = max(0, x1 - mx)\n",
    "        y1 = max(0, y1 - my)\n",
    "        x2 = min(w, x2 + mx)\n",
    "        y2 = min(h, y2 + my)\n",
    "\n",
    "        crop = orig[y1:y2, x1:x2]\n",
    "\n",
    "    # Remove bottom feet_ratio of the crop height\n",
    "    ch, cw = crop.shape[:2]\n",
    "    cut = int(ch * (1.0 - feet_ratio))\n",
    "    cut = max(1, min(cut, ch))  # safety\n",
    "    crop_no_feet = crop[:cut, :]\n",
    "\n",
    "    # Pad to square\n",
    "    ch2, cw2 = crop_no_feet.shape[:2]\n",
    "    side = max(ch2, cw2)\n",
    "    pad_top = (side - ch2) // 2\n",
    "    pad_bottom = side - ch2 - pad_top\n",
    "    pad_left = (side - cw2) // 2\n",
    "    pad_right = side - cw2 - pad_left\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        crop_no_feet, pad_top, pad_bottom, pad_left, pad_right,\n",
    "        borderType=cv2.BORDER_CONSTANT, value=pad_color\n",
    "    )\n",
    "\n",
    "    # Resize to target\n",
    "    final = cv2.resize(padded, target_size, interpolation=cv2.INTER_AREA)\n",
    "    # BGR->RGB for consistency with PIL/TensorFlow pipelines\n",
    "    final_rgb = cv2.cvtColor(final, cv2.COLOR_BGR2RGB)\n",
    "    # Normalize [0,1] and add batch dim\n",
    "    x = (final_rgb.astype(np.float32) / 255.0)[None, ...]  # (1, H, W, 3)\n",
    "    return x\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Prediction helpers (SAME preprocessed batch goes to both models)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def predict_keras(model_path, x_batch):\n",
    "    model = load_model(model_path)\n",
    "    prob = float(np.squeeze(model.predict(x_batch, verbose=0)))\n",
    "    return prob\n",
    "\n",
    "def predict_tflite(model_path, x_batch):\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    in_det  = interpreter.get_input_details()[0]\n",
    "    out_det = interpreter.get_output_details()[0]\n",
    "\n",
    "    x = x_batch\n",
    "    if in_det[\"dtype\"] == np.uint8:\n",
    "        scale, zp = in_det[\"quantization\"]\n",
    "        if scale == 0: scale, zp = 1.0, 0\n",
    "        x = np.round(x / scale + zp).astype(np.uint8)\n",
    "    else:\n",
    "        x = x.astype(np.float32)\n",
    "\n",
    "    if list(in_det[\"shape\"]) != list(x.shape):\n",
    "        interpreter.resize_tensor_input(in_det[\"index\"], x.shape, strict=False)\n",
    "        interpreter.allocate_tensors()\n",
    "\n",
    "    interpreter.set_tensor(in_det[\"index\"], x)\n",
    "    interpreter.invoke()\n",
    "    y = interpreter.get_tensor(out_det[\"index\"]).astype(np.float32)\n",
    "\n",
    "    if out_det[\"dtype\"] == np.uint8:\n",
    "        scale, zp = out_det[\"quantization\"]\n",
    "        if scale == 0: scale, zp = 1.0, 0\n",
    "        y = scale * (y - zp)\n",
    "\n",
    "    prob = float(np.squeeze(y))\n",
    "    # If your TFLite head outputs logits, apply sigmoid:\n",
    "    # prob = 1.0 / (1.0 + np.exp(-prob))\n",
    "    return prob\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Run end-to-end: YOLO crop -> chop feet -> pad+resize -> predict both\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(image_path)\n",
    "if not os.path.exists(keras_model_path):\n",
    "    raise FileNotFoundError(keras_model_path)\n",
    "if not os.path.exists(tflite_path):\n",
    "    raise FileNotFoundError(tflite_path)\n",
    "if not os.path.exists(yolo_weights):\n",
    "    raise FileNotFoundError(yolo_weights)\n",
    "\n",
    "x = yolo_crop_and_chop(\n",
    "    image_path=image_path,\n",
    "    yolo_weights=yolo_weights,\n",
    "    feet_ratio=feet_ratio,\n",
    "    margin_ratio=margin_ratio,\n",
    "    target_size=target_size,\n",
    "    pad_color=pad_color\n",
    ")\n",
    "\n",
    "# TFLite\n",
    "tfl_prob = predict_tflite(tflite_path, x)\n",
    "tfl_pred = \"Good\" if tfl_prob > threshold else \"Bad\"\n",
    "\n",
    "# Keras\n",
    "kr_prob = predict_keras(keras_model_path, x)\n",
    "kr_pred = \"Good\" if kr_prob > threshold else \"Bad\"\n",
    "\n",
    "# Print side-by-side\n",
    "print(f\"Image: {image_path}\")\n",
    "print(\"—— TFLite ———————————————\")\n",
    "print(f\"P(Good): {tfl_prob:.4f} | Pred: {tfl_pred} (thr={threshold})\")\n",
    "print(\"—— Keras ————————————————\")\n",
    "print(f\"P(Good): {kr_prob:.4f} | Pred: {kr_pred} (thr={threshold})\")\n",
    "print(\"—— Compare ——————————————\")\n",
    "print(f\"Δ Prob (TFLite−Keras): {tfl_prob - kr_prob:+.4f}\")\n",
    "print(f\"Agreement: {tfl_pred == kr_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# ====== Paths (edit these) ======\n",
    "test_dir = \"/Users/suzetteschulenburg/Desktop/MainUse/Test\"  # must contain Good/ and Bad/\n",
    "keras_model_path = \"/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras\"\n",
    "tflite_path = \"/Users/suzetteschulenburg/Desktop/Wag/cow_model.tflite\"\n",
    "out_csv = \"/Users/suzetteschulenburg/Desktop/test_predictions_no_yolo.csv\"\n",
    "\n",
    "# ====== Settings ======\n",
    "target_size = (224, 224)\n",
    "threshold = 0.5\n",
    "classes = {\"Good\": 1, \"Bad\": 0}  # ground-truth mapping\n",
    "valid_exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n",
    "\n",
    "# ====== Load models once ======\n",
    "assert os.path.exists(keras_model_path), f\"Missing Keras model: {keras_model_path}\"\n",
    "keras_model = load_model(keras_model_path)\n",
    "\n",
    "assert os.path.exists(tflite_path), f\"Missing TFLite model: {tflite_path}\"\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "tflite_interpreter.allocate_tensors()\n",
    "tfl_in = tflite_interpreter.get_input_details()[0]\n",
    "tfl_out = tflite_interpreter.get_output_details()[0]\n",
    "\n",
    "# ====== Helpers ======\n",
    "def load_image_resize_only(path, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load image, convert to RGB, simple bilinear resize to `size`, scale to [0,1],\n",
    "    and add batch dim: (1, H, W, 3). This matches your single-image sanity script.\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\").resize(size, Image.BILINEAR)\n",
    "    arr = np.asarray(img, dtype=np.float32) / 255.0\n",
    "    return arr[None, ...]  # (1, H, W, 3)\n",
    "\n",
    "def predict_keras_batch(x_batch):\n",
    "    prob = float(np.squeeze(keras_model.predict(x_batch, verbose=0)))\n",
    "    return prob\n",
    "\n",
    "def predict_tflite_batch(x_batch):\n",
    "    # Handle quantized or float TFLite inputs\n",
    "    x = x_batch\n",
    "    if tfl_in[\"dtype\"] == np.uint8:\n",
    "        scale, zp = tfl_in[\"quantization\"]\n",
    "        if scale == 0: scale, zp = 1.0, 0\n",
    "        x = np.round(x / scale + zp).astype(np.uint8)\n",
    "    else:\n",
    "        x = x.astype(np.float32)\n",
    "\n",
    "    # Resize TFLite input if needed\n",
    "    if list(tfl_in[\"shape\"]) != list(x.shape):\n",
    "        tflite_interpreter.resize_tensor_input(tfl_in[\"index\"], x.shape, strict=False)\n",
    "        tflite_interpreter.allocate_tensors()\n",
    "\n",
    "    tflite_interpreter.set_tensor(tfl_in[\"index\"], x)\n",
    "    tflite_interpreter.invoke()\n",
    "    y = tflite_interpreter.get_tensor(tfl_out[\"index\"]).astype(np.float32)\n",
    "\n",
    "    # Dequantize output if needed\n",
    "    if tfl_out[\"dtype\"] == np.uint8:\n",
    "        scale, zp = tfl_out[\"quantization\"]\n",
    "        if scale == 0: scale, zp = 1.0, 0\n",
    "        y = scale * (y - zp)\n",
    "\n",
    "    prob = float(np.squeeze(y))\n",
    "    # If your TFLite outputs logits, uncomment:\n",
    "    # prob = 1.0 / (1.0 + np.exp(-prob))\n",
    "    return prob\n",
    "\n",
    "def iter_images(root):\n",
    "    for label_name, label in classes.items():\n",
    "        folder = os.path.join(root, label_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        for ext in valid_exts:\n",
    "            for path in glob.glob(os.path.join(folder, f\"*{ext}\")):\n",
    "                yield path, label_name, label\n",
    "\n",
    "# ====== Run over test set (no YOLO; images are already cropped) ======\n",
    "rows = []\n",
    "y_true = []\n",
    "y_pred_keras = []\n",
    "y_pred_tfl = []\n",
    "\n",
    "for img_path, label_name, label in iter_images(test_dir):\n",
    "    try:\n",
    "        x = load_image_resize_only(img_path, target_size)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping unreadable image: {img_path} ({e})\")\n",
    "        continue\n",
    "\n",
    "    # Predict\n",
    "    p_keras = predict_keras_batch(x)\n",
    "    p_tfl = predict_tflite_batch(x)\n",
    "    pred_keras = 1 if p_keras > threshold else 0\n",
    "    pred_tfl = 1 if p_tfl > threshold else 0\n",
    "    agree = (pred_keras == pred_tfl)\n",
    "\n",
    "    # Collect\n",
    "    rows.append([img_path, label_name, label, p_keras, pred_keras, p_tfl, pred_tfl, agree])\n",
    "    y_true.append(label)\n",
    "    y_pred_keras.append(pred_keras)\n",
    "    y_pred_tfl.append(pred_tfl)\n",
    "\n",
    "# ====== Metrics ======\n",
    "def metrics(y_true, y_pred, tag):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    print(f\"\\n📊 {tag} — Test Metrics\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "    print(f\"Precision: {pre:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    return acc, f1, pre, rec\n",
    "\n",
    "if y_true:\n",
    "    acc_k, f1_k, pre_k, rec_k = metrics(y_true, y_pred_keras, \"Keras\")\n",
    "    acc_t, f1_t, pre_t, rec_t = metrics(y_true, y_pred_tfl,  \"TFLite\")\n",
    "\n",
    "    agreement_rate = float(np.mean([r[-1] for r in rows]))\n",
    "    prob_delta = [r[5] - r[3] for r in rows]  # TFLite - Keras\n",
    "    mean_abs_delta = float(np.mean(np.abs(prob_delta)))\n",
    "\n",
    "    print(\"\\n🤝 Model Agreement\")\n",
    "    print(f\"Agreement rate: {agreement_rate:.4f}\")\n",
    "    print(f\"Mean |Δ prob| (TFLite−Keras): {mean_abs_delta:.4f}\")\n",
    "else:\n",
    "    print(\"No images found under Good/ or Bad/ in the test_dir.\")\n",
    "\n",
    "# ====== Save CSV ======\n",
    "os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n",
    "with open(out_csv, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"image_path\", \"label_name\", \"label_int\",\n",
    "                \"keras_prob\", \"keras_pred\",\n",
    "                \"tflite_prob\", \"tflite_pred\",\n",
    "                \"agree\"])\n",
    "    w.writerows(rows)\n",
    "\n",
    "print(f\"\\n✅ Done. Wrote per-image results to:\\n{out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Directories ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "\n",
    "# === Map folds to models (all evaluate on same test set)\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load test set once ===\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model on the test set ===\n",
    "metrics = []\n",
    "for fold, model_name in folds.items():\n",
    "    print(f\"\\n📂 Evaluating Fold {fold} Model on Test Set\")\n",
    "    \n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds)\n",
    "    prec = precision_score(y_test, y_preds)\n",
    "    rec = recall_score(y_test, y_preds)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'AUC-PR': auc_pr\n",
    "    })\n",
    "\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC-PR   : {auc_pr:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# === Print average and std metrics ===\n",
    "print(\"\\n📊 Average and Std Dev of Test Metrics Across Folds:\")\n",
    "keys = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']\n",
    "for key in keys:\n",
    "    values = [m[key] for m in metrics]\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values)\n",
    "    print(f\"{key}: {mean:.4f} ± {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show predictions per cattle ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir  = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "fold1_model_name = 'model_fold2345_val1_frozen.keras'\n",
    "\n",
    "# === Load test images ===\n",
    "def load_test_images(image_dir):\n",
    "    images, labels, fnames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                fpath = os.path.join(full_path, fname)\n",
    "                img = load_img(fpath, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "                fnames.append(fname)\n",
    "    return np.array(images), np.array(labels), fnames\n",
    "\n",
    "# === Load test set ===\n",
    "X_test, y_test, file_names = load_test_images(test_dir)\n",
    "\n",
    "# === Load Fold 1 model ===\n",
    "model_path = os.path.join(model_dir, fold1_model_name)\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Predict ===\n",
    "y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "\n",
    "# === Show predictions for each image ===\n",
    "print(\"\\n📋 Predictions for Fold 1 model on Test Set:\")\n",
    "print(f\"{'Image':<50} {'True':>5} {'Confidence (%)':>15}\")\n",
    "print(\"-\" * 80)\n",
    "for fname, true_label, prob in zip(file_names, y_test, y_probs):\n",
    "    confidence = prob * 100  # convert to percentage\n",
    "    print(f\"{fname:<50} {true_label:>5} {confidence:>14.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# ==== Paths ====\n",
    "input_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test/Bad' \n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "fold1_model_name = 'model_fold2345_val1_frozen.keras'\n",
    "yolo_weights = '/Users/suzetteschulenburg/Desktop/Wag/Code/app2/app/cow_api/yolov8s-seg.pt'  # same as server.py location\n",
    "\n",
    "# Images to process (just these four)\n",
    "target_images = [\n",
    "    'CSS19912_IMG_9251.jpg',\n",
    "    'CSS19912_IMG_9250.jpg',\n",
    "    'CSS19912_IMG_9249.jpg',\n",
    "    'CSS19912_IMG_9248.jpg',\n",
    "]\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# === Resize with padding (white background), EXACTLY like server.py ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_h, old_w = image.shape[:2]\n",
    "    scale = float(desired_size) / max(old_h, old_w)\n",
    "    new_h, new_w = int(old_h * scale), int(old_w * scale)\n",
    "    resized = cv2.resize(image, (new_w, new_h))\n",
    "    delta_w, delta_h = desired_size - new_w, desired_size - new_h\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "    return cv2.copyMakeBorder(\n",
    "        resized, top, bottom, left, right,\n",
    "        cv2.BORDER_CONSTANT, value=[255, 255, 255]  # white\n",
    "    )\n",
    "\n",
    "# === YOLO preprocessing: segment, mask background white, crop with margin, remove bottom 30%, pad/resize ===\n",
    "def preprocess_image_with_yolo_from_path(image_path, yolo_model):\n",
    "    # Read with PIL (server.py uses PIL → np.array)\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    pil_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    image_rgb = np.array(pil_image)\n",
    "    H, W = image_rgb.shape[:2]\n",
    "\n",
    "    results = yolo_model(image_rgb)\n",
    "    if (not results) or (results[0].masks is None) or (len(results[0].masks.data) == 0):\n",
    "        raise ValueError(\"No cow detected in the image.\")\n",
    "\n",
    "    masks = results[0].masks\n",
    "    boxes = results[0].boxes\n",
    "    names = results[0].names\n",
    "\n",
    "    # Choose largest detected 'cow' by area\n",
    "    best_idx, best_area = None, 0\n",
    "    for i, cls_id in enumerate(boxes.cls.cpu().numpy()):\n",
    "        cls_name = names[int(cls_id)]\n",
    "        if cls_name != \"cow\":\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        if area > best_area:\n",
    "            best_idx, best_area = i, area\n",
    "\n",
    "    if best_idx is None:\n",
    "        raise ValueError(\"No cow detected in the image.\")\n",
    "\n",
    "    # Build masked image (white background)\n",
    "    mask = masks.data[best_idx].cpu().numpy()\n",
    "    mask_resized = cv2.resize(mask, (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "    mask_3 = np.stack([mask_resized] * 3, axis=-1)\n",
    "    masked = np.where(mask_3 > 0.5, image_rgb, 255)\n",
    "\n",
    "    # Crop to bbox with +10% margin, then remove bottom 30%\n",
    "    x1, y1, x2, y2 = map(int, boxes.xyxy[best_idx].cpu().numpy())\n",
    "    margin = 0.1\n",
    "    x1 = max(0, x1 - int((x2 - x1) * margin))\n",
    "    x2 = min(W, x2 + int((x2 - x1) * margin))\n",
    "    # remove bottom 30%\n",
    "    y2 = y1 + int((y2 - y1) * 0.7)\n",
    "    y1 = max(0, y1); y2 = min(H, y2)\n",
    "\n",
    "    cropped = masked[y1:y2, x1:x2]\n",
    "    resized = resize_with_padding(cropped, desired_size=IMG_SIZE).astype(np.float32) / 255.0\n",
    "    return np.expand_dims(resized, axis=0)  # (1,224,224,3)\n",
    "\n",
    "# ==== Load models ====\n",
    "yolo = YOLO(yolo_weights)\n",
    "keras_model = load_model(os.path.join(model_dir, fold1_model_name))\n",
    "\n",
    "# ==== Run ====\n",
    "print(\"\\n📋 Predictions (YOLO seg → server.py preprocessing → Fold 1 Keras):\")\n",
    "print(f\"{'Image':<35} {'P(Good)%':>10} {'Pred':>7} {'MaxConf%':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name in target_images:\n",
    "    img_path = os.path.join(input_dir, name)\n",
    "    try:\n",
    "        x = preprocess_image_with_yolo_from_path(img_path, yolo)  # (1,224,224,3)\n",
    "    except Exception as e:\n",
    "        print(f\"{name:<35} {'-':>10} {'Error':>7} {str(e):>10}\")\n",
    "        continue\n",
    "\n",
    "    p_good = float(keras_model.predict(x, verbose=0).flatten()[0]) * 100.0\n",
    "    pred = 'Good' if p_good >= 50.0 else 'Bad'\n",
    "    max_conf = p_good if p_good >= 50.0 else (100.0 - p_good)\n",
    "\n",
    "    print(f\"{name:<35} {p_good:>10.2f} {pred:>7} {max_conf:>10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority Cows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Directories ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "\n",
    "# === Map folds to models\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load test images with filenames and labels\n",
    "def load_test_images(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                fpath = os.path.join(path, fname)\n",
    "                img = load_img(fpath, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "                filenames.append(fname)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "# === Extract cow ID for voting\n",
    "def get_individual_id(filename):\n",
    "    return filename.split('_')[0]  # Example: \"ABC123\" from \"ABC123_1_IMG_4567.jpg\"\n",
    "\n",
    "# === Load test set once\n",
    "X_test, y_test, test_filenames = load_test_images(test_dir)\n",
    "\n",
    "# === Evaluate each model\n",
    "metrics = []\n",
    "for fold, model_file in folds.items():\n",
    "    print(f\"\\n📂 Evaluating Fold {fold} with Majority Voting\")\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    # === Organize by individual\n",
    "    indiv_preds = defaultdict(list)\n",
    "    indiv_labels = {}\n",
    "\n",
    "    for pred, label, fname in zip(y_preds, y_test, test_filenames):\n",
    "        indiv_id = get_individual_id(fname)\n",
    "        indiv_preds[indiv_id].append(pred)\n",
    "        indiv_labels[indiv_id] = label  # Assumes all images of individual have same label\n",
    "\n",
    "    final_preds = []\n",
    "    final_labels = []\n",
    "\n",
    "    for indiv_id in indiv_preds:\n",
    "        votes = indiv_preds[indiv_id]\n",
    "        majority_vote = int(np.round(np.mean(votes)))\n",
    "        final_preds.append(majority_vote)\n",
    "        final_labels.append(indiv_labels[indiv_id])\n",
    "\n",
    "    # === Metrics\n",
    "    acc = accuracy_score(final_labels, final_preds)\n",
    "    f1 = f1_score(final_labels, final_preds)\n",
    "    prec = precision_score(final_labels, final_preds)\n",
    "    rec = recall_score(final_labels, final_preds)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(final_labels, final_preds)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'F1 Score': f1,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'AUC-PR': auc_pr\n",
    "    })\n",
    "\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC-PR   : {auc_pr:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# === Summary\n",
    "print(\"\\n📊 Average and Std Dev of Metrics Across Folds (Majority Vote):\")\n",
    "for key in ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']:\n",
    "    values = [m[key] for m in metrics]\n",
    "    print(f\"{key}: {np.mean(values):.4f} ± {np.std(values):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority Bulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load test images with filenames and IDs ===\n",
    "def load_images_labels_and_ids(image_dir):\n",
    "    images, labels, filenames, ids = [], [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        subdir_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(subdir_path):\n",
    "            continue\n",
    "        for fname in os.listdir(subdir_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "                # Extract ID from filename (e.g., abc123_1.jpg → abc123)\n",
    "                id_part = fname.split('_')[0]\n",
    "                ids.append(id_part)\n",
    "    return np.array(images), np.array(labels), np.array(filenames), np.array(ids)\n",
    "\n",
    "X_test, y_test, filenames, ids = load_images_labels_and_ids(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model with majority voting per individual ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Evaluating Fold {fold} with majority vote per individual\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # === Group predictions and labels by ID ===\n",
    "    id_to_preds = defaultdict(list)\n",
    "    id_to_true = {}\n",
    "\n",
    "    for pred, true, cow_id in zip(y_pred, y_test, ids):\n",
    "        id_to_preds[cow_id].append(pred)\n",
    "        id_to_true[cow_id] = true  # assumes all images of same cow have same label\n",
    "\n",
    "    # === Apply majority vote per individual ===\n",
    "    y_true_individuals = []\n",
    "    y_pred_individuals = []\n",
    "\n",
    "    for cow_id in sorted(id_to_preds.keys()):\n",
    "        preds = id_to_preds[cow_id]\n",
    "        vote = Counter(preds).most_common(1)[0][0]\n",
    "        y_pred_individuals.append(vote)\n",
    "        y_true_individuals.append(id_to_true[cow_id])\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_true_individuals, y_pred_individuals)\n",
    "    f1 = f1_score(y_true_individuals, y_pred_individuals)\n",
    "    precision = precision_score(y_true_individuals, y_pred_individuals)\n",
    "    recall = recall_score(y_true_individuals, y_pred_individuals)\n",
    "    conf_mat = confusion_matrix(y_true_individuals, y_pred_individuals)\n",
    "\n",
    "    print(f\"📊 Fold {fold} Test Metrics (Majority Vote per Individual):\")\n",
    "    print(f\"Individuals Evaluated: {len(y_true_individuals)}\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, confusion_matrix,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load test images with filenames and IDs ===\n",
    "def load_images_labels_and_ids(image_dir):\n",
    "    images, labels, filenames, ids = [], [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        subdir_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(subdir_path):\n",
    "            continue\n",
    "        for fname in os.listdir(subdir_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "                id_part = fname.split('_')[0]  # e.g. BTB12345 from BTB12345_1_IMG.jpg\n",
    "                ids.append(id_part)\n",
    "    return np.array(images), np.array(labels), np.array(filenames), np.array(ids)\n",
    "\n",
    "X_test, y_test, filenames, ids = load_images_labels_and_ids(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model with majority voting per individual ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Evaluating Fold {fold} with majority vote per individual\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # === Group predictions and labels by ID ===\n",
    "    id_to_probs = defaultdict(list)\n",
    "    id_to_preds = defaultdict(list)\n",
    "    id_to_true = {}\n",
    "\n",
    "    for prob, pred, true, cow_id in zip(y_pred_probs, y_pred, y_test, ids):\n",
    "        id_to_probs[cow_id].append(prob)\n",
    "        id_to_preds[cow_id].append(pred)\n",
    "        id_to_true[cow_id] = true  # assumes all images of same cow have same label\n",
    "\n",
    "    # === Apply majority vote per individual ===\n",
    "    y_true_individuals = []\n",
    "    y_pred_individuals = []\n",
    "    y_prob_individuals = []\n",
    "\n",
    "    for cow_id in sorted(id_to_preds.keys()):\n",
    "        preds = id_to_preds[cow_id]\n",
    "        avg_prob = np.mean(id_to_probs[cow_id])\n",
    "        vote = Counter(preds).most_common(1)[0][0]\n",
    "\n",
    "        y_pred_individuals.append(vote)\n",
    "        y_true_individuals.append(id_to_true[cow_id])\n",
    "        y_prob_individuals.append(avg_prob)\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_true_individuals, y_pred_individuals)\n",
    "    f1 = f1_score(y_true_individuals, y_pred_individuals)\n",
    "    precision = precision_score(y_true_individuals, y_pred_individuals)\n",
    "    recall = recall_score(y_true_individuals, y_pred_individuals)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_true_individuals, y_prob_individuals)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "    conf_mat = confusion_matrix(y_true_individuals, y_pred_individuals)\n",
    "\n",
    "    print(f\"📊 Fold {fold} Test Metrics (Majority Vote per Individual):\")\n",
    "    print(f\"Individuals Evaluated: {len(y_true_individuals)}\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "# === Convert metrics to DataFrame for plotting\n",
    "plot_data = []\n",
    "\n",
    "for m in metrics:\n",
    "    for metric_name in ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']:\n",
    "        plot_data.append({\n",
    "            'Fold': f\"Fold {m['Fold']}\",\n",
    "            'Metric': metric_name,\n",
    "            'Value': m[metric_name]\n",
    "        })\n",
    "\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "# === Determine bottom y-limit and cap top at 1.0\n",
    "vmin = df_plot['Value'].min()\n",
    "buffer = 0.05\n",
    "ylim_low = max(0.0, vmin - buffer)\n",
    "\n",
    "# === Plot violin plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.violinplot(x='Metric', y='Value', data=df_plot, inner='point', palette='muted')\n",
    "plt.title('Distribution of Evaluation Metrics Across Folds')\n",
    "plt.ylim(ylim_low, 1.0)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === Prepare DataFrame\n",
    "plot_data = []\n",
    "for m in metrics:\n",
    "    for metric_name in ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']:\n",
    "        plot_data.append({\n",
    "            'Fold': f\"Fold {m['Fold']}\",\n",
    "            'Metric': metric_name,\n",
    "            'Value': m[metric_name]\n",
    "        })\n",
    "\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "# === Better Bubble Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_plot,\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    size='Value',\n",
    "    hue='Fold',\n",
    "    sizes=(100, 600),\n",
    "    alpha=0.7,\n",
    "    palette='deep'\n",
    ")\n",
    "\n",
    "plt.title('Evaluation Metrics per Fold (Bubble Size = Metric Value)')\n",
    "plt.ylim(0.5, 1.05)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === Convert to heatmap-style DataFrame\n",
    "heatmap_data = pd.DataFrame([\n",
    "    {\n",
    "        'Fold': f\"Fold {m['Fold']}\",\n",
    "        'Accuracy': m['Accuracy'],\n",
    "        'F1 Score': m['F1 Score'],\n",
    "        'Precision': m['Precision'],\n",
    "        'Recall': m['Recall'],\n",
    "        'AUC-PR': m['AUC-PR']\n",
    "    }\n",
    "    for m in metrics\n",
    "]).set_index('Fold')\n",
    "\n",
    "# === Plot heatmap\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='Blues', fmt='.3f', cbar=True)\n",
    "plt.title('Evaluation Metrics Across Folds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === Setup\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load test images\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Collect confusion matrices\n",
    "conf_matrices = []\n",
    "\n",
    "for fold, model_name in folds.items():\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_probs >= 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append((fold, cm))\n",
    "\n",
    "# === Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i, (fold, cm) in enumerate(conf_matrices):\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax, square=True,\n",
    "                annot_kws={\"size\": 10})\n",
    "    ax.set_title(f'Fold {fold}')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    ax.set_xticklabels(['Bad', 'Good'], fontsize=8)\n",
    "    ax.set_yticklabels(['Bad', 'Good'], fontsize=8, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Confusion Matrices for Each Fold (Threshold = 0.5)', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === Setup\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test2'\n",
    "\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load test images\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Collect confusion matrices\n",
    "conf_matrices = []\n",
    "\n",
    "for fold, model_name in folds.items():\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_probs >= 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append((fold, cm))\n",
    "\n",
    "# === Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i, (fold, cm) in enumerate(conf_matrices):\n",
    "    ax = axes[i]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax, square=True,\n",
    "                annot_kws={\"size\": 10})\n",
    "    ax.set_title(f'Fold {fold}')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "    ax.set_xticklabels(['Bad', 'Good'], fontsize=8)\n",
    "    ax.set_yticklabels(['Bad', 'Good'], fontsize=8, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Confusion Matrices for Each Fold (Threshold = 0.5)', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === Setup\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load test images\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Collect and print confusion matrices\n",
    "conf_matrices = []\n",
    "\n",
    "print(\"\\n📊 Confusion Matrices (Threshold = 0.5):\")\n",
    "print(\"Fold\\tConfusion Matrix [TN, FP] [FN, TP]\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "for fold, model_name in folds.items():\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_probs >= 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrices.append((fold, cm))\n",
    "\n",
    "    # Print confusion matrix in one line\n",
    "    cm_flat = f\"[{cm[0].tolist()}] [{cm[1].tolist()}]\"\n",
    "    print(f\"{fold}\\t{cm_flat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "\n",
    "folds = {\n",
    "    1: 'model_fold2345_val1_frozen.keras',\n",
    "    2: 'model_fold1345_val2_frozen.keras',\n",
    "    3: 'model_fold1245_val3_frozen.keras',\n",
    "    4: 'model_fold1235_val4_frozen.keras',\n",
    "    5: 'model_fold1234_val5_frozen.keras'\n",
    "}\n",
    "\n",
    "# === Load test set\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        folder = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(folder): continue\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(folder, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Collect predictions from all models\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "for fold, model_file in folds.items():\n",
    "    print(f\"📂 Evaluating Fold {fold} Model...\")\n",
    "    model_path = os.path.join(model_dir, model_file)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found: {model_file}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    all_probs.extend(y_probs)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "# === Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "all_probs = np.array(all_probs)\n",
    "all_labels = np.array(all_labels * len(folds))  # repeated labels for each model\n",
    "\n",
    "for i in range(len(all_probs)):\n",
    "    color = 'green' if all_labels[i] == 1 else 'red'\n",
    "    plt.scatter(i, all_probs[i], color=color, alpha=0.6)\n",
    "\n",
    "plt.axhline(y=0.5, linestyle='--', color='black', label='Threshold = 0.5')\n",
    "plt.title('Scatter Plot of Predicted Probabilities on Test Set (All 5 Models)')\n",
    "plt.xlabel('Sample Index (across folds)')\n",
    "plt.ylabel('Predicted Probability')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct and incorrect images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "\n",
    "# === Load images with labels and paths\n",
    "def load_images_and_labels_with_paths(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        folder = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                fpath = os.path.join(folder, fname)\n",
    "                img = load_img(fpath, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "                paths.append(fpath)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, img_paths = load_images_and_labels_with_paths(test_dir)\n",
    "\n",
    "# === Predict\n",
    "model = load_model(model_path)\n",
    "y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Collect image paths by category\n",
    "categories = {\n",
    "    'TP (Correct Good)': [],\n",
    "    'TN (Correct Bad)': [],\n",
    "    'FP (Incorrect Good)': [],\n",
    "    'FN (Incorrect Bad)': []\n",
    "}\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    true = y_test[i]\n",
    "    pred = y_pred[i]\n",
    "    path = img_paths[i]\n",
    "\n",
    "    if true == 1 and pred == 1:\n",
    "        categories['TP (Correct Good)'].append(path)\n",
    "    elif true == 0 and pred == 0:\n",
    "        categories['TN (Correct Bad)'].append(path)\n",
    "    elif true == 0 and pred == 1:\n",
    "        categories['FP (Incorrect Good)'].append(path)\n",
    "    elif true == 1 and pred == 0:\n",
    "        categories['FN (Incorrect Bad)'].append(path)\n",
    "\n",
    "# === Randomly pick one from each\n",
    "selected_paths = {\n",
    "    label: random.choice(paths) if paths else None\n",
    "    for label, paths in categories.items()\n",
    "}\n",
    "\n",
    "# === Plot\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i, (label, path) in enumerate(selected_paths.items()):\n",
    "    if path is not None:\n",
    "        img = load_img(path, target_size=(224, 224))\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(label, fontsize=10)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        print(f\"⚠️ No image found for category: {label}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep all layers frozen VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [1e-6]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [5e-6]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [1e-5]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [5e-5]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [1e-4]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "    # Freeze all layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Directory ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates and exact filenames ===\n",
    "learning_rates = ['1e-06', '5e-06', '1e-05', '5e-05', '0.0001']\n",
    "colors = ['orange', 'purple', 'blue', 'green', 'red']  # match number of LRs\n",
    "\n",
    "# === Set up figure with 2 subplots ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# === Plot Accuracy ===\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    filename = f'history_fold1_lr{lr}.pkl'\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        axes[0].plot(hist['accuracy'], linestyle='-', color=color, alpha=0.6, label=f'Train Acc (LR={lr})')\n",
    "        axes[0].plot(hist['val_accuracy'], linestyle='--', color=color, label=f'Val Acc (LR={lr})')\n",
    "    else:\n",
    "        print(f\"⚠️ Missing: {filename}\")\n",
    "axes[0].set_title('Training and Validation Accuracy per Learning Rate')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "# === Plot Loss ===\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    filename = f'history_fold1_lr{lr}.pkl'\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        axes[1].plot(hist['loss'], linestyle='-', color=color, alpha=0.6, label=f'Train Loss (LR={lr})')\n",
    "        axes[1].plot(hist['val_loss'], linestyle='--', color=color, label=f'Val Loss (LR={lr})')\n",
    "axes[1].set_title('Training and Validation Loss per Learning Rate')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Directory ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates ===\n",
    "learning_rates_str = ['1e-06', '5e-06', '1e-05', '5e-05', '0.0001']\n",
    "learning_rates = [float(lr) for lr in learning_rates_str]\n",
    "\n",
    "# === Extract best val accuracy and min val loss ===\n",
    "best_val_accuracies = []\n",
    "min_val_losses = []\n",
    "\n",
    "for lr_str in learning_rates_str:\n",
    "    filename = f'history_fold1_lr{lr_str}.pkl'\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        best_val_accuracies.append(max(hist['val_accuracy']))\n",
    "        min_val_losses.append(min(hist['val_loss']))\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file: {filename}\")\n",
    "        best_val_accuracies.append(None)\n",
    "        min_val_losses.append(None)\n",
    "\n",
    "# === Filter out None entries ===\n",
    "filtered_lrs = []\n",
    "filtered_accs = []\n",
    "filtered_losses = []\n",
    "\n",
    "for lr, acc, loss in zip(learning_rates, best_val_accuracies, min_val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# Convert to log-scale for interpolation\n",
    "x = np.log10(filtered_lrs)\n",
    "acc_y = filtered_accs\n",
    "loss_y = filtered_losses\n",
    "\n",
    "# Smooth x values\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "\n",
    "# Interpolated curves\n",
    "acc_smooth = make_interp_spline(x, acc_y, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, loss_y, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left y-axis)\n",
    "ax1.set_xlabel('Learning Rate (log scale)')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')  # smoothed curve (no label)\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue', label='Val Accuracy')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Loss (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Minimum Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')  # smoothed curve (no label)\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red', label='Val Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs Learning Rate')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get better lr graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [1e-4, 2e-4, 3e-4, 5e-4, 8e-4, 1e-3]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build model ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Train over multiple learning rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr:.0e}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr:.0e}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr:.0e} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Directory containing all history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates to include (full range) ===\n",
    "learning_rates_str = ['1e-06', '5e-06', '1e-05', '5e-05', '1e-04', '2e-04', '3e-04', '5e-04', '8e-04', '1e-03', '2e-3', '3e-3', '5e-3', '1e-2']\n",
    "learning_rates = [float(lr) for lr in learning_rates_str]\n",
    "\n",
    "# === Collect best val acc and min val loss from each file ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr_str in learning_rates_str:\n",
    "    filename = f'history_fold1_lr{lr_str}.pkl' if float(lr_str) < 1e-4 else f'history_fold1_lr{float(lr_str):.0e}.pkl'\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(min(hist['val_loss']))\n",
    "        print(f\"✅ Loaded: {filename} — Val Acc: {val_accuracies[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing file: {filename}\")\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for log-scale smoothing ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy\n",
    "ax1.set_xlabel('Learning Rate (log scale)')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "# Show all tested learning rates as ticks\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "\n",
    "\n",
    "# Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Minimum Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs Learning Rate (VGG16)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Directory containing all history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates to include ===\n",
    "learning_rates_str = ['1e-06', '5e-06', '1e-05', '5e-05', '1e-04', '2e-04', '3e-04', '5e-04', '8e-04', '1e-03']\n",
    "\n",
    "# === Initialize dicts to hold all histories ===\n",
    "all_histories = {}\n",
    "\n",
    "for lr_str in learning_rates_str:\n",
    "    lr_display = lr_str\n",
    "    filename = f'history_fold1_lr{lr_str}.pkl' if float(lr_str) < 1e-4 else f'history_fold1_lr{float(lr_str):.0e}.pkl'\n",
    "    path = os.path.join(history_dir, filename)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "            all_histories[lr_display] = hist\n",
    "            print(f\"✅ Loaded: {filename}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing: {filename}\")\n",
    "\n",
    "# === Plot Accuracy ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "for lr_str, hist in all_histories.items():\n",
    "    plt.plot(hist['val_accuracy'], label=f'Val Acc - {lr_str}')\n",
    "    plt.plot(hist['accuracy'], linestyle='--', label=f'Train Acc - {lr_str}')\n",
    "plt.title('Training and Validation Accuracy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Plot Loss ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "for lr_str, hist in all_histories.items():\n",
    "    plt.plot(hist['val_loss'], label=f'Val Loss - {lr_str}')\n",
    "    plt.plot(hist['loss'], linestyle='--', label=f'Train Loss - {lr_str}')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more lr in diirection of 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [2e-3, 3e-3, 5e-3, 1e-2]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build model ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Train over multiple learning rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr:.0e}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr:.0e}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr:.0e} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do more LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1.5e-2, # 0.015\n",
    "    2e-2,   # 0.020\n",
    "    3e-2,   # 0.030\n",
    "    5e-2,   # 0.050\n",
    "    7e-2,   # 0.070\n",
    "    1e-1    # 0.100 – be cautious, may explode\n",
    "]\n",
    "\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build model ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2–5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Train over multiple learning rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_lr{lr:.0e}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_lr{lr:.0e}.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr:.0e} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Directory containing all history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates to include (full range) ===\n",
    "learning_rates_str = [\n",
    "    '1e-06', '5e-06', '1e-05', '5e-05', '1e-04',\n",
    "    '2e-04', '3e-04', '5e-04', '8e-04', '1e-03',\n",
    "    '2e-03', '3e-03', '5e-03', '1e-02', \n",
    "    '1.5e-02', '2e-02', '3e-02', '5e-02', '7e-02', '1e-01'\n",
    "]\n",
    "learning_rates = [float(lr) for lr in learning_rates_str]\n",
    "\n",
    "# === Collect best val acc and average val loss from each file ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr_str in learning_rates_str:\n",
    "    try:\n",
    "        float_lr = float(lr_str)\n",
    "        filename = f'history_fold1_lr{float_lr:.0e}.pkl'\n",
    "    except:\n",
    "        filename = f'history_fold1_lr{lr_str}.pkl'\n",
    "\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))  # ← Average instead of min\n",
    "        print(f\"✅ Loaded: {filename} — Val Acc: {val_accuracies[-1]:.4f}, Avg Val Loss: {val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing file: {filename}\")\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for log-scale smoothing ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# ✅ Show only a few learning rate ticks\n",
    "num_ticks_to_show = 6\n",
    "tick_indices = np.round(np.linspace(0, len(filtered_lrs) - 1, num_ticks_to_show)).astype(int)\n",
    "selected_lrs = filtered_lrs[tick_indices]\n",
    "ax1.set_xticks(selected_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.1e}\" for lr in selected_lrs], rotation=60)\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (VGG16)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Directory containing all history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates to include (full range) ===\n",
    "learning_rates_str = [\n",
    "    '1e-06', '5e-06', '1e-05', '5e-05', '1e-04',\n",
    "    '2e-04', '3e-04', '5e-04', '8e-04', '1e-03',\n",
    "    '2e-03', '3e-03', '5e-03', '1e-02', \n",
    "    '1.5e-02', '2e-02', '3e-02', '5e-02', '7e-02', '1e-01'\n",
    "]\n",
    "learning_rates = [float(lr) for lr in learning_rates_str]\n",
    "\n",
    "# === Collect best val acc and average val loss from each file ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr_str in learning_rates_str:\n",
    "    try:\n",
    "        float_lr = float(lr_str)\n",
    "        filename = f'history_fold1_lr{float_lr:.0e}.pkl'\n",
    "    except:\n",
    "        filename = f'history_fold1_lr{lr_str}.pkl'\n",
    "\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))  # ← Average instead of min\n",
    "        print(f\"✅ Loaded: {filename} — Val Acc: {val_accuracies[-1]:.4f}, Avg Val Loss: {val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing file: {filename}\")\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for log-scale smoothing ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# ✅ Show only a few learning rate ticks\n",
    "num_ticks_to_show = 6\n",
    "tick_indices = np.round(np.linspace(0, len(filtered_lrs) - 1, num_ticks_to_show)).astype(int)\n",
    "selected_lrs = filtered_lrs[tick_indices]\n",
    "ax1.set_xticks(selected_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.1e}\" for lr in selected_lrs], rotation=60)\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (VGG16)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import LogLocator, LogFormatterSciNotation\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Directory containing all history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates (2e-3 removed) ===\n",
    "learning_rates_str = [\n",
    "    '1e-06', '5e-06', '1e-05', '5e-05', '1e-04',\n",
    "    '2e-04', '3e-04', '5e-04', '8e-04', '1e-03',\n",
    "    '2e-03',  \n",
    "    '3e-03', '5e-03', '1e-02', \n",
    "    '1.5e-02', '2e-02', '3e-02', '5e-02', '7e-02', '1e-01'\n",
    "]\n",
    "learning_rates = [float(lr) for lr in learning_rates_str]\n",
    "\n",
    "# === Collect best val acc and average val loss from each file ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr_str in learning_rates_str:\n",
    "    try:\n",
    "        float_lr = float(lr_str)\n",
    "        filename = f'history_fold1_lr{float_lr:.0e}.pkl'\n",
    "    except:\n",
    "        filename = f'history_fold1_lr{lr_str}.pkl'\n",
    "\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))\n",
    "        print(f\"✅ Loaded: {filename} — Val Acc: {val_accuracies[-1]:.4f}, Avg Val Loss: {val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing file: {filename}\")\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for log-scale smoothing ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Accuracy (left axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Validation Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.xaxis.set_major_locator(LogLocator(base=10.0, numticks=10))\n",
    "ax1.xaxis.set_minor_locator(LogLocator(base=10.0, subs='auto', numticks=50))\n",
    "ax1.xaxis.set_major_formatter(LogFormatterSciNotation())\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (VGG16)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Directory containing your saved history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Learning rates to plot from 2e-3 to 1e-1 ===\n",
    "selected_lrs = [\n",
    "    2e-3, 3e-3, 5e-3, 1e-2, 1.5e-2, 2e-2, 3e-2, 5e-2, 7e-2, 1e-1\n",
    "]\n",
    "\n",
    "# === Store all histories\n",
    "all_histories = {}\n",
    "\n",
    "for lr in selected_lrs:\n",
    "    filename = f'history_fold1_lr{lr:.0e}.pkl'\n",
    "    path = os.path.join(history_dir, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "        all_histories[lr] = history\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file: {filename}\")\n",
    "\n",
    "# === Plot accuracy (all LRs)\n",
    "plt.figure(figsize=(12, 5))\n",
    "for lr, hist in all_histories.items():\n",
    "    plt.plot(hist['accuracy'], linestyle='--', label=f'Train {lr:.0e}')\n",
    "    plt.plot(hist['val_accuracy'], label=f'Val {lr:.0e}')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Plot loss (all LRs)\n",
    "plt.figure(figsize=(12, 5))\n",
    "for lr, hist in all_histories.items():\n",
    "    plt.plot(hist['loss'], linestyle='--', label=f'Train {lr:.0e}')\n",
    "    plt.plot(hist['val_loss'], label=f'Val {lr:.0e}')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics per learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, auc, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input  # ✅ Added this\n",
    "\n",
    "# === Directories ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "\n",
    "# === Learning rates and plotting colors ===\n",
    "learning_rates = ['1e-06', '5e-06', '1e-05', '5e-05', '0.0001']\n",
    "colors = ['orange', 'purple', 'blue', 'green', 'red']\n",
    "\n",
    "# === Load validation data with proper VGG preprocessing ===\n",
    "def load_validation_data(val_dir):\n",
    "    X_val, y_val = [], []\n",
    "    for label in ['Good', 'Bad']:\n",
    "        label_dir = os.path.join(val_dir, label)\n",
    "        if not os.path.exists(label_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(label_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img = load_img(os.path.join(label_dir, fname), target_size=(224, 224))\n",
    "                img_array = preprocess_input(img_to_array(img))  # ✅ Use VGG16 preprocessing\n",
    "                X_val.append(img_array)\n",
    "                y_val.append(1 if label == 'Good' else 0)\n",
    "    return np.array(X_val), np.array(y_val)\n",
    "\n",
    "X_val, y_val = load_validation_data(val_dir)\n",
    "\n",
    "# === Set up figure ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "print(\"📊 Validation Metrics Summary (Fold 1):\\n\")\n",
    "\n",
    "# === Plotting and metrics evaluation ===\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    history_path = os.path.join(history_dir, f'history_fold1_lr{lr}.pkl')\n",
    "    model_path = os.path.join(model_dir, f'model_fold1_lr{lr}.keras')\n",
    "\n",
    "    if os.path.exists(history_path) and os.path.exists(model_path):\n",
    "        # Load history\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        # Plot accuracy\n",
    "        axes[0].plot(hist['accuracy'], linestyle='-', color=color, alpha=0.6, label=f'Train Acc (LR={lr})')\n",
    "        axes[0].plot(hist['val_accuracy'], linestyle='--', color=color, label=f'Val Acc (LR={lr})')\n",
    "\n",
    "        # Plot loss\n",
    "        axes[1].plot(hist['loss'], linestyle='-', color=color, alpha=0.6, label=f'Train Loss (LR={lr})')\n",
    "        axes[1].plot(hist['val_loss'], linestyle='--', color=color, label=f'Val Loss (LR={lr})')\n",
    "\n",
    "        # Load model and predict\n",
    "        model = load_model(model_path)\n",
    "        y_pred_probs = model.predict(X_val).flatten()\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        # Compute metrics\n",
    "        acc = accuracy_score(y_val, y_pred_labels)\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "        # Display\n",
    "        print(f\"🟢 LR {lr}\")\n",
    "        print(f\"   Accuracy  : {acc:.4f}\")\n",
    "        print(f\"   F1 Score  : {f1:.4f}\")\n",
    "        print(f\"   Precision : {precision:.4f}\")\n",
    "        print(f\"   Recall    : {recall:.4f}\")\n",
    "        print(f\"   AUC-PR    : {auc_pr:.4f}\\n\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing files for LR {lr}\")\n",
    "\n",
    "# === Final plot settings ===\n",
    "axes[0].set_title('Training and Validation Accuracy per Learning Rate')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_title('Training and Validation Loss per Learning Rate')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get val losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === Directories ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "\n",
    "# === Learning rates and plotting colors ===\n",
    "learning_rates = ['1e-06', '5e-06', '1e-05', '5e-05', '0.0001']\n",
    "colors = ['orange', 'purple', 'blue', 'green', 'red']\n",
    "\n",
    "# === Load validation data (optional for full consistency, even if unused) ===\n",
    "def load_validation_data(val_dir):\n",
    "    X_val, y_val = [], []\n",
    "    for label in ['Good', 'Bad']:\n",
    "        label_dir = os.path.join(val_dir, label)\n",
    "        if not os.path.exists(label_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(label_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img = load_img(os.path.join(label_dir, fname), target_size=(224, 224))\n",
    "                img_array = preprocess_input(img_to_array(img))\n",
    "                X_val.append(img_array)\n",
    "                y_val.append(1 if label == 'Good' else 0)\n",
    "    return np.array(X_val), np.array(y_val)\n",
    "\n",
    "X_val, y_val = load_validation_data(val_dir)\n",
    "\n",
    "# === Set up figure ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "avg_val_losses = []\n",
    "\n",
    "print(\"📊 Average Validation Loss per Learning Rate (Fold 1):\\n\")\n",
    "\n",
    "# === Plotting and average val loss summary ===\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    history_path = os.path.join(history_dir, f'history_fold1_lr{lr}.pkl')\n",
    "    model_path = os.path.join(model_dir, f'model_fold1_lr{lr}.keras')\n",
    "\n",
    "    if os.path.exists(history_path) and os.path.exists(model_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        # Plot accuracy\n",
    "        axes[0].plot(hist['accuracy'], linestyle='-', color=color, alpha=0.6, label=f'Train Acc (LR={lr})')\n",
    "        axes[0].plot(hist['val_accuracy'], linestyle='--', color=color, label=f'Val Acc (LR={lr})')\n",
    "\n",
    "        # Plot loss\n",
    "        axes[1].plot(hist['loss'], linestyle='-', color=color, alpha=0.6, label=f'Train Loss (LR={lr})')\n",
    "        axes[1].plot(hist['val_loss'], linestyle='--', color=color, label=f'Val Loss (LR={lr})')\n",
    "\n",
    "        # Compute average val loss\n",
    "        avg_val = np.mean(hist['val_loss'])\n",
    "        avg_val_losses.append(avg_val)\n",
    "        print(f\"🟢 LR {lr} → Avg Val Loss: {avg_val:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing files for LR {lr}\")\n",
    "\n",
    "# === Final plot settings ===\n",
    "axes[0].set_title('Training and Validation Accuracy per Learning Rate')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_title('Training and Validation Loss per Learning Rate')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Print overall average of all avg val losses\n",
    "if avg_val_losses:\n",
    "    overall_avg = np.mean(avg_val_losses)\n",
    "    print(f\"\\n📉 Overall Average of Avg Val Losses: {overall_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take best lr and train 5 folds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold1')  # ✅ Use Fold1 as validation set\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [2e-3]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 2, 3, 4, and 5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in [2, 3, 4, 5]:  # ✅ Exclude Fold1 from training\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 1...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold1_val_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold1_val_lr{lr}.pkl')  # ✅ Save history with Fold1 label\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold2')  # Changed from Fold1 to Fold2\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [2e-3]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 1, 3, 4, and 5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 3, 4, 5]:  # Changed to exclude Fold2 from training\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 2...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold2_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold2_lr{lr}.pkl')  # Updated filename\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold3')  # Validation set is Fold 3\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [2e-3]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 1, 2, 4, and 5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 2, 4, 5]:  # Exclude Fold 3 from training\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 3...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold3_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold3_lr{lr}.pkl')  # Updated filename\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold4')  # Validation set is Fold 4\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [2e-3]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 1, 2, 3, and 5...\")\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 2, 3, 5]:  # Exclude Fold 4 from training\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 4...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold4_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold4_lr{lr}.pkl')  # Updated filename\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold_dir = os.path.join(base_fold_dir, 'Fold5')  # Validation set is Fold 5\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "learning_rates = [2e-3]\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_vgg16_model(image_shape, learning_rate):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load datasets ===\n",
    "print(\"🔄 Loading training data from Folds 1, 2, 3, and 4...\")\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 2, 3, 4]:  # Exclude Fold 5 from training\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(\"📥 Loading validation data from Fold 5...\")\n",
    "X_val, y_val = load_images_and_labels(val_fold_dir)\n",
    "\n",
    "# === Training ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_vgg16_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7, verbose=1),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_fold5_lr{lr}.keras'), save_best_only=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    history_path = os.path.join(history_save_dir, f'history_fold5_lr{lr}.pkl')  # Updated filename\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"✅ LR {lr} — Val Acc: {val_acc*100:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === Directory settings ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Models_VGGFrozen'\n",
    "val_base_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "metrics_dict = {\n",
    "    'Accuracy': [],\n",
    "    'F1 Score': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'AUC-PR': []\n",
    "}\n",
    "\n",
    "# === Function to load validation images ===\n",
    "def load_val_data(fold_num):\n",
    "    fold_dir = os.path.join(val_base_dir, f'Fold{fold_num}')\n",
    "    X, y = [], []\n",
    "    for label_name in ['Good', 'Bad']:\n",
    "        label_dir = os.path.join(fold_dir, label_name)\n",
    "        label = 1 if label_name == 'Good' else 0\n",
    "        for fname in os.listdir(label_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(label_dir, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_arr = img_to_array(img)\n",
    "                img_arr = preprocess_input(img_arr)\n",
    "                X.append(img_arr)\n",
    "                y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === Evaluate each fold ===\n",
    "for fold in folds:\n",
    "    print(f\"📁 Evaluating Fold {fold}\")\n",
    "    \n",
    "    # Adjust model filename for Fold 1\n",
    "    if fold == 1:\n",
    "        model_filename = 'model_fold1_val_lr0.002.keras'\n",
    "    else:\n",
    "        model_filename = f'model_fold{fold}_lr0.002.keras'\n",
    "    \n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"❌ Model not found: {model_path}\")\n",
    "        continue\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load validation data\n",
    "    X_val, y_val = load_val_data(fold)\n",
    "\n",
    "    # Predict\n",
    "    probs = model.predict(X_val).flatten()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    f1 = f1_score(y_val, preds)\n",
    "    prec = precision_score(y_val, preds)\n",
    "    rec = recall_score(y_val, preds)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, probs)\n",
    "    auprc = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Store\n",
    "    metrics_dict['Accuracy'].append(acc)\n",
    "    metrics_dict['F1 Score'].append(f1)\n",
    "    metrics_dict['Precision'].append(prec)\n",
    "    metrics_dict['Recall'].append(rec)\n",
    "    metrics_dict['AUC-PR'].append(auprc)\n",
    "\n",
    "    # Print\n",
    "    print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, AUC-PR: {auprc:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# === Print Average and Std ===\n",
    "print(\"\\n📊 Average Metrics Across Folds:\")\n",
    "for metric, values in metrics_dict.items():\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    print(f\"{metric}: {mean_val:.4f} ± {std_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Directory where history files are saved ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Fold numbers and learning rate used ===\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "learning_rate = '0.002'  # format string, no scientific notation\n",
    "\n",
    "def load_history(fold):\n",
    "    if fold == 1:\n",
    "        filename = f'history_fold1_val_lr{learning_rate}.pkl'\n",
    "    else:\n",
    "        filename = f'history_fold{fold}_lr{learning_rate}.pkl'\n",
    "    file_path = os.path.join(history_save_dir, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"❌ History file not found for Fold {fold}: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color='blue', alpha=0.6, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color='red', alpha=0.6, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Loss Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'])\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], color='blue', alpha=0.6, label=f'Fold {fold} Train Acc' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', color='red', alpha=0.6, label=f'Fold {fold} Val Acc' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Accuracy Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'])\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Load all histories ===\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    history = load_history(fold)\n",
    "    if history:\n",
    "        fold_histories[fold] = history\n",
    "\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"🚫 No valid history files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Directory where history files are saved ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Saved_Histories_VGGFrozen'\n",
    "\n",
    "# === Folds and learning rate ===\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "learning_rate = '0.002'\n",
    "\n",
    "def load_history(fold):\n",
    "    if fold == 1:\n",
    "        filename = f'history_fold1_val_lr{learning_rate}.pkl'\n",
    "    else:\n",
    "        filename = f'history_fold{fold}_lr{learning_rate}.pkl'\n",
    "    path = os.path.join(history_save_dir, filename)\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"❌ History not found for Fold {fold}\")\n",
    "        return None\n",
    "\n",
    "# === Store metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "\n",
    "print(\"📊 Metrics per Fold:\\n\")\n",
    "for fold in folds:\n",
    "    history = load_history(fold)\n",
    "    if history:\n",
    "        val_acc = history['val_accuracy'][-1]\n",
    "        val_loss = history['val_loss'][-1]\n",
    "        train_acc = history['accuracy'][-1]\n",
    "        train_loss = history['loss'][-1]\n",
    "\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        print(f\"📁 Fold {fold}:\")\n",
    "        print(f\"   ✅ Val Accuracy:  {val_acc * 100:.2f}%\")\n",
    "        print(f\"   ✅ Val Loss:      {val_loss:.4f}\")\n",
    "        print(f\"   🏋️ Train Accuracy:{train_acc * 100:.2f}%\")\n",
    "        print(f\"   🏋️ Train Loss:    {train_loss:.4f}\")\n",
    "        print()\n",
    "\n",
    "# === Mean and Std Dev ===\n",
    "print(\"📈 Average Metrics Across Folds:\")\n",
    "print(f\"🔹 Mean Val Accuracy : {np.mean(val_accuracies) * 100:.2f}% ± {np.std(val_accuracies) * 100:.2f}%\")\n",
    "print(f\"🔹 Mean Val Loss     : {np.mean(val_losses):.4f} ± {np.std(val_losses):.4f}\")\n",
    "print(f\"🔹 Mean Train Accuracy : {np.mean(train_accuracies) * 100:.2f}% ± {np.std(train_accuracies) * 100:.2f}%\")\n",
    "print(f\"🔹 Mean Train Loss     : {np.mean(train_losses):.4f} ± {np.std(train_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# === Paths ===\n",
    "base_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_dir = os.path.join(base_dir, 'Saved_Models_VGGFrozen')\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "lr = '0.002'\n",
    "\n",
    "# === Load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Store metrics ===\n",
    "all_metrics = []\n",
    "\n",
    "print(\"📊 Evaluation Metrics per Fold:\\n\")\n",
    "\n",
    "for fold in folds:\n",
    "    # Load validation data\n",
    "    val_dir = os.path.join(base_dir, f'Fold{fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load model\n",
    "    if fold == 1:\n",
    "        model_path = os.path.join(model_dir, f'model_fold1_val_lr{lr}.keras')\n",
    "    else:\n",
    "        model_path = os.path.join(model_dir, f'model_fold{fold}_lr{lr}.keras')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"❌ Model for Fold {fold} not found.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_val, verbose=0).flatten()\n",
    "    y_pred = (y_probs >= 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred)\n",
    "    rec = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    prc_prec, prc_rec, _ = precision_recall_curve(y_val, y_probs)\n",
    "    auc_pr = auc(prc_rec, prc_prec)\n",
    "\n",
    "    all_metrics.append([acc, prec, rec, f1, auc_pr])\n",
    "\n",
    "    print(f\"📁 Fold {fold}\")\n",
    "    print(f\"   Accuracy : {acc*100:.2f}%\")\n",
    "    print(f\"   Precision: {prec:.4f}\")\n",
    "    print(f\"   Recall   : {rec:.4f}\")\n",
    "    print(f\"   F1 Score : {f1:.4f}\")\n",
    "    print(f\"   AUC-PR   : {auc_pr:.4f}\")\n",
    "    print()\n",
    "\n",
    "# === Mean ± Std ===\n",
    "all_metrics = np.array(all_metrics)\n",
    "mean = np.mean(all_metrics, axis=0)\n",
    "std = np.std(all_metrics, axis=0)\n",
    "\n",
    "print(\"📈 Average Metrics Across Folds:\")\n",
    "print(f\"🔹 Accuracy : {mean[0]*100:.2f}% ± {std[0]*100:.2f}%\")\n",
    "print(f\"🔹 Precision: {mean[1]:.4f} ± {std[1]:.4f}\")\n",
    "print(f\"🔹 Recall   : {mean[2]:.4f} ± {std[2]:.4f}\")\n",
    "print(f\"🔹 F1 Score : {mean[3]:.4f} ± {std[3]:.4f}\")\n",
    "print(f\"🔹 AUC-PR   : {mean[4]:.4f} ± {std[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffrent image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPre'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPre'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [1e-3, 5e-4]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === History Directories ===\n",
    "history_dir_base = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCropped'\n",
    "history_dir_more_layers = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedMoreLayers'\n",
    "history_dir_pre = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPre'\n",
    "\n",
    "# === Configs: learning rate, color, label, linestyle, source dir\n",
    "configs = [\n",
    "    # 1e-3\n",
    "    {'lr': 1e-3, 'color': 'royalblue', 'label': 'Base LR=1e-3', 'style': '-', 'dir': history_dir_base},\n",
    "    {'lr': 1e-3, 'color': 'navy', 'label': 'More Layers LR=1e-3', 'style': '--', 'dir': history_dir_more_layers},\n",
    "    {'lr': 1e-3, 'color': 'teal', 'label': 'Preprocessed LR=1e-3', 'style': ':', 'dir': history_dir_pre},\n",
    "    \n",
    "    # 5e-4\n",
    "    {'lr': 5e-4, 'color': 'darkorange', 'label': 'Base LR=5e-4', 'style': '-', 'dir': history_dir_base},\n",
    "    {'lr': 5e-4, 'color': 'firebrick', 'label': 'More Layers LR=5e-4', 'style': '--', 'dir': history_dir_more_layers},\n",
    "    {'lr': 5e-4, 'color': 'seagreen', 'label': 'Preprocessed LR=5e-4', 'style': ':', 'dir': history_dir_pre},\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "# === Accuracy Plot ===\n",
    "plt.subplot(1, 2, 1)\n",
    "for cfg in configs:\n",
    "    path = os.path.join(cfg['dir'], f'history_resnet_lr{cfg[\"lr\"]}_fold1.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        plt.plot(hist['val_accuracy'], linestyle=cfg['style'], color=cfg['color'], linewidth=2, label=f'{cfg[\"label\"]} (Val)')\n",
    "        plt.plot(hist['accuracy'], linestyle=cfg['style'], color=cfg['color'], alpha=0.3, label=f'{cfg[\"label\"]} (Train)')\n",
    "plt.title('Accuracy per Epoch', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.legend(fontsize=10, loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "# === Loss Plot ===\n",
    "plt.subplot(1, 2, 2)\n",
    "for cfg in configs:\n",
    "    path = os.path.join(cfg['dir'], f'history_resnet_lr{cfg[\"lr\"]}_fold1.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        plt.plot(hist['val_loss'], linestyle=cfg['style'], color=cfg['color'], linewidth=2, label=f'{cfg[\"label\"]} (Val)')\n",
    "        plt.plot(hist['loss'], linestyle=cfg['style'], color=cfg['color'], alpha=0.3, label=f'{cfg[\"label\"]} (Train)')\n",
    "plt.title('Loss per Epoch', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(fontsize=10, loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment lr with correct preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [1e-6]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [5e-4]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [1e-3]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do 0.01 and 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [5e-2, 1e-2]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Directory ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "\n",
    "# === Learning rates and their exact filename representations ===\n",
    "learning_rates = ['0.001', '0.0005', '0.0001', '1e-05', '5e-05', '5e-06', '1e-06']\n",
    "colors = ['brown', 'black', 'red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# === Plot Accuracy ===\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        # Plot only first 100 epochs\n",
    "        axes[0].plot(hist['accuracy'][:100], linestyle='-', color=color, alpha=0.6, label=f'Train Acc (LR={lr})')\n",
    "        axes[0].plot(hist['val_accuracy'][:100], linestyle='--', color=color, label=f'Val Acc (LR={lr})')\n",
    "axes[0].set_title('Training and Validation Accuracy (First 100 Epochs)')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].grid(True)\n",
    "axes[0].legend()\n",
    "\n",
    "# === Plot Loss ===\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        axes[1].plot(hist['loss'][:100], linestyle='-', color=color, alpha=0.6, label=f'Train Loss (LR={lr})')\n",
    "        axes[1].plot(hist['val_loss'][:100], linestyle='--', color=color, label=f'Val Loss (LR={lr})')\n",
    "axes[1].set_title('Training and Validation Loss (First 100 Epochs)')\n",
    "axes[1].set_xlabel('Epochs')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Directory with ResNet histories ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "\n",
    "# === Learning rates and filenames ===\n",
    "\n",
    "learning_rates_str =  ['0.001', '0.0005', '0.0001', '1e-05', '5e-05', '5e-06', '1e-06']\n",
    "learning_rates = [float(lr) for lr in learning_rates_str]\n",
    "\n",
    "# === Extract best val acc and min val loss ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr_str in learning_rates_str:\n",
    "    path = os.path.join(history_dir, f'history_resnet_lr{lr_str}_fold1.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(min(hist['val_loss']))\n",
    "        print(f\"✅ LR={lr_str}: Val Acc={max(hist['val_accuracy']):.4f}, Val Loss={min(hist['val_loss']):.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file: {lr_str}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort by learning rate to ensure strictly increasing x ===\n",
    "sorted_indices = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_indices]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_indices]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_indices]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left y-axis)\n",
    "ax1.set_xlabel('Learning Rate (log scale)')\n",
    "ax1.set_ylabel('Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs Learning Rate (ResNet)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Directory ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "\n",
    "# === Learning rates and their exact filename representations ===\n",
    "learning_rates = ['0.0001', '0.0005', '0.001', '0.005', '0.01', '0.05']\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange', 'brown', 'teal', 'pink', 'cyan']\n",
    "\n",
    "# === Plot Accuracy ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        plt.plot(hist['accuracy'], linestyle='-', color=color, alpha=0.6, label=f'Train Acc (LR={lr})')\n",
    "        plt.plot(hist['val_accuracy'], linestyle='--', color=color, label=f'Val Acc (LR={lr})')\n",
    "plt.title('Training and Validation Accuracy per Learning Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Plot Loss ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "for lr, color in zip(learning_rates, colors):\n",
    "    path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        plt.plot(hist['loss'], linestyle='-', color=color, alpha=0.6, label=f'Train Loss (LR={lr})')\n",
    "        plt.plot(hist['val_loss'], linestyle='--', color=color, label=f'Val Loss (LR={lr})')\n",
    "plt.title('Training and Validation Loss per Learning Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Settings ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "learning_rates = ['0.001', '0.0005', '0.0001', '1e-05', '5e-05', '5e-06', '1e-06']\n",
    "\n",
    "# === Helper function to load images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path): continue\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = preprocess_input(img_to_array(img))\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load validation data ===\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Evaluation loop (validation only) ===\n",
    "for lr in learning_rates:\n",
    "    model_path = os.path.join(model_dir, f'model_resnet_lr{lr}_fold1.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model for LR={lr} not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # === Evaluate on validation set ===\n",
    "    probs = model.predict(X_val, verbose=0).flatten()\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    f1 = f1_score(y_val, preds)\n",
    "    prec = precision_score(y_val, preds)\n",
    "    rec = recall_score(y_val, preds)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_val, probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    print(f\"📊 Validation Metrics for LR={lr}\")\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  F1 Score : {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  AUC-PR   : {auc_pr:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_metrics = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    file_path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        min_val_loss = min(hist['val_loss'])\n",
    "        avg_val_loss = sum(hist['val_loss']) / len(hist['val_loss'])\n",
    "        final_train_loss = hist['loss'][-1]\n",
    "        loss_metrics.append((lr, round(min_val_loss, 4), round(avg_val_loss, 4), round(final_train_loss, 4)))\n",
    "    else:\n",
    "        loss_metrics.append((lr, 'missing', 'missing', 'missing'))\n",
    "\n",
    "# === Display Updated Results ===\n",
    "print(f\"{'LR':<10} {'Min Val Loss':<15} {'Avg Val Loss':<15} {'Final Train Loss'}\")\n",
    "print(\"-\" * 55)\n",
    "for lr, min_loss, avg_loss, train_loss in loss_metrics:\n",
    "    print(f\"{lr:<10} {min_loss:<15} {avg_loss:<15} {train_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get better graph per lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [1e-5, 2e-5, 3e-5, 5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 5e-4, 7e-4, 1e-3]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Directory with saved history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "\n",
    "# === Same learning rates used in training ===\n",
    "learning_rates = [1e-5, 2e-5, 3e-5, 5e-5, 7e-5, 1e-4, 1.5e-4, 2e-4, 3e-4, 5e-4, 7e-4, 1e-3]\n",
    "\n",
    "# === Collect best val accuracy and min val loss per LR ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    file_path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "        best_val_acc = max(history['val_accuracy'])\n",
    "        min_val_loss = min(history['val_loss'])\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(min_val_loss)\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={best_val_acc:.4f}, Val Loss={min_val_loss:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing history: {file_path}\")\n",
    "\n",
    "# === Filter out missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for safe interpolation ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot smoothed curves ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left y-axis)\n",
    "ax1.set_xlabel('Learning Rate (log scale)')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Add all learning rate ticks\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "\n",
    "# Loss (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Minimum Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs Learning Rate (ResNet50)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 1.5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [1.5e-4]\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get more LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    2e-3,   # 0.002\n",
    "    3e-3,   # 0.003\n",
    "    5e-3,   # 0.005\n",
    "    7e-3,   # 0.007\n",
    "    1e-2,   # 0.010\n",
    "    1.5e-2, # 0.015\n",
    "    2e-2,   # 0.020\n",
    "    3e-2,   # 0.030\n",
    "    5e-2,   # 0.050\n",
    "    1e-1    # 0.100\n",
    "]\n",
    "\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcess'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1e-1 ,  \n",
    "    6e-2, 8e-2, 9e-2\n",
    "]\n",
    "\n",
    "\n",
    "# === Load function with preprocess_input ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))  # <== changed here\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "# === Run learning rate experiments ===\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "    model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Save history\n",
    "    with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate\n",
    "    val_preds = model.predict(X_val) > 0.5\n",
    "    val_f1 = f1_score(y_val, val_preds)\n",
    "    val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "    results[lr] = {'accuracy': val_acc * 100, 'f1_score': val_f1}\n",
    "    print(f\"✅ LR {lr} — Accuracy: {val_acc:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# === Plot Results ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(results.keys(), [r['accuracy'] for r in results.values()], marker='o', label='Accuracy (%)')\n",
    "plt.plot(results.keys(), [r['f1_score'] for r in results.values()], marker='s', label='F1 Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('ResNet50 Learning Rate vs Performance (Fold 1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Directory with saved history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "\n",
    "# === Same learning rates used in training ===\n",
    "learning_rates = [\n",
    "    1e-5,\n",
    "    2e-5,\n",
    "    3e-5,\n",
    "    5e-5,\n",
    "    7e-5,\n",
    "    1e-4,\n",
    "    1.5e-4,\n",
    "    2e-4,\n",
    "    3e-4,\n",
    "    5e-4,\n",
    "    7e-4,\n",
    "    1e-3,\n",
    "    2e-3,    # 0.002\n",
    "    3e-3,    # 0.003\n",
    "    5e-3,    # 0.005\n",
    "    7e-3,    # 0.007\n",
    "    1e-2,    # 0.010\n",
    "    1.5e-2,  # 0.015\n",
    "    2e-2,    # 0.020\n",
    "    3e-2,    # 0.030\n",
    "    5e-2,    # 0.050\n",
    "    6e-2,    # 0.060\n",
    "    7e-2,    # 0.070 (already tested, you can comment if reused)\n",
    "    8e-2,    # 0.080\n",
    "    9e-2,    # 0.090\n",
    "    1e-1     # 0.100\n",
    "]\n",
    "\n",
    "\n",
    "# === Collect best val accuracy and min val loss per LR ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    file_path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "        best_val_acc = max(history['val_accuracy'])\n",
    "        min_val_loss = min(history['val_loss'])\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(min_val_loss)\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={best_val_acc:.4f}, Val Loss={min_val_loss:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing history: {file_path}\")\n",
    "\n",
    "# === Filter out missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for safe interpolation ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot smoothed curves ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (left y-axis)\n",
    "ax1.set_xlabel('Learning Rate (log scale)')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Add all learning rate ticks\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "\n",
    "# Loss (right y-axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Minimum Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs Learning Rate (ResNet50)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Directory with saved history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "\n",
    "# === Learning rates used in training ===\n",
    "learning_rates = [\n",
    "    1e-5, 2e-5, 3e-5, 5e-5, 7e-5, 1e-4, 1.5e-4, 2e-4, 3e-4, 5e-4, 7e-4,\n",
    "    1e-3, 2e-3, 3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 3e-2, 5e-2, 6e-2, 7e-2, 8e-2, 9e-2\n",
    "]\n",
    "\n",
    "# === Collect best val accuracy and average val loss per LR ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    file_path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "        best_val_acc = max(history['val_accuracy'])\n",
    "        avg_val_loss = np.mean(history['val_loss'])  # Use average\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={best_val_acc:.4f}, Avg Val Loss={avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing history: {file_path}\")\n",
    "\n",
    "# === Filter out missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for interpolation ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Interpolate smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Left y-axis: Accuracy\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# ✅ Show only a few learning rates on x-axis\n",
    "num_ticks_to_show = 6\n",
    "tick_indices = np.round(np.linspace(0, len(filtered_lrs) - 1, num_ticks_to_show)).astype(int)\n",
    "selected_lrs = filtered_lrs[tick_indices]\n",
    "ax1.set_xticks(selected_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.1e}\" for lr in selected_lrs], rotation=60)\n",
    "\n",
    "# Right y-axis: Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (ResNet50)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "\n",
    "# === Directory with saved history files ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcess'\n",
    "\n",
    "# === Learning rates used in training ===\n",
    "learning_rates = [\n",
    "    1e-5, 2e-5, 3e-5, 5e-5, 7e-5, 1e-4, 1.5e-4, 2e-4, 3e-4, 5e-4, 7e-4,\n",
    "    1e-3, 2e-3, 3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 3e-2, 5e-2, 6e-2, 7e-2, 8e-2, 9e-2\n",
    "]\n",
    "\n",
    "# === Collect best val accuracy and average val loss per LR ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    file_path = os.path.join(history_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "        best_val_acc = max(history['val_accuracy'])\n",
    "        avg_val_loss = np.mean(history['val_loss'])  # Use average\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f\"✅ LR={lr:.0e}: Val Acc={best_val_acc:.4f}, Avg Val Loss={avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "        print(f\"⚠️ Missing history: {file_path}\")\n",
    "\n",
    "# === Filter out missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for interpolation ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Interpolate smooth curves ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Left y-axis: Accuracy\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# ✅ Show only a few learning rates on x-axis\n",
    "num_ticks_to_show = 6\n",
    "tick_indices = np.round(np.linspace(0, len(filtered_lrs) - 1, num_ticks_to_show)).astype(int)\n",
    "selected_lrs = filtered_lrs[tick_indices]\n",
    "ax1.set_xticks(selected_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.1e}\" for lr in selected_lrs], rotation=60)\n",
    "\n",
    "# Right y-axis: Loss\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (ResNet50)')\n",
    "plt.grid(True, which='both', axis='x')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take best Lr and do all 5 folds 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold1')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcessFina'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Load function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 2–5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in range(2, 6):\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "lr = 5e-4\n",
    "print(f\"\\n🚀 Training with Learning Rate = {lr}\")\n",
    "model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold1.keras'), save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# === Save history ===\n",
    "with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "val_preds = model.predict(X_val) > 0.5\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "print(f\"✅ Final Metrics for LR={lr}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2%}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold2')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcessFina'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Load function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 1, 3, 4, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 3, 4, 5]:\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 2) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "lr = 5e-4\n",
    "print(f\"\\n🚀 Training with Learning Rate = {lr} using Fold 2 as Validation Set\")\n",
    "model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold2.keras'), save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# === Save history ===\n",
    "with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold2.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "val_preds = model.predict(X_val) > 0.5\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "print(f\"✅ Final Metrics for LR={lr}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2%}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold3')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcessFina'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Load function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 1, 2, 4, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 2, 4, 5]:\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 3) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "lr = 5e-4\n",
    "print(f\"\\n🚀 Training with Learning Rate = {lr} using Fold 3 as Validation Set\")\n",
    "model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold3.keras'), save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# === Save history ===\n",
    "with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold3.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "val_preds = model.predict(X_val) > 0.5\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "print(f\"✅ Final Metrics for LR={lr}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2%}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold4')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcessFina'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Load function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 1, 2, 3, 5) ===\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 2, 3, 5]:\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 4) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "lr = 5e-4\n",
    "print(f\"\\n🚀 Training with Learning Rate = {lr} using Fold 4 as Validation Set\")\n",
    "model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold4.keras'), save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# === Save history ===\n",
    "with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold4.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "val_preds = model.predict(X_val) > 0.5\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "print(f\"✅ Final Metrics for LR={lr}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2%}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "val_fold = os.path.join(base_fold_dir, 'Fold5')\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcessFina'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(history_save_dir, exist_ok=True)\n",
    "\n",
    "# === Load function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Model builder ===\n",
    "def create_resnet50_model(image_shape, learning_rate):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Load Training Data (Folds 1, 2, 3, 4) ===\n",
    "X_train, y_train = [], []\n",
    "for i in [1, 2, 3, 4]:\n",
    "    images, labels = load_images_and_labels(os.path.join(base_fold_dir, f'Fold{i}'))\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 5) ===\n",
    "X_val, y_val = load_images_and_labels(val_fold)\n",
    "\n",
    "lr = 5e-4\n",
    "print(f\"\\n🚀 Training with Learning Rate = {lr} using Fold 5 as Validation Set\")\n",
    "model = create_resnet50_model(X_train.shape[1:], lr)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_save_dir, f'model_resnet_lr{lr}_fold5.keras'), save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# === Save history ===\n",
    "with open(os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold5.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "val_preds = model.predict(X_val) > 0.5\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "val_acc = np.mean(val_preds.flatten() == y_val)\n",
    "\n",
    "print(f\"✅ Final Metrics for LR={lr}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2%}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze 5 folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directories\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot Training and Validation Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], label=f'Fold {fold} Train Loss')\n",
    "        plt.plot(history['val_loss'], linestyle='--', label=f'Fold {fold} Val Loss')\n",
    "    plt.title('Training and Validation Loss Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], label=f'Fold {fold} Train Acc')\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', label=f'Fold {fold} Val Acc')\n",
    "    plt.title('Training and Validation Accuracy Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_history(fold):\n",
    "    file_path = os.path.join(history_save_dir, f'history_resnet_lr0.0005_fold{fold}.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"History file not found for Fold {fold}\")\n",
    "        return None\n",
    "\n",
    "# Load histories for all folds\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    history = load_history(fold)\n",
    "    if history:\n",
    "        fold_histories[fold] = history\n",
    "\n",
    "# Plot graphs\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"No valid history files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size\n",
    "    'axes.titlesize': 16,     # Title font size\n",
    "    'axes.labelsize': 16,     # Axis label font size\n",
    "    'xtick.labelsize': 16,    # X-tick label font size\n",
    "    'ytick.labelsize': 16,    # Y-tick label font size\n",
    "    'legend.fontsize': 16     # Legend font size (if you add one)\n",
    "})\n",
    "\n",
    "# Directories\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Define colors\n",
    "    train_color = 'blue'\n",
    "    val_color = 'red'\n",
    "\n",
    "    # Plot Training and Validation Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color=train_color, alpha=0.6, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color=val_color, alpha=0.6, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    \n",
    "    plt.title('Training and Validation Loss Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'])\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], color=train_color, alpha=0.6, label=f'Fold {fold} Train Acc' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', color=val_color, alpha=0.6, label=f'Fold {fold} Val Acc' if fold == 1 else \"\")\n",
    "    \n",
    "    plt.title('Training and Validation Accuracy Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'])\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_history(fold):\n",
    "    file_path = os.path.join(history_save_dir, f'history_resnet_lr0.0005_fold{fold}.pkl')\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"History file not found for Fold {fold}\")\n",
    "        return None\n",
    "\n",
    "# Load histories for all folds\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    history = load_history(fold)\n",
    "    if history:\n",
    "        fold_histories[fold] = history\n",
    "\n",
    "# Plot graphs\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"No valid history files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metrics val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcessFina'\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Metrics containers\n",
    "train_accuracies, train_losses = [], []\n",
    "val_accuracies, val_losses = [], []\n",
    "recalls, f1_scores, precisions, auc_prs = [], [], [], []\n",
    "\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): \n",
    "            continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "for fold in folds:\n",
    "    print(f\"\\n📦 Processing Fold {fold}\")\n",
    "\n",
    "    # Load validation data\n",
    "    val_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    if len(X_val) == 0:\n",
    "        print(f\"Fold {fold} - No validation data found.\")\n",
    "        continue\n",
    "\n",
    "    # Load the model\n",
    "    model_path = os.path.join(model_save_dir, f'model_resnet_lr0.0005_fold{fold}.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model for Fold {fold} not found.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Predict on validation data\n",
    "    y_val_pred = model.predict(X_val).flatten()\n",
    "\n",
    "    # Convert predictions to binary\n",
    "    y_pred_binary = (y_val_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_acc = accuracy_score(y_val, y_pred_binary)\n",
    "    recall = recall_score(y_val, y_pred_binary)\n",
    "    f1 = f1_score(y_val, y_pred_binary)\n",
    "    precision = precision_score(y_val, y_pred_binary)\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_val, y_val_pred)\n",
    "    auc_pr = auc(recall_curve, precision_curve)\n",
    "\n",
    "    # Store fold metrics\n",
    "    val_accuracies.append(val_acc)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    precisions.append(precision)\n",
    "    auc_prs.append(auc_pr)\n",
    "\n",
    "    # Print fold metrics\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "\n",
    "# Calculate and display averages\n",
    "if len(val_accuracies) > 0:\n",
    "    print(\"\\n📊 AVERAGE METRICS ACROSS FOLDS:\")\n",
    "    print(f\"Validation Accuracy - Avg: {np.mean(val_accuracies):.4f}, Std: {np.std(val_accuracies):.4f}\")\n",
    "    print(f\"Recall - Avg: {np.mean(recalls):.4f}, Std: {np.std(recalls):.4f}\")\n",
    "    print(f\"F1 Score - Avg: {np.mean(f1_scores):.4f}, Std: {np.std(f1_scores):.4f}\")\n",
    "    print(f\"Precision - Avg: {np.mean(precisions):.4f}, Std: {np.std(precisions):.4f}\")\n",
    "    print(f\"AUC-PR - Avg: {np.mean(auc_prs):.4f}, Std: {np.std(auc_prs):.4f}\")\n",
    "else:\n",
    "    print(\"No metrics available for calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw graph of metrics on val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc, log_loss\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Directories\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed'\n",
    "model_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_ExperimentsResNetCroppedPreProcessFina'\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCroppedPreProcessFina'\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Initialize metrics container\n",
    "metrics_data = {\n",
    "    'Fold': [],\n",
    "    'Val Accuracy': [],\n",
    "    'F1 Score': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'AUC-PR': [],\n",
    "    'Val Loss': []\n",
    "}\n",
    "\n",
    "def load_images_and_labels(image_dir):\n",
    "    \"\"\"Load images and labels from directory.\"\"\"\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_dir): \n",
    "            continue\n",
    "        for fname in os.listdir(full_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_dir, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_arr = preprocess_input(img_to_array(img))\n",
    "                images.append(img_arr)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Process each fold\n",
    "for fold in folds:\n",
    "    print(f\"Processing Fold {fold}...\")\n",
    "\n",
    "    val_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    model_path = os.path.join(model_save_dir, f'model_resnet_lr0.0005_fold{fold}.keras')\n",
    "    history_path = os.path.join(history_save_dir, f'history_resnet_lr0.0005_fold{fold}.pkl')\n",
    "\n",
    "    if not os.path.exists(model_path) or not os.path.exists(history_path):\n",
    "        print(f\"Missing model or history for Fold {fold}\")\n",
    "        continue\n",
    "\n",
    "    # Load model and data\n",
    "    model = load_model(model_path)\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_val).flatten()\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_acc = accuracy_score(y_val, y_pred_labels)\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "    val_loss = log_loss(y_val, y_pred_probs)\n",
    "\n",
    "    # Store metrics\n",
    "    metrics_data['Fold'].append(f'Fold {fold}')\n",
    "    metrics_data['Val Accuracy'].append(val_acc)\n",
    "    metrics_data['F1 Score'].append(f1)\n",
    "    metrics_data['Precision'].append(precision)\n",
    "    metrics_data['Recall'].append(recall)\n",
    "    metrics_data['AUC-PR'].append(auc_pr)\n",
    "    metrics_data['Val Loss'].append(val_loss)\n",
    "\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# === Plotting ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot Metrics\n",
    "ax1.plot(metrics_df['Fold'], metrics_df['Val Accuracy'], marker='o', linestyle='-', label='Val Accuracy', color='blue')\n",
    "ax1.plot(metrics_df['Fold'], metrics_df['F1 Score'], marker='o', linestyle='-', label='F1 Score', color='green')\n",
    "ax1.plot(metrics_df['Fold'], metrics_df['Precision'], marker='o', linestyle='-', label='Precision', color='red')\n",
    "ax1.plot(metrics_df['Fold'], metrics_df['Recall'], marker='o', linestyle='-', label='Recall', color='purple')\n",
    "ax1.plot(metrics_df['Fold'], metrics_df['AUC-PR'], marker='o', linestyle='-', label='AUC-PR', color='orange')\n",
    "\n",
    "ax1.set_xlabel('Fold')\n",
    "ax1.set_ylabel('Metrics')\n",
    "ax1.set_xticks(np.arange(len(metrics_df['Fold'])))\n",
    "ax1.set_xticklabels(metrics_df['Fold'])\n",
    "ax1.grid(alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Plot Validation Loss on Secondary Y-Axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(metrics_df['Fold'], metrics_df['Val Loss'], marker='o', linestyle='--', label='Val Loss', color='black')\n",
    "ax2.set_ylabel('Validation Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Metrics Across Folds with Validation Loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get yolo results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show images of YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# === Path to processed images ===\n",
    "base_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test'\n",
    "classes = ['Good', 'Bad']\n",
    "\n",
    "# === Collect all image paths ===\n",
    "all_images = []\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(base_path, cls)\n",
    "    image_files = [os.path.join(cls_path, fname) for fname in os.listdir(cls_path) if fname.endswith('.jpg')]\n",
    "    all_images.extend(image_files)\n",
    "\n",
    "# === Sample 5 random images ===\n",
    "sample_images = random.sample(all_images, 4)\n",
    "\n",
    "# === Plot the images ===\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for ax, img_path in zip(axs, sample_images):\n",
    "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(os.path.basename(img_path), fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do YOLO and manual segmentation for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # height, width\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# === Paths ===\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/E1886_IMG_8243.json'\n",
    "yolo_output_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Bad/E1886_IMG_8243_processed.jpg'\n",
    "\n",
    "# === Load YOLO output (already cropped and resized) ===\n",
    "yolo_img = cv2.cvtColor(cv2.imread(yolo_output_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Load LabelMe JSON and original image ===\n",
    "with open(labelme_json_path, 'r') as f:\n",
    "    labelme_data = json.load(f)\n",
    "original_img_path = os.path.join(os.path.dirname(labelme_json_path), labelme_data['imagePath'])\n",
    "original_img = Image.open(original_img_path)\n",
    "\n",
    "# === Create binary mask from LabelMe polygon ===\n",
    "labelme_mask = Image.new('L', original_img.size, 0)\n",
    "draw = ImageDraw.Draw(labelme_mask)\n",
    "for shape in labelme_data['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        draw.polygon(polygon, outline=1, fill=1)\n",
    "labelme_mask = np.array(labelme_mask) * 255\n",
    "\n",
    "# === Resize LabelMe mask to YOLO image size using padding ===\n",
    "resized_mask = resize_with_padding(labelme_mask, desired_size=224)\n",
    "\n",
    "# === Convert both to binary masks ===\n",
    "labelme_binary = (resized_mask > 127).astype(np.uint8)\n",
    "\n",
    "# Use the YOLO image to extract a binary mask (assumes white background)\n",
    "yolo_gray = cv2.cvtColor(yolo_img, cv2.COLOR_RGB2GRAY)\n",
    "yolo_mask = (yolo_gray < 250).astype(np.uint8)\n",
    "\n",
    "# === Compute IoU ===\n",
    "intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "iou = intersection / union if union != 0 else 0\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# === Visualization ===\n",
    "# Convert labelme mask to 3-channel for overlay\n",
    "resized_mask_rgb = np.stack([resized_mask]*3, axis=-1)\n",
    "\n",
    "overlay = cv2.addWeighted(yolo_img, 0.6, resized_mask_rgb, 0.4, 0)\n",
    "\n",
    "# === Show side-by-side comparison ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(yolo_img)\n",
    "axs[0].set_title(\"YOLO Cutout\")\n",
    "axs[1].imshow(resized_mask, cmap='gray')\n",
    "axs[1].set_title(\"Manual LabelMe Mask (Resized)\")\n",
    "axs[2].imshow(overlay)\n",
    "axs[2].set_title(\"Overlay Comparison\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # height, width\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# === Paths ===\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/CowsTestYOLO/YOLO/Bad/CSS19912_IMG_9248.json'\n",
    "yolo_output_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Bad/CSS19912_IMG_9248_processed.jpg'\n",
    "\n",
    "# === Load YOLO output (already cropped and resized) ===\n",
    "yolo_img = cv2.cvtColor(cv2.imread(yolo_output_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Load LabelMe JSON and original image ===\n",
    "with open(labelme_json_path, 'r') as f:\n",
    "    labelme_data = json.load(f)\n",
    "original_img_path = os.path.join(os.path.dirname(labelme_json_path), labelme_data['imagePath'])\n",
    "original_img = Image.open(original_img_path)\n",
    "\n",
    "# === Create binary mask from LabelMe polygon ===\n",
    "labelme_mask = Image.new('L', original_img.size, 0)\n",
    "draw = ImageDraw.Draw(labelme_mask)\n",
    "for shape in labelme_data['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        draw.polygon(polygon, outline=1, fill=1)\n",
    "labelme_mask = np.array(labelme_mask) * 255\n",
    "\n",
    "# === Resize LabelMe mask to YOLO image size using padding ===\n",
    "resized_mask = resize_with_padding(labelme_mask, desired_size=224)\n",
    "\n",
    "# === Convert both to binary masks ===\n",
    "labelme_binary = (resized_mask > 127).astype(np.uint8)\n",
    "\n",
    "# Use the YOLO image to extract a binary mask (assumes white background)\n",
    "yolo_gray = cv2.cvtColor(yolo_img, cv2.COLOR_RGB2GRAY)\n",
    "yolo_mask = (yolo_gray < 250).astype(np.uint8)\n",
    "\n",
    "# === Compute IoU ===\n",
    "intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "iou = intersection / union if union != 0 else 0\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# === Visualization ===\n",
    "# Convert labelme mask to 3-channel for overlay\n",
    "resized_mask_rgb = np.stack([resized_mask]*3, axis=-1)\n",
    "\n",
    "overlay = cv2.addWeighted(yolo_img, 0.6, resized_mask_rgb, 0.4, 0)\n",
    "\n",
    "# === Show side-by-side comparison ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(yolo_img)\n",
    "axs[0].set_title(\"YOLO Cutout\")\n",
    "axs[1].imshow(resized_mask, cmap='gray')\n",
    "axs[1].set_title(\"Manual LabelMe Mask (Resized)\")\n",
    "axs[2].imshow(overlay)\n",
    "axs[2].set_title(\"Overlay Comparison\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # height, width\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# === Paths ===\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/CSS19912_IMG_9248.json'\n",
    "yolo_output_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Bad/CSS19912_IMG_9248_processed.jpg'\n",
    "\n",
    "# === Load YOLO output (already cropped and resized) ===\n",
    "yolo_img = cv2.cvtColor(cv2.imread(yolo_output_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Load LabelMe JSON and original image ===\n",
    "with open(labelme_json_path, 'r') as f:\n",
    "    labelme_data = json.load(f)\n",
    "original_img_path = os.path.join(os.path.dirname(labelme_json_path), labelme_data['imagePath'])\n",
    "original_img = Image.open(original_img_path)\n",
    "\n",
    "# === Create binary mask from LabelMe polygon ===\n",
    "labelme_mask = Image.new('L', original_img.size, 0)\n",
    "draw = ImageDraw.Draw(labelme_mask)\n",
    "for shape in labelme_data['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        draw.polygon(polygon, outline=1, fill=1)\n",
    "labelme_mask = np.array(labelme_mask) * 255\n",
    "\n",
    "# === Resize LabelMe mask to YOLO image size using padding ===\n",
    "resized_mask = resize_with_padding(labelme_mask, desired_size=224)\n",
    "\n",
    "# === Convert both to binary masks ===\n",
    "labelme_binary = (resized_mask > 127).astype(np.uint8)\n",
    "\n",
    "# Use the YOLO image to extract a binary mask (assumes white background)\n",
    "yolo_gray = cv2.cvtColor(yolo_img, cv2.COLOR_RGB2GRAY)\n",
    "yolo_mask = (yolo_gray < 250).astype(np.uint8)\n",
    "\n",
    "# === Compute IoU ===\n",
    "intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "iou = intersection / union if union != 0 else 0\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# === Visualization ===\n",
    "# Convert labelme mask to 3-channel for overlay\n",
    "resized_mask_rgb = np.stack([resized_mask]*3, axis=-1)\n",
    "\n",
    "overlay = cv2.addWeighted(yolo_img, 0.6, resized_mask_rgb, 0.4, 0)\n",
    "\n",
    "# === Show side-by-side comparison ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(yolo_img)\n",
    "axs[0].set_title(\"YOLO Cutout\")\n",
    "axs[1].imshow(resized_mask, cmap='gray')\n",
    "axs[1].set_title(\"Manual LabelMe Mask (Resized)\")\n",
    "axs[2].imshow(overlay)\n",
    "axs[2].set_title(\"Overlay Comparison\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # height, width\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# === Paths ===\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/AK2015_IMG_9690.json'\n",
    "yolo_output_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Good/AK2015_IMG_9690_processed.jpg'\n",
    "\n",
    "# === Load YOLO output (already cropped and resized) ===\n",
    "yolo_img = cv2.cvtColor(cv2.imread(yolo_output_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Load LabelMe JSON and original image ===\n",
    "with open(labelme_json_path, 'r') as f:\n",
    "    labelme_data = json.load(f)\n",
    "original_img_path = os.path.join(os.path.dirname(labelme_json_path), labelme_data['imagePath'])\n",
    "original_img = Image.open(original_img_path)\n",
    "\n",
    "# === Create binary mask from LabelMe polygon ===\n",
    "labelme_mask = Image.new('L', original_img.size, 0)\n",
    "draw = ImageDraw.Draw(labelme_mask)\n",
    "for shape in labelme_data['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        draw.polygon(polygon, outline=1, fill=1)\n",
    "labelme_mask = np.array(labelme_mask) * 255\n",
    "\n",
    "# === Resize LabelMe mask to YOLO image size using padding ===\n",
    "resized_mask = resize_with_padding(labelme_mask, desired_size=224)\n",
    "\n",
    "# === Convert both to binary masks ===\n",
    "labelme_binary = (resized_mask > 127).astype(np.uint8)\n",
    "\n",
    "# Use the YOLO image to extract a binary mask (assumes white background)\n",
    "yolo_gray = cv2.cvtColor(yolo_img, cv2.COLOR_RGB2GRAY)\n",
    "yolo_mask = (yolo_gray < 250).astype(np.uint8)\n",
    "\n",
    "# === Compute IoU ===\n",
    "intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "iou = intersection / union if union != 0 else 0\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# === Visualization ===\n",
    "# Convert labelme mask to 3-channel for overlay\n",
    "resized_mask_rgb = np.stack([resized_mask]*3, axis=-1)\n",
    "\n",
    "overlay = cv2.addWeighted(yolo_img, 0.6, resized_mask_rgb, 0.4, 0)\n",
    "\n",
    "# === Show side-by-side comparison ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(yolo_img)\n",
    "axs[0].set_title(\"YOLO Cutout\")\n",
    "axs[1].imshow(resized_mask, cmap='gray')\n",
    "axs[1].set_title(\"Manual LabelMe Mask (Resized)\")\n",
    "axs[2].imshow(overlay)\n",
    "axs[2].set_title(\"Overlay Comparison\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # height, width\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# === Paths ===\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/JH1673_IMG_9572.json'\n",
    "yolo_output_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Bad/JH1673_IMG_9572_processed.jpg'\n",
    "\n",
    "# === Load YOLO output (already cropped and resized) ===\n",
    "yolo_img = cv2.cvtColor(cv2.imread(yolo_output_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Load LabelMe JSON and original image ===\n",
    "with open(labelme_json_path, 'r') as f:\n",
    "    labelme_data = json.load(f)\n",
    "original_img_path = os.path.join(os.path.dirname(labelme_json_path), labelme_data['imagePath'])\n",
    "original_img = Image.open(original_img_path)\n",
    "\n",
    "# === Create binary mask from LabelMe polygon ===\n",
    "labelme_mask = Image.new('L', original_img.size, 0)\n",
    "draw = ImageDraw.Draw(labelme_mask)\n",
    "for shape in labelme_data['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        draw.polygon(polygon, outline=1, fill=1)\n",
    "labelme_mask = np.array(labelme_mask) * 255\n",
    "\n",
    "# === Resize LabelMe mask to YOLO image size using padding ===\n",
    "resized_mask = resize_with_padding(labelme_mask, desired_size=224)\n",
    "\n",
    "# === Convert both to binary masks ===\n",
    "labelme_binary = (resized_mask > 127).astype(np.uint8)\n",
    "\n",
    "# Use the YOLO image to extract a binary mask (assumes white background)\n",
    "yolo_gray = cv2.cvtColor(yolo_img, cv2.COLOR_RGB2GRAY)\n",
    "yolo_mask = (yolo_gray < 250).astype(np.uint8)\n",
    "\n",
    "# === Compute IoU ===\n",
    "intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "iou = intersection / union if union != 0 else 0\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# === Visualization ===\n",
    "# Convert labelme mask to 3-channel for overlay\n",
    "resized_mask_rgb = np.stack([resized_mask]*3, axis=-1)\n",
    "\n",
    "overlay = cv2.addWeighted(yolo_img, 0.6, resized_mask_rgb, 0.4, 0)\n",
    "\n",
    "# === Show side-by-side comparison ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(yolo_img)\n",
    "axs[0].set_title(\"YOLO Cutout\")\n",
    "axs[1].imshow(resized_mask, cmap='gray')\n",
    "axs[1].set_title(\"Manual LabelMe Mask (Resized)\")\n",
    "axs[2].imshow(overlay)\n",
    "axs[2].set_title(\"Overlay Comparison\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # height, width\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# === Paths ===\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/WA1646_IMG_9669.json'\n",
    "yolo_output_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Good/WA1646_IMG_9669_processed.jpg'\n",
    "\n",
    "# === Load YOLO output (already cropped and resized) ===\n",
    "yolo_img = cv2.cvtColor(cv2.imread(yolo_output_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Load LabelMe JSON and original image ===\n",
    "with open(labelme_json_path, 'r') as f:\n",
    "    labelme_data = json.load(f)\n",
    "original_img_path = os.path.join(os.path.dirname(labelme_json_path), labelme_data['imagePath'])\n",
    "original_img = Image.open(original_img_path)\n",
    "\n",
    "# === Create binary mask from LabelMe polygon ===\n",
    "labelme_mask = Image.new('L', original_img.size, 0)\n",
    "draw = ImageDraw.Draw(labelme_mask)\n",
    "for shape in labelme_data['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        draw.polygon(polygon, outline=1, fill=1)\n",
    "labelme_mask = np.array(labelme_mask) * 255\n",
    "\n",
    "# === Resize LabelMe mask to YOLO image size using padding ===\n",
    "resized_mask = resize_with_padding(labelme_mask, desired_size=224)\n",
    "\n",
    "# === Convert both to binary masks ===\n",
    "labelme_binary = (resized_mask > 127).astype(np.uint8)\n",
    "\n",
    "# Use the YOLO image to extract a binary mask (assumes white background)\n",
    "yolo_gray = cv2.cvtColor(yolo_img, cv2.COLOR_RGB2GRAY)\n",
    "yolo_mask = (yolo_gray < 250).astype(np.uint8)\n",
    "\n",
    "# === Compute IoU ===\n",
    "intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "iou = intersection / union if union != 0 else 0\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# === Visualization ===\n",
    "# Convert labelme mask to 3-channel for overlay\n",
    "resized_mask_rgb = np.stack([resized_mask]*3, axis=-1)\n",
    "\n",
    "overlay = cv2.addWeighted(yolo_img, 0.6, resized_mask_rgb, 0.4, 0)\n",
    "\n",
    "# === Show side-by-side comparison ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(yolo_img)\n",
    "axs[0].set_title(\"YOLO Cutout\")\n",
    "axs[1].imshow(resized_mask, cmap='gray')\n",
    "axs[1].set_title(\"Manual LabelMe Mask (Resized)\")\n",
    "axs[2].imshow(overlay)\n",
    "axs[2].set_title(\"Overlay Comparison\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # height, width\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, (new_size[1], new_size[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# === Paths ===\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/CowsTestYOLO/YOLO/Bad/CSS19912_IMG_9248.json'\n",
    "yolo_output_path = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Bad/CSS19912_IMG_9248_processed.jpg'\n",
    "\n",
    "# === Load YOLO output (already cropped and resized) ===\n",
    "yolo_img = cv2.cvtColor(cv2.imread(yolo_output_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# === Load LabelMe JSON and original image ===\n",
    "with open(labelme_json_path, 'r') as f:\n",
    "    labelme_data = json.load(f)\n",
    "original_img_path = os.path.join(os.path.dirname(labelme_json_path), labelme_data['imagePath'])\n",
    "original_img = Image.open(original_img_path)\n",
    "\n",
    "# === Create binary mask from LabelMe polygon ===\n",
    "labelme_mask = Image.new('L', original_img.size, 0)\n",
    "draw = ImageDraw.Draw(labelme_mask)\n",
    "for shape in labelme_data['shapes']:\n",
    "    if shape['shape_type'] == 'polygon':\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        draw.polygon(polygon, outline=1, fill=1)\n",
    "labelme_mask = np.array(labelme_mask) * 255\n",
    "\n",
    "# === Resize LabelMe mask to YOLO image size using padding ===\n",
    "resized_mask = resize_with_padding(labelme_mask, desired_size=224)\n",
    "\n",
    "# === Convert both to binary masks ===\n",
    "labelme_binary = (resized_mask > 127).astype(np.uint8)\n",
    "\n",
    "# Use the YOLO image to extract a binary mask (assumes white background)\n",
    "yolo_gray = cv2.cvtColor(yolo_img, cv2.COLOR_RGB2GRAY)\n",
    "yolo_mask = (yolo_gray < 250).astype(np.uint8)\n",
    "\n",
    "# === Compute IoU ===\n",
    "intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "iou = intersection / union if union != 0 else 0\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# === Visualization ===\n",
    "# Convert labelme mask to 3-channel for overlay\n",
    "resized_mask_rgb = np.stack([resized_mask]*3, axis=-1)\n",
    "\n",
    "overlay = cv2.addWeighted(yolo_img, 0.6, resized_mask_rgb, 0.4, 0)\n",
    "\n",
    "# === Show side-by-side comparison ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "axs[0].imshow(yolo_img)\n",
    "axs[0].set_title(\"YOLO Cutout\")\n",
    "axs[1].imshow(resized_mask, cmap='gray')\n",
    "axs[1].set_title(\"Manual LabelMe Mask (Resized)\")\n",
    "axs[2].imshow(overlay)\n",
    "axs[2].set_title(\"Overlay Comparison\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "# import matplotlib.pyplot as plt # Kept commented out as you requested no display\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# === Helper: Resize with padding like YOLO output ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    \"\"\"\n",
    "    Resizes an image to desired_size with padding, maintaining aspect ratio.\n",
    "    Pads with black (value=0).\n",
    "    \"\"\"\n",
    "    old_size = image.shape[:2]  # height, width (e.g., 3456, 5184)\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Ensure new_size dimensions are integers for cv2.resize\n",
    "    # cv2.resize expects (width, height)\n",
    "    new_size_cv2 = (int(new_size[1]), int(new_size[0]))\n",
    "\n",
    "    # Resize image with preserved aspect ratio\n",
    "    resized = cv2.resize(image, new_size_cv2, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Compute padding\n",
    "    delta_w = desired_size - resized.shape[1]\n",
    "    delta_h = desired_size - resized.shape[0]\n",
    "    top, bottom = delta_h // 2, delta_h - delta_h // 2\n",
    "    left, right = delta_w // 2, delta_w - delta_w // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right,\n",
    "                                 cv2.BORDER_CONSTANT, value=0)  # black background\n",
    "    return padded\n",
    "\n",
    "# --- Configuration Paths ---\n",
    "# !!! IMPORTANT: Set your base directories here !!!\n",
    "labelme_base_dir = '/Users/suzetteschulenburg/Desktop/CowsTestYOLO/YOLO/Bad/'\n",
    "yolo_processed_base_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Test/Bad/'\n",
    "original_images_root_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test/Bad' # This is the explicit root for original images\n",
    "\n",
    "# --- Processing Loop Initialization ---\n",
    "json_files = [f for f in os.listdir(labelme_base_dir) if os.path.isfile(os.path.join(labelme_base_dir, f)) and f.endswith('.json')]\n",
    "\n",
    "print(f\"Found {len(json_files)} LabelMe JSON files in '{labelme_base_dir}'.\")\n",
    "print(f\"Attempting to match them with YOLO images in '{yolo_processed_base_dir}'.\")\n",
    "print(f\"Original images will be looked for in: '{original_images_root_dir}'.\")\n",
    "print(\"\\n--- NOTE: All images and masks WILL BE RESIZED to 224x224 for consistent IoU computation. ---\")\n",
    "print(\"--- PAY ATTENTION to 'DIAGNOSTIC PATHS' below for CSS19912_IMG_9249 ---\")\n",
    "\n",
    "\n",
    "processed_files_count = 0\n",
    "skipped_files_count = 0\n",
    "all_ious = []\n",
    "\n",
    "# --- Main Loop ---\n",
    "for json_file_name in json_files:\n",
    "    labelme_json_path = os.path.join(labelme_base_dir, json_file_name)\n",
    "    base_name = os.path.splitext(json_file_name)[0]\n",
    "    yolo_image_name = f\"{base_name}_processed.jpg\"\n",
    "    yolo_output_path = os.path.join(yolo_processed_base_dir, yolo_image_name)\n",
    "\n",
    "    print(f\"\\n--- Processing: '{base_name}' ---\")\n",
    "    print(f\"  LabelMe JSON: {labelme_json_path}\")\n",
    "    print(f\"  YOLO Image:   {yolo_output_path}\") # This already prints the YOLO path\n",
    "\n",
    "    try:\n",
    "        # 1. Load YOLO output image\n",
    "        if not os.path.exists(yolo_output_path):\n",
    "            print(f\"  SKIPPING: Corresponding YOLO image NOT FOUND at {yolo_output_path}\")\n",
    "            skipped_files_count += 1\n",
    "            continue\n",
    "        yolo_img_raw = cv2.imread(yolo_output_path)\n",
    "        if yolo_img_raw is None:\n",
    "            print(f\"  SKIPPING: Could not read YOLO image file: {yolo_output_path}\")\n",
    "            skipped_files_count += 1\n",
    "            continue\n",
    "        yolo_img_resized = resize_with_padding(cv2.cvtColor(yolo_img_raw, cv2.COLOR_BGR2RGB), desired_size=224)\n",
    "\n",
    "\n",
    "        # 2. Load LabelMe JSON and original image\n",
    "        with open(labelme_json_path, 'r') as f:\n",
    "            labelme_data = json.load(f)\n",
    "\n",
    "        original_img_filename = os.path.basename(labelme_data.get('imagePath', ''))\n",
    "\n",
    "        if not original_img_filename:\n",
    "            print(f\"  SKIPPING: 'imagePath' field is missing or empty in LabelMe JSON for {base_name}.\")\n",
    "            skipped_files_count += 1\n",
    "            continue\n",
    "\n",
    "        original_img_full_path = os.path.join(original_images_root_dir, original_img_filename)\n",
    "\n",
    "        # --- DIAGNOSTIC PRINT FOR CSS19912_IMG_9249 ---\n",
    "        if base_name == \"CSS19912_IMG_9249\":\n",
    "            print(f\"  *** DIAGNOSTIC PATHS for {base_name} ***\")\n",
    "            print(f\"  YOLO Path:        {yolo_output_path}\")\n",
    "            print(f\"  Original Img Path: {original_img_full_path}\")\n",
    "            # Also print sums to see if masks are empty or different\n",
    "            yolo_gray_diag = cv2.cvtColor(yolo_img_resized, cv2.COLOR_RGB2GRAY)\n",
    "            yolo_mask_diag = (cv2.adaptiveThreshold(yolo_gray_diag, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2) / 255).astype(np.uint8)\n",
    "            print(f\"  YOLO Mask Sum (pixels): {yolo_mask_diag.sum()}\")\n",
    "            \n",
    "            # Re-generate LabelMe mask for diagnostic purposes to ensure it's fresh\n",
    "            labelme_mask_pil_diag = Image.new('L', (original_img_np.shape[1], original_img_np.shape[0]), 0)\n",
    "            draw_diag = ImageDraw.Draw(labelme_mask_pil_diag)\n",
    "            for shape_diag in labelme_data.get('shapes', []):\n",
    "                if shape_diag['shape_type'] == 'polygon' and 'points' in shape_diag:\n",
    "                    polygon_diag = [(x, y) for x, y in shape_diag['points']]\n",
    "                    if len(polygon_diag) >= 3:\n",
    "                        draw_diag.polygon(polygon_diag, outline=1, fill=1)\n",
    "            labelme_mask_raw_diag = np.array(labelme_mask_pil_diag) * 255\n",
    "            resized_labelme_mask_diag = resize_with_padding(labelme_mask_raw_diag, desired_size=224)\n",
    "            labelme_binary_diag = (resized_labelme_mask_diag > 127).astype(np.uint8)\n",
    "            print(f\"  LabelMe Mask Sum (pixels): {labelme_binary_diag.sum()}\")\n",
    "            print(f\"  *** END DIAGNOSTIC ***\")\n",
    "\n",
    "\n",
    "        if not os.path.exists(original_img_full_path):\n",
    "            print(f\"  SKIPPING: Original image referenced in JSON NOT FOUND at {original_img_full_path}\")\n",
    "            skipped_files_count += 1\n",
    "            continue\n",
    "\n",
    "        original_img_pil = Image.open(original_img_full_path)\n",
    "        original_img_np = np.array(original_img_pil)\n",
    "\n",
    "\n",
    "        # 3. Create binary mask from LabelMe polygon on the ORIGINAL image size\n",
    "        labelme_mask_pil = Image.new('L', (original_img_np.shape[1], original_img_np.shape[0]), 0)\n",
    "        draw = ImageDraw.Draw(labelme_mask_pil)\n",
    "        found_polygon = False\n",
    "        for shape in labelme_data.get('shapes', []):\n",
    "            if shape['shape_type'] == 'polygon' and 'points' in shape:\n",
    "                polygon = [(x, y) for x, y in shape['points']]\n",
    "                if len(polygon) >= 3:\n",
    "                    draw.polygon(polygon, outline=1, fill=1)\n",
    "                    found_polygon = True\n",
    "        if not found_polygon:\n",
    "            print(f\"  SKIPPING: No valid polygon (with 3+ points) found in LabelMe JSON for {base_name}.\")\n",
    "            skipped_files_count += 1\n",
    "            continue\n",
    "        labelme_mask_raw = np.array(labelme_mask_pil) * 255\n",
    "\n",
    "\n",
    "        # 4. Resize LabelMe mask to match the desired_size (224x224)\n",
    "        resized_labelme_mask = resize_with_padding(labelme_mask_raw, desired_size=224)\n",
    "\n",
    "        # 5. Convert LabelMe mask to binary (0 or 1)\n",
    "        labelme_binary = (resized_labelme_mask > 127).astype(np.uint8)\n",
    "\n",
    "\n",
    "        # 6. Create binary mask from YOLO image (already resized to 224x224)\n",
    "        yolo_gray = cv2.cvtColor(yolo_img_resized, cv2.COLOR_RGB2GRAY)\n",
    "        yolo_mask = cv2.adaptiveThreshold(yolo_gray, 255,\n",
    "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                          cv2.THRESH_BINARY_INV,\n",
    "                                          11,\n",
    "                                          2)\n",
    "        yolo_mask = (yolo_mask / 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        # 7. Compute IoU\n",
    "        if yolo_mask.shape != labelme_binary.shape:\n",
    "            print(f\"  CRITICAL ERROR: Internal mask shape mismatch after resizing for {base_name}! YOLO: {yolo_mask.shape}, LabelMe: {labelme_binary.shape}. Skipping.\")\n",
    "            skipped_files_count += 1\n",
    "            continue\n",
    "\n",
    "        intersection = np.logical_and(yolo_mask, labelme_binary).sum()\n",
    "        union = np.logical_or(yolo_mask, labelme_binary).sum()\n",
    "        iou = intersection / union if union != 0 else 0\n",
    "        print(f\"  Calculated IoU: {iou * 100:.2f}%\")\n",
    "        processed_files_count += 1\n",
    "        all_ious.append(iou)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ERROR: File not found for {base_name} - {e}. Skipping.\")\n",
    "        skipped_files_count += 1\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"  ERROR: Could not decode JSON for {base_name}. Skipping.\")\n",
    "        skipped_files_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"  An unexpected error occurred while processing {base_name}: {e}. Skipping.\")\n",
    "        skipped_files_count += 1\n",
    "\n",
    "# --- Final Summary ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- Processing Complete ---\")\n",
    "print(f\"Total LabelMe JSON files found: {len(json_files)}\")\n",
    "print(f\"Successfully processed: {processed_files_count} file pairs.\")\n",
    "print(f\"Skipped due to errors, missing files, or invalid data: {skipped_files_count} file pairs.\")\n",
    "\n",
    "if all_ious:\n",
    "    average_iou = np.mean(all_ious)\n",
    "    print(f\"\\nOverall Average IoU across successfully processed files: {average_iou * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"\\nNo IoU values were calculated successfully.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from ultralytics import YOLO # Import YOLO model\n",
    "\n",
    "# --- Paths for the specific image to test ---\n",
    "# Please double-check these paths are correct for your system\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/CowsTestYOLO/YOLO/Bad/CSS19912_IMG_9248.json'\n",
    "# We will NOT use yolo_output_path directly for mask extraction anymore.\n",
    "# We'll run YOLO on the original image.\n",
    "original_image_manual_path = '/Users/suzetteschulenburg/Desktop/MainUse/Test/Bad/CSS19912_IMG_9248.jpg'\n",
    "\n",
    "# === Load YOLO segmentation model ===\n",
    "try:\n",
    "    model = YOLO(\"yolov8s-seg.pt\") # Ensure you have this model downloaded or accessible\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    print(\"Please ensure 'yolov8s-seg.pt' is in your current directory or specified path.\")\n",
    "    exit()\n",
    "\n",
    "# --- Load LabelMe JSON and original image ---\n",
    "try:\n",
    "    with open(labelme_json_path, 'r') as f:\n",
    "        labelme_data = json.load(f)\n",
    "\n",
    "    original_img_path = original_image_manual_path\n",
    "    if not os.path.exists(original_img_path):\n",
    "        raise FileNotFoundError(f\"Original image NOT FOUND at {original_img_path}. Please check the path.\")\n",
    "\n",
    "    original_img_pil = Image.open(original_img_path).convert('RGB') # Ensure RGB for YOLO\n",
    "    original_img_np = np.array(original_img_pil) # Original image as NumPy array\n",
    "    original_h, original_w = original_img_np.shape[:2]\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading LabelMe data or original image: {e}\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode LabelMe JSON from {labelme_json_path}. Check file format.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Create binary mask from LabelMe polygon (at original image resolution) ---\n",
    "labelme_mask_pil = Image.new('L', (original_w, original_h), 0)\n",
    "draw = ImageDraw.Draw(labelme_mask_pil)\n",
    "found_polygon = False\n",
    "labelme_polygon_points = []\n",
    "for shape in labelme_data.get('shapes', []):\n",
    "    if shape['shape_type'] == 'polygon' and 'points' in shape:\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        if len(polygon) >= 3:\n",
    "            # Ensure points are integers for ImageDraw\n",
    "            int_polygon = [(int(p[0]), int(p[1])) for p in polygon]\n",
    "            draw.polygon(int_polygon, outline=1, fill=1)\n",
    "            labelme_polygon_points.extend(polygon)\n",
    "            found_polygon = True\n",
    "\n",
    "if not found_polygon:\n",
    "    print(f\"Warning: No valid polygon found in LabelMe JSON for {os.path.basename(labelme_json_path)}. IoU will be 0.\")\n",
    "    # Create an empty mask if no polygon is found\n",
    "    labelme_binary_original_res = np.zeros((original_h, original_w), dtype=np.uint8)\n",
    "else:\n",
    "    # Convert PIL mask to a binary NumPy array (0 or 1) at original resolution\n",
    "    labelme_binary_original_res = (np.array(labelme_mask_pil) > 0).astype(np.uint8)\n",
    "\n",
    "# --- Run YOLO segmentation on the ORIGINAL image ---\n",
    "yolo_binary_original_res = np.zeros((original_h, original_w), dtype=np.uint8) # Initialize empty YOLO mask\n",
    "yolo_confidence = 0.0\n",
    "\n",
    "try:\n",
    "    results = model(original_img_np, verbose=False) # Run inference, suppress verbose output\n",
    "    masks = results[0].masks\n",
    "    boxes = results[0].boxes\n",
    "    names = results[0].names\n",
    "\n",
    "    if masks is None or len(masks.data) == 0:\n",
    "        print(f\"❌ No cow mask found by YOLO in: {os.path.basename(original_img_path)}\")\n",
    "    else:\n",
    "        # Find the largest 'cow' mask (or similar animal class)\n",
    "        best_index = None\n",
    "        largest_area = 0\n",
    "        for i, cls_id in enumerate(boxes.cls.cpu().numpy()):\n",
    "            name = names[int(cls_id)]\n",
    "            if name in ['cow', 'bull', 'animal', 'cattle']: # Adjust class names if needed\n",
    "                x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                if area > largest_area:\n",
    "                    best_index = i\n",
    "                    largest_area = area\n",
    "        \n",
    "        if best_index is not None:\n",
    "            # Get the mask data, resize to original image dimensions\n",
    "            yolo_mask_data = masks.data[best_index].cpu().numpy()\n",
    "            yolo_mask_resized = cv2.resize(yolo_mask_data, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "            yolo_binary_original_res = (yolo_mask_resized > 0.5).astype(np.uint8) # Threshold to binary\n",
    "            yolo_confidence = float(boxes.conf[best_index].cpu().numpy())\n",
    "            print(f\"✅ YOLO detected a '{names[int(boxes.cls[best_index])]}' with confidence: {yolo_confidence:.2f}\")\n",
    "        else:\n",
    "            print(f\"❌ No valid 'cow' class detected by YOLO in: {os.path.basename(original_img_path)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during YOLO inference: {e}\")\n",
    "\n",
    "# --- Compute IoU (both masks are at original image resolution) ---\n",
    "if yolo_binary_original_res.shape != labelme_binary_original_res.shape:\n",
    "    print(f\"Error: Mask shapes do not match for IoU calculation! YOLO: {yolo_binary_original_res.shape}, LabelMe: {labelme_binary_original_res.shape}\")\n",
    "    iou = 0.0\n",
    "else:\n",
    "    intersection = np.logical_and(yolo_binary_original_res, labelme_binary_original_res).sum()\n",
    "    union = np.logical_or(yolo_binary_original_res, labelme_binary_original_res).sum()\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# --- Visualization ---\n",
    "fig_title = (f\"IoU: {iou * 100:.2f}% | YOLO Conf: {yolo_confidence:.2f} \"\n",
    "             f\"for {os.path.basename(original_img_path)} \"\n",
    "             f\"(Comparing Full-Image YOLO to Manual Label)\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(28, 10)) # Adjusted figsize for potentially large images\n",
    "\n",
    "# Plot 1: Original Image with Manual Label (Ground Truth)\n",
    "original_img_display_gt = original_img_np.copy()\n",
    "if found_polygon:\n",
    "    temp_pil_gt = Image.fromarray(original_img_display_gt)\n",
    "    temp_draw_gt = ImageDraw.Draw(temp_pil_gt)\n",
    "    int_polygon = [(int(p[0]), int(p[1])) for p in polygon] # Use int_polygon here\n",
    "    temp_draw_gt.polygon(int_polygon, outline=(255, 0, 0), width=5) # Red outline\n",
    "    axs[0].imshow(temp_pil_gt)\n",
    "else:\n",
    "    axs[0].imshow(original_img_display_gt)\n",
    "axs[0].set_title(\"Original Image with Manual Label (Ground Truth)\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Plot 2: Original Image with YOLO Segmentation Mask\n",
    "yolo_mask_colored = np.zeros_like(original_img_np, dtype=np.uint8)\n",
    "yolo_mask_colored[yolo_binary_original_res > 0] = [0, 255, 0] # Green for YOLO mask\n",
    "\n",
    "overlay_yolo_on_original = cv2.addWeighted(original_img_np, 0.7, yolo_mask_colored, 0.3, 0)\n",
    "axs[1].imshow(overlay_yolo_on_original)\n",
    "axs[1].set_title(\"Original Image with YOLO Prediction\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Plot 3: Combined Overlay (Manual Red + YOLO Green + Overlap Blue)\n",
    "combined_mask_colored = np.zeros_like(original_img_np, dtype=np.uint8)\n",
    "# Red: LabelMe only\n",
    "combined_mask_colored[np.logical_and(labelme_binary_original_res, ~yolo_binary_original_res) > 0] = [255, 0, 0]\n",
    "# Green: YOLO only\n",
    "combined_mask_colored[np.logical_and(~labelme_binary_original_res, yolo_binary_original_res) > 0] = [0, 255, 0]\n",
    "# Blue: Overlap\n",
    "combined_mask_colored[np.logical_and(labelme_binary_original_res, yolo_binary_original_res) > 0] = [0, 0, 255]\n",
    "\n",
    "final_overlay_display = cv2.addWeighted(original_img_np, 0.7, combined_mask_colored, 0.3, 0)\n",
    "axs[2].imshow(final_overlay_display)\n",
    "axs[2].set_title(\"Overlay: Manual (Red) + YOLO (Green) + Overlap (Blue)\")\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.suptitle(fig_title, fontsize=18, y=0.98) # Adjusted y for title\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === Paths ===\n",
    "json_dir = '/Users/suzetteschulenburg/Desktop/CowsTestYOLO/YOLO/Good'\n",
    "image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test/Good'\n",
    "\n",
    "# === Load YOLO model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "ious = []\n",
    "missing_images = []\n",
    "processed = 0\n",
    "\n",
    "for json_file in os.listdir(json_dir):\n",
    "    if not json_file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    image_name = os.path.splitext(json_file)[0] + '.jpg'\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        missing_images.append(image_name)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # === Load image and json ===\n",
    "        with open(json_path, 'r') as f:\n",
    "            labelme_data = json.load(f)\n",
    "\n",
    "        img_pil = Image.open(image_path).convert('RGB')\n",
    "        img_np = np.array(img_pil)\n",
    "        h, w = img_np.shape[:2]\n",
    "\n",
    "        # === Create LabelMe mask ===\n",
    "        labelme_mask = Image.new('L', (w, h), 0)\n",
    "        draw = ImageDraw.Draw(labelme_mask)\n",
    "        found_polygon = False\n",
    "        for shape in labelme_data.get('shapes', []):\n",
    "            if shape['shape_type'] == 'polygon' and 'points' in shape:\n",
    "                polygon = [(int(x), int(y)) for x, y in shape['points']]\n",
    "                if len(polygon) >= 3:\n",
    "                    draw.polygon(polygon, outline=1, fill=1)\n",
    "                    found_polygon = True\n",
    "\n",
    "        if not found_polygon:\n",
    "            label_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        else:\n",
    "            label_mask = (np.array(labelme_mask) > 0).astype(np.uint8)\n",
    "\n",
    "        # === YOLO prediction ===\n",
    "        yolo_result = model(img_np, verbose=False)[0]\n",
    "        yolo_mask_bin = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        if yolo_result.masks and len(yolo_result.masks.data) > 0:\n",
    "            best_index = -1\n",
    "            max_area = 0\n",
    "            for i, cls in enumerate(yolo_result.boxes.cls.cpu().numpy()):\n",
    "                if yolo_result.names[int(cls)] in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                    x1, y1, x2, y2 = map(int, yolo_result.boxes.xyxy[i].cpu().numpy())\n",
    "                    area = (x2 - x1) * (y2 - y1)\n",
    "                    if area > max_area:\n",
    "                        max_area = area\n",
    "                        best_index = i\n",
    "            if best_index != -1:\n",
    "                yolo_mask = yolo_result.masks.data[best_index].cpu().numpy()\n",
    "                yolo_mask_resized = cv2.resize(yolo_mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "                yolo_mask_bin = (yolo_mask_resized > 0.5).astype(np.uint8)\n",
    "\n",
    "        # === IoU calculation ===\n",
    "        intersection = np.logical_and(yolo_mask_bin, label_mask).sum()\n",
    "        union = np.logical_or(yolo_mask_bin, label_mask).sum()\n",
    "        iou = intersection / union if union != 0 else 0\n",
    "        ious.append(iou)\n",
    "        processed += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file}: {e}\")\n",
    "\n",
    "# === Final Output ===\n",
    "print(f\"\\nProcessed {processed} images.\")\n",
    "if missing_images:\n",
    "    print(\"Missing image files for:\")\n",
    "    for img in missing_images:\n",
    "        print(f\" - {img}\")\n",
    "\n",
    "if ious:\n",
    "    avg_iou = sum(ious) / len(ious)\n",
    "    print(f\"\\n✅ Average IoU across all matched files: {avg_iou * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"❌ No IoU values computed (check files).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === Base paths ===\n",
    "base_json_dir = '/Users/suzetteschulenburg/Desktop/CowsTestYOLO/YOLO'\n",
    "base_image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test'\n",
    "\n",
    "# === Load YOLO model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "def compute_avg_iou(subfolder):\n",
    "    json_dir = os.path.join(base_json_dir, subfolder)\n",
    "    image_dir = os.path.join(base_image_dir, subfolder)\n",
    "\n",
    "    ious = []\n",
    "    missing_images = 0\n",
    "    total_files = 0\n",
    "\n",
    "    for json_file in sorted(os.listdir(json_dir)):\n",
    "        if not json_file.endswith('.json'):\n",
    "            continue\n",
    "\n",
    "        json_path = os.path.join(json_dir, json_file)\n",
    "        image_name = os.path.splitext(json_file)[0] + '.jpg'\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            missing_images += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                labelme_data = json.load(f)\n",
    "\n",
    "            img_pil = Image.open(image_path).convert('RGB')\n",
    "            img_np = np.array(img_pil)\n",
    "            h, w = img_np.shape[:2]\n",
    "\n",
    "            # Manual mask (already excludes bottom 30%)\n",
    "            labelme_mask = Image.new('L', (w, h), 0)\n",
    "            draw = ImageDraw.Draw(labelme_mask)\n",
    "            for shape in labelme_data.get('shapes', []):\n",
    "                if shape['shape_type'] == 'polygon' and 'points' in shape:\n",
    "                    polygon = [(int(x), int(y)) for x, y in shape['points']]\n",
    "                    if len(polygon) >= 3:\n",
    "                        draw.polygon(polygon, outline=1, fill=1)\n",
    "\n",
    "            label_mask = (np.array(labelme_mask) > 0).astype(np.uint8)\n",
    "\n",
    "            # YOLO\n",
    "            yolo_result = model(img_np, verbose=False)[0]\n",
    "            yolo_mask_bin = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "            if yolo_result.masks and len(yolo_result.masks.data) > 0:\n",
    "                best_index = -1\n",
    "                max_area = 0\n",
    "                for i, cls in enumerate(yolo_result.boxes.cls.cpu().numpy()):\n",
    "                    name = yolo_result.names[int(cls)]\n",
    "                    if name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                        x1, y1, x2, y2 = map(int, yolo_result.boxes.xyxy[i].cpu().numpy())\n",
    "                        area = (x2 - x1) * (y2 - y1)\n",
    "                        if area > max_area:\n",
    "                            best_index = i\n",
    "                            max_area = area\n",
    "\n",
    "                if best_index != -1:\n",
    "                    yolo_mask = yolo_result.masks.data[best_index].cpu().numpy()\n",
    "                    yolo_mask_resized = cv2.resize(yolo_mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "                    yolo_mask_bin = (yolo_mask_resized > 0.5).astype(np.uint8)\n",
    "\n",
    "            # Crop only YOLO mask to top 70%\n",
    "            cutoff = int(0.7 * h)\n",
    "            yolo_mask_bin = yolo_mask_bin[:cutoff, :]\n",
    "            label_mask_cropped = label_mask[:cutoff, :]\n",
    "\n",
    "            # IoU\n",
    "            intersection = np.logical_and(yolo_mask_bin, label_mask_cropped).sum()\n",
    "            union = np.logical_or(yolo_mask_bin, label_mask_cropped).sum()\n",
    "            iou = intersection / union if union != 0 else 0\n",
    "            ious.append(iou)\n",
    "            total_files += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file} in {subfolder}: {e}\")\n",
    "\n",
    "    avg_iou = (sum(ious) / len(ious)) if ious else 0.0\n",
    "    print(f\"\\n📁 {subfolder}:\")\n",
    "    print(f\"Processed: {total_files} files\")\n",
    "    if missing_images > 0:\n",
    "        print(f\"Missing image files: {missing_images}\")\n",
    "    print(f\"✅ Average IoU: {avg_iou * 100:.2f}%\")\n",
    "\n",
    "# === Run for both folders\n",
    "compute_avg_iou('Good')\n",
    "compute_avg_iou('Bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === Paths for Bad ===\n",
    "json_dir = '/Users/suzetteschulenburg/Desktop/CowsTestYOLO/YOLO/Bad'\n",
    "image_dir = '/Users/suzetteschulenburg/Desktop/MainUse/Test/Bad'\n",
    "\n",
    "# === Load YOLO model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "results = []  # (filename, IoU)\n",
    "missing_images = 0\n",
    "total_files = 0\n",
    "\n",
    "for json_file in sorted(os.listdir(json_dir)):\n",
    "    if not json_file.endswith('.json'):\n",
    "        continue\n",
    "\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    image_name = os.path.splitext(json_file)[0] + '.jpg'\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        missing_images += 1\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(json_path, 'r') as f:\n",
    "            labelme_data = json.load(f)\n",
    "\n",
    "        img_pil = Image.open(image_path).convert('RGB')\n",
    "        img_np = np.array(img_pil)\n",
    "        h, w = img_np.shape[:2]\n",
    "\n",
    "        # Manual mask (ALREADY cropped, do not crop again)\n",
    "        labelme_mask = Image.new('L', (w, h), 0)\n",
    "        draw = ImageDraw.Draw(labelme_mask)\n",
    "        for shape in labelme_data.get('shapes', []):\n",
    "            if shape['shape_type'] == 'polygon' and 'points' in shape:\n",
    "                polygon = [(int(x), int(y)) for x, y in shape['points']]\n",
    "                if len(polygon) >= 3:\n",
    "                    draw.polygon(polygon, outline=1, fill=1)\n",
    "        label_mask = (np.array(labelme_mask) > 0).astype(np.uint8)\n",
    "\n",
    "        # YOLO prediction\n",
    "        yolo_result = model(img_np, verbose=False)[0]\n",
    "        yolo_mask_bin = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        if yolo_result.masks and len(yolo_result.masks.data) > 0:\n",
    "            # Find the cow with the highest confidence\n",
    "            best_index = -1\n",
    "            highest_conf = 0.0\n",
    "            for i, cls in enumerate(yolo_result.boxes.cls.cpu().numpy()):\n",
    "                name = yolo_result.names[int(cls)]\n",
    "                if name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                    conf = float(yolo_result.boxes.conf[i].cpu().numpy())\n",
    "                    if conf > highest_conf:\n",
    "                        best_index = i\n",
    "                        highest_conf = conf\n",
    "\n",
    "            if best_index != -1:\n",
    "                yolo_mask = yolo_result.masks.data[best_index].cpu().numpy()\n",
    "                yolo_mask_resized = cv2.resize(yolo_mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "                yolo_mask_bin = (yolo_mask_resized > 0.5).astype(np.uint8)\n",
    "\n",
    "        # Crop only YOLO mask (manual mask already excludes bottom 30%)\n",
    "        cutoff = int(0.7 * h)\n",
    "        yolo_mask_bin = yolo_mask_bin[:cutoff, :]\n",
    "\n",
    "        # Keep manual mask as-is (already cropped)\n",
    "        label_mask_cropped = label_mask\n",
    "\n",
    "        # Compute IoU\n",
    "        intersection = np.logical_and(yolo_mask_bin, label_mask_cropped).sum()\n",
    "        union = np.logical_or(yolo_mask_bin, label_mask_cropped).sum()\n",
    "        iou = intersection / union if union != 0 else 0\n",
    "        results.append((json_file, iou))\n",
    "        total_files += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file}: {e}\")\n",
    "\n",
    "# === Sort by IoU (ascending)\n",
    "results_sorted = sorted(results, key=lambda x: x[1])\n",
    "avg_iou = sum(iou for _, iou in results_sorted) / len(results_sorted) if results_sorted else 0.0\n",
    "\n",
    "# === Print results\n",
    "print(\"\\n📁 Bad\")\n",
    "print(f\"Processed: {total_files} files\")\n",
    "print(f\"Missing image files: {missing_images}\")\n",
    "print(f\"✅ Average IoU: {avg_iou * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n❌ 5 Lowest IoU Samples:\")\n",
    "for filename, iou in results_sorted[:5]:\n",
    "    print(f\"{filename} → IoU: {iou * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axs[0].imshow(label_mask, cmap='gray')\n",
    "axs[0].set_title(\"Manual Mask\")\n",
    "axs[1].imshow(yolo_mask_resized, cmap='gray')\n",
    "axs[1].set_title(\"YOLO Mask (Resized)\")\n",
    "axs[2].imshow(img_np)\n",
    "axs[2].set_title(\"Original Image\")\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_lr1e-06_unf40.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Load model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Extract the last conv layer name (adapt if different) ===\n",
    "last_conv_layer_name = None\n",
    "for layer in reversed(model.layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        last_conv_layer_name = layer.name\n",
    "        break\n",
    "if not last_conv_layer_name:\n",
    "    raise ValueError(\"No Conv2D layer found in the model.\")\n",
    "\n",
    "# === Helper: Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    path = os.path.join(full_path, fname)\n",
    "                    img = load_img(path, target_size=(224, 224))\n",
    "                    img_arr = img_to_array(img) / 255.0\n",
    "                    images.append(img_arr)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                    paths.append(path)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ {fname} skipped due to error: {e}\")\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, image_paths = load_images_and_labels(test_dir)\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Grad-CAM Function ===\n",
    "def generate_gradcam(model, img_array, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = Model(\n",
    "        [model.inputs], \n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.expand_dims(img_array, axis=0))\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "# === Plotting Helper ===\n",
    "def display_gradcam(img_array, heatmap, alpha=0.4):\n",
    "    img = np.uint8(255 * img_array)\n",
    "    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (224, 224)).numpy().squeeze()\n",
    "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "    heatmap_color = tf.keras.preprocessing.image.array_to_img(plt.cm.jet(heatmap_resized / 255.0)[..., :3])\n",
    "    overlay = Image.fromarray(img.astype('uint8')).convert('RGBA')\n",
    "    heatmap_img = heatmap_color.convert('RGBA')\n",
    "\n",
    "    blended = Image.blend(overlay, heatmap_img, alpha=alpha)\n",
    "    return blended\n",
    "\n",
    "# === Show Grad-CAM for 2 TPs and 2 FPs ===\n",
    "from PIL import Image\n",
    "\n",
    "print(\"\\n📸 Showing Grad-CAMs:\")\n",
    "\n",
    "# Collect indices\n",
    "tp_idx = [i for i in range(len(y_test)) if y_test[i] == 1 and y_pred[i] == 1]\n",
    "fp_idx = [i for i in range(len(y_test)) if y_test[i] == 0 and y_pred[i] == 1]\n",
    "\n",
    "selected_indices = tp_idx[:2] + fp_idx[:2]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    img = X_test[idx]\n",
    "    heatmap = generate_gradcam(model, img, last_conv_layer_name)\n",
    "    blended = display_gradcam(img, heatmap)\n",
    "\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(blended)\n",
    "    true_label = \"Good\" if y_test[idx] == 1 else \"Bad\"\n",
    "    pred_label = \"Good\" if y_pred[idx] == 1 else \"Bad\"\n",
    "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, SeparableConv2D\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_lr1e-06_unf40.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Load model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Get all convolutional layers ===\n",
    "conv_layer_names = [\n",
    "    layer.name for layer in model.layers \n",
    "    if isinstance(layer, (Conv2D, DepthwiseConv2D, SeparableConv2D))\n",
    "]\n",
    "\n",
    "# You can reduce to only a few for visualization clarity\n",
    "selected_layers = conv_layer_names[-4:]  # Last 4 conv-type layers\n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    path = os.path.join(full_path, fname)\n",
    "                    img = load_img(path, target_size=(224, 224))\n",
    "                    img_arr = img_to_array(img) / 255.0\n",
    "                    images.append(img_arr)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                    paths.append(path)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ {fname} skipped due to error: {e}\")\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, image_paths = load_images_and_labels(test_dir)\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Grad-CAM Function ===\n",
    "def generate_gradcam(model, img_array, layer_name, pred_index=None):\n",
    "    grad_model = Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.expand_dims(img_array, axis=0))\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    if tf.reduce_max(heatmap) == 0:\n",
    "        return heatmap.numpy()\n",
    "    heatmap /= tf.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# === Overlay Function ===\n",
    "def display_gradcam(img_array, heatmap, alpha=0.4):\n",
    "    img = np.uint8(255 * img_array)\n",
    "    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (224, 224)).numpy().squeeze()\n",
    "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "    heatmap_color = plt.cm.jet(heatmap_resized / 255.0)[..., :3]\n",
    "    heatmap_img = Image.fromarray((heatmap_color * 255).astype('uint8')).convert('RGBA')\n",
    "    overlay = Image.fromarray(img.astype('uint8')).convert('RGBA')\n",
    "    return Image.blend(overlay, heatmap_img, alpha=alpha)\n",
    "\n",
    "# === Select 2 TPs + 2 FPs ===\n",
    "tp_idx = [i for i in range(len(y_test)) if y_test[i] == 1 and y_pred[i] == 1]\n",
    "fp_idx = [i for i in range(len(y_test)) if y_test[i] == 0 and y_pred[i] == 1]\n",
    "selected_indices = tp_idx[:2] + fp_idx[:2]\n",
    "\n",
    "# === Plot heatmaps per image per layer ===\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    img = X_test[idx]\n",
    "    true_label = \"Good\" if y_test[idx] == 1 else \"Bad\"\n",
    "    pred_label = \"Good\" if y_pred[idx] == 1 else \"Bad\"\n",
    "\n",
    "    plt.figure(figsize=(4 * len(selected_layers), 4))\n",
    "    for j, layer_name in enumerate(selected_layers):\n",
    "        heatmap = generate_gradcam(model, img, layer_name)\n",
    "        blended = display_gradcam(img, heatmap)\n",
    "\n",
    "        plt.subplot(1, len(selected_layers), j + 1)\n",
    "        plt.imshow(blended)\n",
    "        plt.title(f\"{layer_name}\", fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Image {i+1}: True={true_label}, Pred={pred_label}\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates to include (≤ 5e-3) ===\n",
    "learning_rates = [\n",
    "    5e-4, 7e-4, 1e-3, 1.5e-3, 2e-3, 2.5e-3, 3e-3, 4e-3, 5e-3,\n",
    "    6e-3, 7e-3, 8e-3, 1e-2, 2e-2\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Histories'\n",
    "\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "print(\"📊 Validation Results (LR ≤ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Best Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        best_val_loss = min(hist['val_loss'])\n",
    "\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(best_val_loss)\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {best_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "filtered_lrs = np.array(filtered_lrs)\n",
    "filtered_accs = np.array(filtered_accs)\n",
    "filtered_losses = np.array(filtered_losses)\n",
    "\n",
    "# === Convert learning rates to log10 space ===\n",
    "log_lrs = np.log10(filtered_lrs)\n",
    "\n",
    "# === Smooth interpolation ===\n",
    "x_smooth = np.linspace(log_lrs.min(), log_lrs.max(), 300)\n",
    "acc_smooth = make_interp_spline(log_lrs, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(log_lrs, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.set_xlabel('Learning Rate', fontsize=22)\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue', fontsize=22)\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# === Unique exponents only ===\n",
    "exponents = sorted(set(int(np.floor(np.log10(lr))) for lr in filtered_lrs))\n",
    "xticks = [10**e for e in exponents]\n",
    "xtick_labels = [f\"$10^{{{e}}}$\" for e in exponents]\n",
    "\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.set_xticklabels(xtick_labels, fontsize=22)\n",
    "ax1.tick_params(axis='y', labelcolor='blue', labelsize=22)\n",
    "ax1.tick_params(axis='x', labelsize=22)\n",
    "\n",
    "# Loss plot\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Best Validation Loss', color='red', fontsize=22)\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red', labelsize=22)\n",
    "\n",
    "# Title and layout\n",
    "plt.title('Validation Accuracy and Loss vs Learning Rate (Transfer to Bulls)', fontsize=22)\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates to include (≤ 5e-3) ===\n",
    "learning_rates = [\n",
    "    5e-4, 7e-4, 1e-3, 1.5e-3, 2e-3, 2.5e-3, 3e-3, 4e-3, 5e-3,\n",
    "    6e-3, 7e-3, 8e-3, 1e-2, 2e-2\n",
    "]\n",
    "\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Histories'\n",
    "\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "print(\"📊 Validation Results (LR ≤ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "filtered_lrs = np.array(filtered_lrs)\n",
    "filtered_accs = np.array(filtered_accs)\n",
    "filtered_losses = np.array(filtered_losses)\n",
    "\n",
    "# === Convert learning rates to log10 space ===\n",
    "log_lrs = np.log10(filtered_lrs)\n",
    "\n",
    "# === Smooth interpolation ===\n",
    "x_smooth = np.linspace(log_lrs.min(), log_lrs.max(), 300)\n",
    "acc_smooth = make_interp_spline(log_lrs, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(log_lrs, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.set_xlabel('Learning Rate', fontsize=22)\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue', fontsize=22)\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Set x-tick labels using powers of 10\n",
    "exponents = sorted(set(int(np.floor(np.log10(lr))) for lr in filtered_lrs))\n",
    "xticks = [10**e for e in exponents]\n",
    "xtick_labels = [f\"$10^{{{e}}}$\" for e in exponents]\n",
    "\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.set_xticklabels(xtick_labels, fontsize=22)\n",
    "ax1.tick_params(axis='y', labelcolor='blue', labelsize=22)\n",
    "ax1.tick_params(axis='x', labelsize=22)\n",
    "\n",
    "# Loss plot\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Avg Validation Loss', color='red', fontsize=22)\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red', labelsize=22)\n",
    "\n",
    "# Title and layout\n",
    "plt.title('Validation Accuracy and Avg Loss vs Learning Rate (Transfer to Bulls)', fontsize=22)\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Models/lr_1e03/bull_transfer_model.keras'\n",
    "\n",
    "\n",
    "# === Load test data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"📊 Test Evaluation for LR = 1e-5\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Models/lr_1e03/bull_transfer_model.keras'\n",
    "\n",
    "\n",
    "# === Load test data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"📊 Test Evaluation for LR = 1e-5\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Models/lr_8e03/bull_transfer_model.keras'\n",
    "\n",
    "\n",
    "# === Load test data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"📊 Test Evaluation for LR = 1e-5\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Models/lr_8e03/bull_transfer_model.keras'\n",
    "\n",
    "# === Load test images and IDs ===\n",
    "def load_images_labels_ids(image_dir):\n",
    "    images, labels, ids = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        for fname in sorted(os.listdir(full_path)):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                # Extract ID from filename (e.g. 'ADC123_1.jpg' → 'ADC123')\n",
    "                id_part = fname.split('_')[0]\n",
    "                ids.append(id_part)\n",
    "    return np.array(images), np.array(labels), ids\n",
    "\n",
    "X_test, y_test, ids = load_images_labels_ids(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# === Group predictions by ID and majority vote ===\n",
    "votes = defaultdict(list)\n",
    "true_labels = {}\n",
    "\n",
    "for pred, label, id_ in zip(y_pred, y_test, ids):\n",
    "    votes[id_].append(pred)\n",
    "    if id_ not in true_labels:\n",
    "        true_labels[id_] = label  # Assumes all images of same cow have same label\n",
    "\n",
    "majority_preds = {}\n",
    "for id_, preds in votes.items():\n",
    "    count = Counter(preds)\n",
    "    final = 1 if count[1] >= 3 else 0\n",
    "    majority_preds[id_] = final\n",
    "\n",
    "# === Extract final predictions and true labels ===\n",
    "final_ids = sorted(majority_preds.keys())\n",
    "final_preds = [majority_preds[i] for i in final_ids]\n",
    "final_trues = [true_labels[i] for i in final_ids]\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(final_trues, final_preds)\n",
    "f1 = f1_score(final_trues, final_preds)\n",
    "precision = precision_score(final_trues, final_preds)\n",
    "recall = recall_score(final_trues, final_preds)\n",
    "conf_mat = confusion_matrix(final_trues, final_preds)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"📊 Majority Vote Test Evaluation (per individual)\")\n",
    "print(f\"Total Individuals: {len(final_ids)}\")\n",
    "print(f\"Accuracy         : {acc:.4f}\")\n",
    "print(f\"F1 Score         : {f1:.4f}\")\n",
    "print(f\"Precision        : {precision:.4f}\")\n",
    "print(f\"Recall           : {recall:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Models/lr_1e03/bull_transfer_model.keras'\n",
    "\n",
    "# === Load test images and IDs ===\n",
    "def load_images_labels_ids(image_dir):\n",
    "    images, labels, ids = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        for fname in sorted(os.listdir(full_path)):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                # Extract ID from filename (e.g. 'ADC123_1.jpg' → 'ADC123')\n",
    "                id_part = fname.split('_')[0]\n",
    "                ids.append(id_part)\n",
    "    return np.array(images), np.array(labels), ids\n",
    "\n",
    "X_test, y_test, ids = load_images_labels_ids(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "# === Group predictions by ID and majority vote ===\n",
    "votes = defaultdict(list)\n",
    "true_labels = {}\n",
    "\n",
    "for pred, label, id_ in zip(y_pred, y_test, ids):\n",
    "    votes[id_].append(pred)\n",
    "    if id_ not in true_labels:\n",
    "        true_labels[id_] = label  # Assumes all images of same cow have same label\n",
    "\n",
    "majority_preds = {}\n",
    "for id_, preds in votes.items():\n",
    "    count = Counter(preds)\n",
    "    final = 1 if count[1] >= 3 else 0\n",
    "    majority_preds[id_] = final\n",
    "\n",
    "# === Extract final predictions and true labels ===\n",
    "final_ids = sorted(majority_preds.keys())\n",
    "final_preds = [majority_preds[i] for i in final_ids]\n",
    "final_trues = [true_labels[i] for i in final_ids]\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(final_trues, final_preds)\n",
    "f1 = f1_score(final_trues, final_preds)\n",
    "precision = precision_score(final_trues, final_preds)\n",
    "recall = recall_score(final_trues, final_preds)\n",
    "conf_mat = confusion_matrix(final_trues, final_preds)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"📊 Majority Vote Test Evaluation (per individual)\")\n",
    "print(f\"Total Individuals: {len(final_ids)}\")\n",
    "print(f\"Accuracy         : {acc:.4f}\")\n",
    "print(f\"F1 Score         : {f1:.4f}\")\n",
    "print(f\"Precision        : {precision:.4f}\")\n",
    "print(f\"Recall           : {recall:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Path to history file for LR = 1e-3 ===\n",
    "history_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Histories/lr_1e03/history.pkl'\n",
    "\n",
    "# === Load history ===\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy (LR = 1e-3)')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss (LR = 1e-3)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Path to history file for LR = 1e-3 ===\n",
    "history_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Histories/lr_8e03/history.pkl'\n",
    "\n",
    "# === Load history ===\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy (LR = 1e-3)')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss (LR = 8e-3)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Folds for bulls using lr 1e-03 using 30 layers Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_1e3Final5Folds'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 1e-3\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === 5-Fold Cross Validation ===\n",
    "for val_fold in range(1, 6):\n",
    "    print(f\"\\n🚀 Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    X_train, y_train = [], []\n",
    "    for fold in range(1, 6):\n",
    "        if fold == val_fold:\n",
    "            continue\n",
    "        fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "        X, y = load_images_and_labels(fold_dir)\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Validation data\n",
    "    val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load and modify model\n",
    "    model = load_model(cow_model_path)\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Create output directories\n",
    "    fold_tag = f'fold{val_fold}'\n",
    "    model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"⏱️ Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"📊 Fold {val_fold} Results (LR = 8e-3):\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_1e3Final5Folds'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 1e-3\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === 5-Fold Cross Validation ===\n",
    "for val_fold in range(3, 6):\n",
    "    print(f\"\\n🚀 Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    X_train, y_train = [], []\n",
    "    for fold in range(1, 6):\n",
    "        if fold == val_fold:\n",
    "            continue\n",
    "        fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "        X, y = load_images_and_labels(fold_dir)\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Validation data\n",
    "    val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load and modify model\n",
    "    model = load_model(cow_model_path)\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Create output directories\n",
    "    fold_tag = f'fold{val_fold}'\n",
    "    model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"⏱️ Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"📊 Fold {val_fold} Results (LR = 8e-3):\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_1e3Final5Folds'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 1e-3\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    img = load_img(img_path, target_size=(224, 224))\n",
    "                    img_array = img_to_array(img) / 255.0\n",
    "                    images.append(img_array)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Fold 5 as Validation ===\n",
    "val_fold = 5\n",
    "print(f\"\\n🚀 Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "# === Load Training Data (Folds 1 to 4) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in range(1, 5):\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 5) ===\n",
    "val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Load and Modify Model ===\n",
    "model = load_model(cow_model_path)\n",
    "\n",
    "# Freeze all but the last 30 layers\n",
    "for layer in model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# === Compile Model ===\n",
    "model.compile(optimizer=Adam(learning_rate=lr),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# === Output Directories ===\n",
    "fold_tag = f'fold{val_fold}'\n",
    "model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train Model ===\n",
    "start = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"⏱️ Training time: {elapsed:.2f}s\")\n",
    "\n",
    "# === Save Training History ===\n",
    "with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate on Validation Set ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "print(f\"\\n📊 Fold {val_fold} Results (LR = {lr}):\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_1e3Final5Folds/Models'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load test images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Evaluating Fold {fold} model on test set\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(recall_curve, prec_curve)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"📊 Fold {fold} Test Metrics:\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_mat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_1e3Final5Folds/Models'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load test images with filenames and IDs ===\n",
    "def load_images_labels_and_ids(image_dir):\n",
    "    images, labels, filenames, ids = [], [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        subdir_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(subdir_path):\n",
    "            continue\n",
    "        for fname in os.listdir(subdir_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "                # Extract ID from filename (e.g., abc123_1.jpg → abc123)\n",
    "                id_part = fname.split('_')[0]\n",
    "                ids.append(id_part)\n",
    "    return np.array(images), np.array(labels), np.array(filenames), np.array(ids)\n",
    "\n",
    "X_test, y_test, filenames, ids = load_images_labels_and_ids(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model with majority voting per individual ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Evaluating Fold {fold} with majority vote per individual\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # === Group predictions and labels by ID ===\n",
    "    id_to_preds = defaultdict(list)\n",
    "    id_to_true = {}\n",
    "\n",
    "    for pred, true, cow_id in zip(y_pred, y_test, ids):\n",
    "        id_to_preds[cow_id].append(pred)\n",
    "        id_to_true[cow_id] = true  # assumes all images of same cow have same label\n",
    "\n",
    "    # === Apply majority vote per individual ===\n",
    "    y_true_individuals = []\n",
    "    y_pred_individuals = []\n",
    "\n",
    "    for cow_id in sorted(id_to_preds.keys()):\n",
    "        preds = id_to_preds[cow_id]\n",
    "        vote = Counter(preds).most_common(1)[0][0]\n",
    "        y_pred_individuals.append(vote)\n",
    "        y_true_individuals.append(id_to_true[cow_id])\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_true_individuals, y_pred_individuals)\n",
    "    f1 = f1_score(y_true_individuals, y_pred_individuals)\n",
    "    precision = precision_score(y_true_individuals, y_pred_individuals)\n",
    "    recall = recall_score(y_true_individuals, y_pred_individuals)\n",
    "    conf_mat = confusion_matrix(y_true_individuals, y_pred_individuals)\n",
    "\n",
    "    print(f\"📊 Fold {fold} Test Metrics (Majority Vote per Individual):\")\n",
    "    print(f\"Individuals Evaluated: {len(y_true_individuals)}\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_mat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Folds for bulls using 8e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 8e-3\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === 5-Fold Cross Validation ===\n",
    "for val_fold in range(1, 6):\n",
    "    print(f\"\\n🚀 Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    X_train, y_train = [], []\n",
    "    for fold in range(1, 6):\n",
    "        if fold == val_fold:\n",
    "            continue\n",
    "        fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "        X, y = load_images_and_labels(fold_dir)\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Validation data\n",
    "    val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load and modify model\n",
    "    model = load_model(cow_model_path)\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Create output directories\n",
    "    fold_tag = f'fold{val_fold}'\n",
    "    model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"⏱️ Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"📊 Fold {val_fold} Results (LR = 8e-3):\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 8e-3\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Only Folds 3, 4, and 5 ===\n",
    "for val_fold in [3, 4, 5]:\n",
    "    print(f\"\\n🚀 Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "    # Prepare training data from remaining folds\n",
    "    X_train, y_train = [], []\n",
    "    for fold in [1, 2, 3, 4, 5]:\n",
    "        if fold == val_fold:\n",
    "            continue\n",
    "        fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "        X, y = load_images_and_labels(fold_dir)\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Validation data\n",
    "    val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load and modify model\n",
    "    model = load_model(cow_model_path)\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Create output directories\n",
    "    fold_tag = f'fold{val_fold}'\n",
    "    model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"⏱️ Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"📊 Fold {val_fold} Results (LR = {lr}):\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 8e-3\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Only Folds 3, 4, and 5 ===\n",
    "for val_fold in [5]:\n",
    "    print(f\"\\n🚀 Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "    # Prepare training data from remaining folds\n",
    "    X_train, y_train = [], []\n",
    "    for fold in [1, 2, 3, 4, 5]:\n",
    "        if fold == val_fold:\n",
    "            continue\n",
    "        fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "        X, y = load_images_and_labels(fold_dir)\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Validation data\n",
    "    val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load and modify model\n",
    "    model = load_model(cow_model_path)\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Create output directories\n",
    "    fold_tag = f'fold{val_fold}'\n",
    "    model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"⏱️ Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"📊 Fold {val_fold} Results (LR = {lr}):\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 8e-3\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Fold 5 Training ===\n",
    "val_fold = 5\n",
    "print(f\"\\n🚀 Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "# Prepare training data from remaining folds\n",
    "X_train, y_train = [], []\n",
    "for fold in [1, 2, 3, 4, 5]:\n",
    "    if fold == val_fold:\n",
    "        continue\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# Validation data\n",
    "val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Load and modify model ===\n",
    "base_model = load_model(cow_model_path)\n",
    "\n",
    "# Freeze most layers\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# ✅ Add sigmoid activation to final output\n",
    "x = base_model.output\n",
    "output = Activation('sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# ✅ Build model to finalize variables (prevents TFLite crash)\n",
    "model(tf.zeros((1, 224, 224, 3)))\n",
    "\n",
    "# === Compile ===\n",
    "model.compile(optimizer=Adam(learning_rate=lr),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# === Create output directories ===\n",
    "fold_tag = f'fold{val_fold}'\n",
    "model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "# === Callbacks ===\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model_built.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# === Train ===\n",
    "start = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "elapsed = time.time() - start\n",
    "print(f\"⏱️ Training time: {elapsed:.2f}s\")\n",
    "\n",
    "# === Save training history ===\n",
    "with open(os.path.join(history_dir, 'history_built.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "print(f\"\\n📊 Fold {val_fold} Results (LR = {lr}):\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 18\n",
    "})\n",
    "\n",
    "# === Directory and LR\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Histories'\n",
    "chosen_lr = 8e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load history file\n",
    "def load_history(fold):\n",
    "    tag = f'fold{fold}'\n",
    "    file_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"❌ History not found for Fold {fold}: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# === Load all fold histories\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    hist = load_history(fold)\n",
    "    if hist:\n",
    "        fold_histories[fold] = hist\n",
    "\n",
    "# === Plotting function\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # --- Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color='blue', alpha=0.5, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Loss Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # --- Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], color='blue', alpha=0.5, label=f'Fold {fold} Train Acc' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Acc' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Accuracy Across Folds (LR=8e-3)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Run plotting\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"🚫 No valid history files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings (large & clean) ===\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 16\n",
    "})\n",
    "\n",
    "# === Config ===\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Histories'\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "model_label = 'VGG16 (LR=8e-3)'  # <- change if you want on the titles\n",
    "show_ema = True                   # toggle smoothing overlay on/off\n",
    "ema_alpha = 0.2                   # lower = more smoothing\n",
    "\n",
    "# === Utilities ===\n",
    "def load_history(fold):\n",
    "    \"\"\"Load Keras History.history dict from pickle.\"\"\"\n",
    "    file_path = os.path.join(base_history_dir, f'fold{fold}', 'history.pkl')\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Not found: {file_path}\")\n",
    "        return None\n",
    "    with open(file_path, 'rb') as f:\n",
    "        hist = pickle.load(f)\n",
    "    # Some pickles store History object; others store dict. Normalize to dict.\n",
    "    if hasattr(hist, 'history'):\n",
    "        hist = hist.history\n",
    "    return hist\n",
    "\n",
    "def get_metric(history, key, default_key=None):\n",
    "    \"\"\"Safely fetch a metric from history, trying an alternate key if needed.\"\"\"\n",
    "    if key in history:\n",
    "        return list(history[key])\n",
    "    if default_key and default_key in history:\n",
    "        return list(history[default_key])\n",
    "    # Try common variants\n",
    "    variants = [key, key.lower(), key.replace('accuracy','acc'), key.replace('val_accuracy','val_acc')]\n",
    "    for v in variants:\n",
    "        if v in history:\n",
    "            return list(history[v])\n",
    "    return None\n",
    "\n",
    "def exponential_moving_average(x, alpha=0.2):\n",
    "    if x is None or len(x) == 0:\n",
    "        return x\n",
    "    out = [x[0]]\n",
    "    for i in range(1, len(x)):\n",
    "        out.append(alpha * x[i] + (1 - alpha) * out[-1])\n",
    "    return out\n",
    "\n",
    "# === Load histories ===\n",
    "fold_histories = {}\n",
    "for f in folds:\n",
    "    h = load_history(f)\n",
    "    if h:\n",
    "        fold_histories[f] = h\n",
    "\n",
    "if not fold_histories:\n",
    "    raise SystemExit(\"🚫 No valid history files found.\")\n",
    "\n",
    "# === Collect best epoch stats per fold ===\n",
    "summary = []  # each item: dict with fold, best_epoch, val_loss, val_acc, train_loss, train_acc\n",
    "for f, hist in fold_histories.items():\n",
    "    val_loss = get_metric(hist, 'val_loss')\n",
    "    if not val_loss:\n",
    "        print(f\"⚠️ Fold {f}: no 'val_loss' found; skipping.\")\n",
    "        continue\n",
    "    loss = get_metric(hist, 'loss')\n",
    "    val_acc = get_metric(hist, 'val_accuracy', default_key='val_acc')\n",
    "    acc = get_metric(hist, 'accuracy', default_key='acc')\n",
    "\n",
    "    best_idx = int(np.argmin(val_loss))\n",
    "    row = {\n",
    "        'fold': f,\n",
    "        'best_epoch_idx': best_idx,\n",
    "        'best_epoch_number': best_idx + 1,  # human-friendly 1-based\n",
    "        'best_val_loss': float(val_loss[best_idx]),\n",
    "        'best_val_acc': float(val_acc[best_idx]) if val_acc else float('nan'),\n",
    "        'train_loss_at_best': float(loss[best_idx]) if loss else float('nan'),\n",
    "        'train_acc_at_best': float(acc[best_idx]) if acc else float('nan'),\n",
    "        'num_epochs': len(val_loss)\n",
    "    }\n",
    "    summary.append(row)\n",
    "\n",
    "# Sort by fold for nice printing\n",
    "summary = sorted(summary, key=lambda d: d['fold'])\n",
    "\n",
    "# === Print a compact table ===\n",
    "print(\"\\n📋 Best-epoch summary (per fold):\")\n",
    "print(f\"{'Fold':>4} | {'Epoch':>5} | {'Val Loss':>9} | {'Val Acc':>8} | {'Train Loss':>10} | {'Train Acc':>9} | {'#Ep':>4}\")\n",
    "print(\"-\" * 64)\n",
    "for r in summary:\n",
    "    print(f\"{r['fold']:>4} | {r['best_epoch_number']:>5} | {r['best_val_loss']:>9.4f} | \"\n",
    "          f\"{(r['best_val_acc'] if not math.isnan(r['best_val_acc']) else float('nan')):>8.4f} | \"\n",
    "          f\"{(r['train_loss_at_best'] if not math.isnan(r['train_loss_at_best']) else float('nan')):>10.4f} | \"\n",
    "          f\"{(r['train_acc_at_best'] if not math.isnan(r['train_acc_at_best']) else float('nan')):>9.4f} | \"\n",
    "          f\"{r['num_epochs']:>4}\")\n",
    "\n",
    "# === Aggregate stats across folds ===\n",
    "valid_accs = [r['best_val_acc'] for r in summary if not math.isnan(r['best_val_acc'])]\n",
    "avg_best_val_acc = float(np.mean(valid_accs)) if valid_accs else float('nan')\n",
    "avg_best_val_loss = float(np.mean([r['best_val_loss'] for r in summary]))\n",
    "print(f\"\\n🔢 Cross-fold averages — Best Val Acc: {avg_best_val_acc:.4f} | Best Val Loss: {avg_best_val_loss:.4f}\\n\")\n",
    "\n",
    "# === Plot 1: Curves with best-epoch markers (val_loss & val_accuracy) ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# --- Loss curves\n",
    "ax = axes[0]\n",
    "for f, hist in fold_histories.items():\n",
    "    loss = get_metric(hist, 'loss')\n",
    "    val_loss = get_metric(hist, 'val_loss')\n",
    "    if not val_loss: \n",
    "        continue\n",
    "    epochs = np.arange(1, len(val_loss) + 1)\n",
    "    if show_ema:\n",
    "        loss_sm = exponential_moving_average(loss, ema_alpha) if loss else None\n",
    "        val_loss_sm = exponential_moving_average(val_loss, ema_alpha)\n",
    "        if loss_sm:\n",
    "            ax.plot(epochs, loss_sm, alpha=0.4, label=f'Fold {f} Train (EMA)')\n",
    "        ax.plot(epochs, val_loss_sm, '--', alpha=0.9, label=f'Fold {f} Val (EMA)')\n",
    "    else:\n",
    "        if loss:\n",
    "            ax.plot(epochs, loss, alpha=0.4, label=f'Fold {f} Train')\n",
    "        ax.plot(epochs, val_loss, '--', alpha=0.9, label=f'Fold {f} Val')\n",
    "\n",
    "    # best epoch marker\n",
    "    best_idx = int(np.argmin(val_loss))\n",
    "    ax.axvline(best_idx + 1, color='gray', linestyle=':', alpha=0.6)\n",
    "\n",
    "ax.set_title(f'Loss Curves with Best-Epoch Markers\\n{model_label}')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(ncol=2, frameon=True, fontsize=12)\n",
    "\n",
    "# --- Accuracy curves\n",
    "ax = axes[1]\n",
    "for f, hist in fold_histories.items():\n",
    "    acc = get_metric(hist, 'accuracy', default_key='acc')\n",
    "    val_acc = get_metric(hist, 'val_accuracy', default_key='val_acc')\n",
    "    if not val_acc:\n",
    "        continue\n",
    "    epochs = np.arange(1, len(val_acc) + 1)\n",
    "    if show_ema:\n",
    "        acc_sm = exponential_moving_average(acc, ema_alpha) if acc else None\n",
    "        val_acc_sm = exponential_moving_average(val_acc, ema_alpha)\n",
    "        if acc_sm:\n",
    "            ax.plot(epochs, acc_sm, alpha=0.4, label=f'Fold {f} Train (EMA)')\n",
    "        ax.plot(epochs, val_acc_sm, '--', alpha=0.9, label=f'Fold {f} Val (EMA)')\n",
    "    else:\n",
    "        if acc:\n",
    "            ax.plot(epochs, acc, alpha=0.4, label=f'Fold {f} Train')\n",
    "        ax.plot(epochs, val_acc, '--', alpha=0.9, label=f'Fold {f} Val')\n",
    "\n",
    "    # best epoch marker (by val_loss)\n",
    "    val_loss = get_metric(hist, 'val_loss')\n",
    "    if val_loss:\n",
    "        best_idx = int(np.argmin(val_loss))\n",
    "        ax.axvline(best_idx + 1, color='gray', linestyle=':', alpha=0.6)\n",
    "\n",
    "ax.set_title(f'Accuracy Curves with Best-Epoch Markers\\n{model_label}')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(ncol=2, frameon=True, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Plot 2: Bar chart of best val_accuracy per fold + average line ===\n",
    "fold_ids = [r['fold'] for r in summary]\n",
    "best_accs = [r['best_val_acc'] for r in summary]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar([str(f) for f in fold_ids], best_accs)\n",
    "for b, v in zip(bars, best_accs):\n",
    "    plt.text(b.get_x() + b.get_width()/2, v + 0.002, f\"{v:.3f}\", ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "if not math.isnan(avg_best_val_acc):\n",
    "    plt.axhline(avg_best_val_acc, linestyle='--', alpha=0.8)\n",
    "    plt.text(len(fold_ids)-0.4, avg_best_val_acc + 0.002, f\"Avg {avg_best_val_acc:.3f}\", fontsize=14)\n",
    "\n",
    "plt.title(f'Best Validation Accuracy per Fold\\n{model_label}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO TRansfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings (consistent) ===\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 16\n",
    "})\n",
    "\n",
    "# === Paths (your corrected set) ===\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "model_label = f'MobileNetV2 (LR={chosen_lr:.0e})'\n",
    "\n",
    "# === Options ===\n",
    "show_ema = True     # overlay smoothing to calm noisy curves\n",
    "ema_alpha = 0.2     # lower = more smoothing\n",
    "zoom_last_n = 10    # how many epochs to zoom into at the end\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def lr_tag_variants(lr):\n",
    "    \"\"\"Produce likely folder-tag strings for the LR portion.\"\"\"\n",
    "    # 0.002 -> '2e-03' and '2e-3'\n",
    "    s1 = f\"{lr:.0e}\"        # e.g., '2e-03'\n",
    "    s2 = s1.replace('e-0', 'e-')  # -> '2e-3'\n",
    "    return [s1, s2]\n",
    "\n",
    "def load_history(fold):\n",
    "    \"\"\"Try multiple tag variants to find history.pkl for the given fold.\"\"\"\n",
    "    tried = []\n",
    "    for lr_tag in lr_tag_variants(chosen_lr):\n",
    "        tag = f\"LR_{lr_tag}_Fold{fold}\"\n",
    "        p = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "        tried.append(p)\n",
    "        if os.path.exists(p):\n",
    "            with open(p, 'rb') as f:\n",
    "                h = pickle.load(f)\n",
    "            if hasattr(h, 'history'):\n",
    "                h = h.history  # normalize to dict\n",
    "            return h\n",
    "        # Some users stored a tag without the minus sign at all\n",
    "        tag2 = tag.replace('-', '')\n",
    "        p2 = os.path.join(base_history_dir, tag2, 'history.pkl')\n",
    "        tried.append(p2)\n",
    "        if os.path.exists(p2):\n",
    "            with open(p2, 'rb') as f:\n",
    "                h = pickle.load(f)\n",
    "            if hasattr(h, 'history'):\n",
    "                h = h.history\n",
    "            return h\n",
    "    print(f\"❌ History not found for Fold {fold}. Tried:\\n  - \" + \"\\n  - \".join(tried))\n",
    "    return None\n",
    "\n",
    "def get_metric(history, key, fallback=None):\n",
    "    \"\"\"Fetch metric with common variants handled.\"\"\"\n",
    "    if not history:\n",
    "        return None\n",
    "    if key in history:\n",
    "        return list(history[key])\n",
    "    if fallback and fallback in history:\n",
    "        return list(history[fallback])\n",
    "    for v in [key.lower(),\n",
    "              key.replace('accuracy','acc'),\n",
    "              key.replace('val_accuracy','val_acc'),\n",
    "              key.replace('Accuracy','acc')]:\n",
    "        if v in history:\n",
    "            return list(history[v])\n",
    "    return None\n",
    "\n",
    "def ema(x, alpha=0.2):\n",
    "    if x is None or len(x) == 0:\n",
    "        return x\n",
    "    out = [x[0]]\n",
    "    for i in range(1, len(x)):\n",
    "        out.append(alpha * x[i] + (1 - alpha) * out[-1])\n",
    "    return out\n",
    "\n",
    "# ---------- Load histories ----------\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    h = load_history(fold)\n",
    "    if h:\n",
    "        fold_histories[fold] = h\n",
    "\n",
    "if not fold_histories:\n",
    "    raise SystemExit(\"🚫 No valid history files found.\")\n",
    "\n",
    "# ---------- Summarize best epoch (by val_loss) ----------\n",
    "summary = []\n",
    "for f, hist in fold_histories.items():\n",
    "    vloss = get_metric(hist, 'val_loss')\n",
    "    if not vloss:\n",
    "        print(f\"⚠️ Fold {f}: missing 'val_loss'; skipping.\")\n",
    "        continue\n",
    "    loss = get_metric(hist, 'loss')\n",
    "    vacc = get_metric(hist, 'val_accuracy', fallback='val_acc')\n",
    "    acc  = get_metric(hist, 'accuracy', fallback='acc')\n",
    "\n",
    "    best_idx = int(np.argmin(vloss))\n",
    "    summary.append({\n",
    "        'fold': f,\n",
    "        'best_epoch_idx': best_idx,\n",
    "        'best_epoch_number': best_idx + 1,\n",
    "        'best_val_loss': float(vloss[best_idx]),\n",
    "        'best_val_acc': float(vacc[best_idx]) if vacc else float('nan'),\n",
    "        'train_loss_at_best': float(loss[best_idx]) if loss else float('nan'),\n",
    "        'train_acc_at_best': float(acc[best_idx]) if acc else float('nan'),\n",
    "        'num_epochs': len(vloss)\n",
    "    })\n",
    "\n",
    "summary = sorted(summary, key=lambda d: d['fold'])\n",
    "\n",
    "# Print table\n",
    "print(\"\\n📋 Best-epoch summary (per fold):\")\n",
    "print(f\"{'Fold':>4} | {'Epoch':>5} | {'Val Loss':>9} | {'Val Acc':>8} | {'Train Loss':>10} | {'Train Acc':>9} | {'#Ep':>4}\")\n",
    "print(\"-\" * 64)\n",
    "for r in summary:\n",
    "    print(f\"{r['fold']:>4} | {r['best_epoch_number']:>5} | {r['best_val_loss']:>9.4f} | \"\n",
    "          f\"{(r['best_val_acc'] if not math.isnan(r['best_val_acc']) else float('nan')):>8.4f} | \"\n",
    "          f\"{(r['train_loss_at_best'] if not math.isnan(r['train_loss_at_best']) else float('nan')):>10.4f} | \"\n",
    "          f\"{(r['train_acc_at_best'] if not math.isnan(r['train_acc_at_best']) else float('nan')):>9.4f} | \"\n",
    "          f\"{r['num_epochs']:>4}\")\n",
    "\n",
    "valid_accs = [r['best_val_acc'] for r in summary if not math.isnan(r['best_val_acc'])]\n",
    "avg_best_val_acc = float(np.mean(valid_accs)) if valid_accs else float('nan')\n",
    "avg_best_val_loss = float(np.mean([r['best_val_loss'] for r in summary]))\n",
    "print(f\"\\n🔢 Cross-fold averages — Best Val Acc: {avg_best_val_acc:.4f} | Best Val Loss: {avg_best_val_loss:.4f}\\n\")\n",
    "\n",
    "# ---------- Plot 1: Full curves with best-epoch markers ----------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Loss\n",
    "ax = axes[0]\n",
    "for f, hist in fold_histories.items():\n",
    "    loss = get_metric(hist, 'loss')\n",
    "    vloss = get_metric(hist, 'val_loss')\n",
    "    if not vloss:\n",
    "        continue\n",
    "    epochs = np.arange(1, len(vloss) + 1)\n",
    "    if show_ema:\n",
    "        loss_sm = ema(loss, ema_alpha) if loss else None\n",
    "        vloss_sm = ema(vloss, ema_alpha)\n",
    "        if loss_sm:\n",
    "            ax.plot(epochs, loss_sm, alpha=0.4, label=f'Fold {f} Train (EMA)')\n",
    "        ax.plot(epochs, vloss_sm, '--', alpha=0.9, label=f'Fold {f} Val (EMA)')\n",
    "    else:\n",
    "        if loss:\n",
    "            ax.plot(epochs, loss, alpha=0.4, label=f'Fold {f} Train')\n",
    "        ax.plot(epochs, vloss, '--', alpha=0.9, label=f'Fold {f} Val')\n",
    "    best_idx = int(np.argmin(vloss))\n",
    "    ax.axvline(best_idx + 1, color='gray', linestyle=':', alpha=0.6)\n",
    "\n",
    "ax.set_title(f'Loss Curves with Best-Epoch Markers\\n{model_label}')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss'); ax.grid(alpha=0.3)\n",
    "ax.legend(ncol=2, frameon=True, fontsize=12)\n",
    "\n",
    "# Accuracy\n",
    "ax = axes[1]\n",
    "for f, hist in fold_histories.items():\n",
    "    acc  = get_metric(hist, 'accuracy', fallback='acc')\n",
    "    vacc = get_metric(hist, 'val_accuracy', fallback='val_acc')\n",
    "    if not vacc:\n",
    "        continue\n",
    "    epochs = np.arange(1, len(vacc) + 1)\n",
    "    if show_ema:\n",
    "        acc_sm  = ema(acc, ema_alpha) if acc else None\n",
    "        vacc_sm = ema(vacc, ema_alpha)\n",
    "        if acc_sm:\n",
    "            ax.plot(epochs, acc_sm, alpha=0.4, label=f'Fold {f} Train (EMA)')\n",
    "        ax.plot(epochs, vacc_sm, '--', alpha=0.9, label=f'Fold {f} Val (EMA)')\n",
    "    else:\n",
    "        if acc:\n",
    "            ax.plot(epochs, acc, alpha=0.4, label=f'Fold {f} Train')\n",
    "        ax.plot(epochs, vacc, '--', alpha=0.9, label=f'Fold {f} Val')\n",
    "\n",
    "    vloss = get_metric(hist, 'val_loss')\n",
    "    if vloss:\n",
    "        best_idx = int(np.argmin(vloss))\n",
    "        ax.axvline(best_idx + 1, color='gray', linestyle=':', alpha=0.6)\n",
    "\n",
    "ax.set_title(f'Accuracy Curves with Best-Epoch Markers\\n{model_label}')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Accuracy'); ax.grid(alpha=0.3)\n",
    "ax.legend(ncol=2, frameon=True, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Plot 2: Zoom on last N epochs (loss & accuracy) ----------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Loss zoom\n",
    "ax = axes[0]\n",
    "for f, hist in fold_histories.items():\n",
    "    loss = get_metric(hist, 'loss')\n",
    "    vloss = get_metric(hist, 'val_loss')\n",
    "    if not vloss: \n",
    "        continue\n",
    "    # last N\n",
    "    loss_last  = loss[-zoom_last_n:] if loss else None\n",
    "    vloss_last = vloss[-zoom_last_n:]\n",
    "    # epoch indices aligned to global epoch numbers\n",
    "    start = len(vloss) - zoom_last_n + 1\n",
    "    epochs = np.arange(start, start + len(vloss_last))\n",
    "    if loss_last:\n",
    "        ax.plot(epochs, loss_last, alpha=0.4, label=f'Fold {f} Train')\n",
    "    ax.plot(epochs, vloss_last, '--', alpha=0.9, label=f'Fold {f} Val')\n",
    "ax.set_title(f'Loss — Last {zoom_last_n} Epochs\\n{model_label}')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss'); ax.grid(alpha=0.3)\n",
    "ax.legend(ncol=2, frameon=True, fontsize=12)\n",
    "\n",
    "# Accuracy zoom\n",
    "ax = axes[1]\n",
    "for f, hist in fold_histories.items():\n",
    "    acc  = get_metric(hist, 'accuracy', fallback='acc')\n",
    "    vacc = get_metric(hist, 'val_accuracy', fallback='val_acc')\n",
    "    if not vacc: \n",
    "        continue\n",
    "    acc_last  = acc[-zoom_last_n:] if acc else None\n",
    "    vacc_last = vacc[-zoom_last_n:]\n",
    "    start = len(vacc) - zoom_last_n + 1\n",
    "    epochs = np.arange(start, start + len(vacc_last))\n",
    "    if acc_last:\n",
    "        ax.plot(epochs, acc_last, alpha=0.4, label=f'Fold {f} Train')\n",
    "    ax.plot(epochs, vacc_last, '--', alpha=0.9, label=f'Fold {f} Val')\n",
    "ax.set_title(f'Accuracy — Last {zoom_last_n} Epochs\\n{model_label}')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Accuracy'); ax.grid(alpha=0.3)\n",
    "ax.legend(ncol=2, frameon=True, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- Plot 3: Best val_accuracy per fold + average ----------\n",
    "fold_ids = [r['fold'] for r in summary]\n",
    "best_accs = [r['best_val_acc'] for r in summary]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar([str(f) for f in fold_ids], best_accs)\n",
    "for b, v in zip(bars, best_accs):\n",
    "    plt.text(b.get_x() + b.get_width()/2, v + 0.002, f\"{v:.3f}\", ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "if not math.isnan(avg_best_val_acc):\n",
    "    plt.axhline(avg_best_val_acc, linestyle='--', alpha=0.8)\n",
    "    plt.text(len(fold_ids)-0.4, avg_best_val_acc + 0.002, f\"Avg {avg_best_val_acc:.3f}\", fontsize=14)\n",
    "\n",
    "plt.title(f'Best Validation Accuracy per Fold\\n{model_label}')\n",
    "plt.xlabel('Fold'); plt.ylabel('Best Validation Accuracy'); plt.ylim(0, 1)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Print metrics at minimum val_loss per fold\n",
    "print(\"\\n📉 Metrics at Minimum Validation Loss Per Fold\")\n",
    "print(f\"{'Fold':<6} {'Epoch':<6} {'Val Loss':<10} {'Val Acc':<10} {'Train Loss':<11} {'Train Acc':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for fold, history in fold_histories.items():\n",
    "    val_losses = history['val_loss']\n",
    "    min_idx = int(np.argmin(val_losses))\n",
    "\n",
    "    val_loss = val_losses[min_idx]\n",
    "    val_acc = history['val_accuracy'][min_idx]\n",
    "    train_loss = history['loss'][min_idx]\n",
    "    train_acc = history['accuracy'][min_idx]\n",
    "\n",
    "    # Correct if metrics were saved as percentage\n",
    "    if val_acc > 1.5: val_acc /= 100.0\n",
    "    if train_acc > 1.5: train_acc /= 100.0\n",
    "\n",
    "    print(f\"{fold:<6} {min_idx:<6} {val_loss:<10.4f} {val_acc:<10.4f} {train_loss:<11.4f} {train_acc:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load test images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Evaluating Fold {fold} model on test set\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(recall_curve, prec_curve)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"📊 Fold {fold} Test Metrics:\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_mat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === Font settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 18\n",
    "})\n",
    "\n",
    "# === Updated Fold metrics from test evaluation\n",
    "metrics = [\n",
    "    {'Fold': 1, 'Accuracy': 0.5532, 'F1 Score': 0.5227, 'Precision': 0.5610, 'Recall': 0.4894, 'AUC-PR': 0.5593},\n",
    "    {'Fold': 2, 'Accuracy': 0.5000, 'F1 Score': 0.3380, 'Precision': 0.5000, 'Recall': 0.2553, 'AUC-PR': 0.5777},\n",
    "    {'Fold': 3, 'Accuracy': 0.5426, 'F1 Score': 0.4691, 'Precision': 0.5588, 'Recall': 0.4043, 'AUC-PR': 0.6038},\n",
    "    {'Fold': 4, 'Accuracy': 0.5426, 'F1 Score': 0.4691, 'Precision': 0.5588, 'Recall': 0.4043, 'AUC-PR': 0.5537},\n",
    "    {'Fold': 5, 'Accuracy': 0.5532, 'F1 Score': 0.5333, 'Precision': 0.5581, 'Recall': 0.5106, 'AUC-PR': 0.4832}\n",
    "]\n",
    "\n",
    "# === Convert to long-form DataFrame\n",
    "plot_data = []\n",
    "for m in metrics:\n",
    "    for metric_name in ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']:\n",
    "        plot_data.append({\n",
    "            'Fold': f\"Fold {m['Fold']}\",\n",
    "            'Metric': metric_name,\n",
    "            'Value': m[metric_name]\n",
    "        })\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "# === Violin Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.violinplot(x='Metric', y='Value', data=df_plot, inner='point', palette='muted')\n",
    "plt.title('Distribution of Evaluation Metrics Across Folds')\n",
    "plt.ylim(0.08, 1.0)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load test images with filenames and IDs ===\n",
    "def load_images_labels_and_ids(image_dir):\n",
    "    images, labels, filenames, ids = [], [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        subdir_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(subdir_path):\n",
    "            continue\n",
    "        for fname in os.listdir(subdir_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "                # Extract ID from filename (e.g., abc123_1.jpg → abc123)\n",
    "                id_part = fname.split('_')[0]\n",
    "                ids.append(id_part)\n",
    "    return np.array(images), np.array(labels), np.array(filenames), np.array(ids)\n",
    "\n",
    "X_test, y_test, filenames, ids = load_images_labels_and_ids(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model with majority voting per individual ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Evaluating Fold {fold} with majority vote per individual\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # === Group predictions and labels by ID ===\n",
    "    id_to_preds = defaultdict(list)\n",
    "    id_to_true = {}\n",
    "\n",
    "    for pred, true, cow_id in zip(y_pred, y_test, ids):\n",
    "        id_to_preds[cow_id].append(pred)\n",
    "        id_to_true[cow_id] = true  # assumes all images of same cow have same label\n",
    "\n",
    "    # === Apply majority vote per individual ===\n",
    "    y_true_individuals = []\n",
    "    y_pred_individuals = []\n",
    "\n",
    "    for cow_id in sorted(id_to_preds.keys()):\n",
    "        preds = id_to_preds[cow_id]\n",
    "        vote = Counter(preds).most_common(1)[0][0]\n",
    "        y_pred_individuals.append(vote)\n",
    "        y_true_individuals.append(id_to_true[cow_id])\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_true_individuals, y_pred_individuals)\n",
    "    f1 = f1_score(y_true_individuals, y_pred_individuals)\n",
    "    precision = precision_score(y_true_individuals, y_pred_individuals)\n",
    "    recall = recall_score(y_true_individuals, y_pred_individuals)\n",
    "    conf_mat = confusion_matrix(y_true_individuals, y_pred_individuals)\n",
    "\n",
    "    print(f\"📊 Fold {fold} Test Metrics (Majority Vote per Individual):\")\n",
    "    print(f\"Individuals Evaluated: {len(y_true_individuals)}\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load test images (with filenames) ===\n",
    "def load_images_labels_and_filenames(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in sorted(os.listdir(full_path)):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(f\"{subdir}/{fname}\")\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "X_test, y_test, filenames = load_images_labels_and_filenames(test_dir)\n",
    "\n",
    "# === Evaluate each fold's model ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Evaluating Fold {fold} model on test set\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # === Predict all ===\n",
    "    y_pred_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # === Print individual predictions ===\n",
    "    print(\"\\n📋 Per-image predictions:\")\n",
    "    for fname, prob, true_label in zip(filenames, y_pred_probs, y_test):\n",
    "        pred_label = \"Good\" if prob > 0.5 else \"Bad\"\n",
    "        actual_label = \"Good\" if true_label == 1 else \"Bad\"\n",
    "        print(f\"{fname:<50} | Predicted: {pred_label:>4} ({prob:.4f}) | Actual: {actual_label}\")\n",
    "\n",
    "    # === Metrics ===\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(recall_curve, prec_curve)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n📊 Fold {fold} Test Metrics:\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models'\n",
    "image_path = \"/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1/Bad/R18228_6_IMG_3154_Rating5_processed.jpg\"\n",
    "# image_path = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Test copy/Bad/R18228_6_IMG_3154_Rating5.jpg\"\n",
    "\n",
    "# === Load model (Fold 5) ===\n",
    "model_path = os.path.join(base_model_dir, 'fold5', 'bull_transfer_model.keras')\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "model = load_model(model_path)\n",
    "print(f\"✅ Loaded model: {model_path}\")\n",
    "\n",
    "# === Preprocess image ===\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "x = img_to_array(img) / 255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# === Predict ===\n",
    "prob = float(model.predict(x, verbose=0).flatten()[0])  # sigmoid prob of \"Good\"\n",
    "pred_label = \"Good\" if prob > 0.5 else \"Bad\"\n",
    "\n",
    "# === Infer actual label from folder name ===\n",
    "parent = os.path.basename(os.path.dirname(image_path))\n",
    "actual_label = parent if parent in {\"Good\", \"Bad\"} else \"Unknown\"\n",
    "\n",
    "# === Output ===\n",
    "print(\"\\n🖼️ Image:\", image_path)\n",
    "print(f\"🔮 Predicted: {pred_label} (p(Good) = {prob:.4f})\")\n",
    "print(f\"🏷️  Actual   : {actual_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models'\n",
    "image_path = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Test/Good/MAD21216_IMG_4_Rating8.jpg\"\n",
    "\n",
    "# === Preprocess the single image ===\n",
    "img = load_img(image_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img).astype(np.float32) / 255.0\n",
    "input_array = np.expand_dims(img_array, axis=0)  # Shape: (1, 224, 224, 3)\n",
    "\n",
    "print(f\"✅ Image loaded: {os.path.basename(image_path)}\")\n",
    "print(f\"📐 Shape: {input_array.shape}, dtype: {input_array.dtype}\")\n",
    "\n",
    "# === Predict with each fold ===\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n🧪 Predicting with Fold {fold} model\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    model(tf.zeros((1, 224, 224, 3)))  # Warm-up\n",
    "\n",
    "    prob = float(model.predict(input_array, verbose=0)[0][0])\n",
    "    label = \"Good\" if prob > 0.5 else \"Bad\"\n",
    "\n",
    "    print(f\"🧪 Fold {fold} Prediction: {label} ({prob:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# === Load base model and wrap with sigmoid (if not done already) ===\n",
    "base_model = load_model(\"/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models/fold5/bull_transfer_model.keras\")\n",
    "output = Activation(\"sigmoid\")(base_model.output)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# === Save new model WITH sigmoid ===\n",
    "model.save(\"/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds/Models/fold5/bull_transfer_model_with_sigmoid.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "prob = expit(float(output[0][0]))\n",
    "label = \"Good\" if prob > 0.5 else \"Bad\"\n",
    "print(f\"🧪 Sigmoid-corrected TFLite Prediction: {label} ({prob:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# ================== Paths ==================\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'  # contains Fold1..Fold5/{Good,Bad}\n",
    "output_base   = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_8e3Final5Folds'\n",
    "# Models expected at: {output_base}/Models/fold{K}/bull_transfer_model.keras\n",
    "\n",
    "# ================== Config ==================\n",
    "FOLDS  = [1, 2, 3, 4, 5]\n",
    "TOP_N  = 2               # how many misclassified originals to show per fold\n",
    "BATCH  = 32\n",
    "\n",
    "# Filenames containing any of these substrings are considered AUGMENTED and will be skipped\n",
    "AUGMENTATION_KEYWORDS = [\n",
    "    \"_aug\", \"_flip\", \"_rot\", \"_rotated\", \"_shift\", \"_zoom\", \"_noise\", \"_noisy\",\n",
    "    \"_blur\", \"_shear\", \"_contrast\", \"_bright\", \"_gamma\", \"_cutout\", \"_mixup\"\n",
    "]\n",
    "\n",
    "def is_original_filename(fname: str) -> bool:\n",
    "    f = fname.lower()\n",
    "    return not any(k in f for k in AUGMENTATION_KEYWORDS)\n",
    "\n",
    "def load_val_images_labels_paths(val_dir):\n",
    "    \"\"\"\n",
    "    Loads ALL .jpg images from val_dir/{Good,Bad}. Returns (X, y, paths, filenames).\n",
    "    \"\"\"\n",
    "    X, y, paths, names = [], [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full = os.path.join(val_dir, subdir)\n",
    "        if not os.path.isdir(full):\n",
    "            continue\n",
    "        for fname in os.listdir(full):\n",
    "            if not fname.lower().endswith('.jpg'):\n",
    "                continue\n",
    "            fpath = os.path.join(full, fname)\n",
    "            try:\n",
    "                img = load_img(fpath, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                X.append(arr)\n",
    "                y.append(1 if subdir == 'Good' else 0)\n",
    "                paths.append(fpath)\n",
    "                names.append(fname)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Skipping {fpath}: {e}\")\n",
    "    if len(X) == 0:\n",
    "        return np.empty((0,224,224,3), dtype=np.float32), np.array([]), [], []\n",
    "    return np.stack(X, axis=0), np.array(y), paths, names\n",
    "\n",
    "def pick_top_misclassified_originals(y_true, probs, paths, names, top_n):\n",
    "    \"\"\"\n",
    "    Rank misclassified ORIGINAL images by confidence, return indices (into arrays) of top_n.\n",
    "    - misclassified if predicted != y_true\n",
    "    - confidence = max(p, 1-p)\n",
    "    - only keep entries where filename passes is_original_filename()\n",
    "    \"\"\"\n",
    "    probs = probs.reshape(-1)\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    conf  = np.maximum(probs, 1 - probs)\n",
    "\n",
    "    # misclassified mask\n",
    "    wrong = preds != y_true\n",
    "\n",
    "    # original-only mask (no augmentation keywords)\n",
    "    originals = np.array([is_original_filename(n) for n in names])\n",
    "\n",
    "    # combine masks\n",
    "    cand_idx = np.where(wrong & originals)[0]\n",
    "    if cand_idx.size == 0:\n",
    "        return []\n",
    "\n",
    "    # sort by descending confidence\n",
    "    order = cand_idx[np.argsort(-conf[cand_idx])]\n",
    "    return order[:top_n]\n",
    "\n",
    "# ================== Main ==================\n",
    "for fold in FOLDS:\n",
    "    print(f\"\\n🔎 Fold {fold}:\")\n",
    "    model_path = os.path.join(output_base, 'Models', f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.isfile(model_path):\n",
    "        print(f\"❌ Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    val_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X_val, y_val, paths, names = load_val_images_labels_paths(val_dir)\n",
    "    if X_val.shape[0] == 0:\n",
    "        print(\"⚠️ No validation images found.\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    probs = model.predict(X_val, batch_size=BATCH, verbose=0).reshape(-1)\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    conf  = np.maximum(probs, 1 - probs)\n",
    "\n",
    "    # choose top-N misclassified originals\n",
    "    top_idx = pick_top_misclassified_originals(y_val, probs, paths, names, TOP_N)\n",
    "    if len(top_idx) == 0:\n",
    "        print(\"✅ No misclassified ORIGINAL images found in this fold.\")\n",
    "        continue\n",
    "\n",
    "    # Print filenames in one line\n",
    "    print(\"📂 Top misclassified ORIGINAL filenames:\")\n",
    "    print(\" | \".join([names[i] for i in top_idx]))\n",
    "\n",
    "    # Show images\n",
    "    fig, axes = plt.subplots(1, len(top_idx), figsize=(6 * len(top_idx), 6))\n",
    "    if len(top_idx) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, i in zip(axes, top_idx):\n",
    "        img = load_img(paths[i], target_size=(224, 224))\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(\n",
    "            f\"{names[i]}\\nTrue:{'Good' if y_val[i] else 'Bad'} | Pred:{'Good' if preds[i] else 'Bad'} | Conf:{conf[i]:.2f}\",\n",
    "            fontsize=11\n",
    "        )\n",
    "    plt.suptitle(f\"Fold {fold} — Top {len(top_idx)} misclassified ORIGINALS\", fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# ===== Paths =====\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "\n",
    "# ===== Example: fill in your own single misclassified filename per fold =====\n",
    "# Put the filename exactly as it appears in the Good/Bad folder for each fold\n",
    "misclassified_images = {\n",
    "    1: \"JH2128_16_Rating5_processed.jpg\",\n",
    "    2: \"\",\n",
    "    3: \"\",\n",
    "    4: \"\",\n",
    "    5: \"\"\n",
    "}\n",
    "\n",
    "# ===== Display loop =====\n",
    "for fold, fname in misclassified_images.items():\n",
    "    if not fname.strip():\n",
    "        continue\n",
    "    \n",
    "    # Search in both Good and Bad folders\n",
    "    found_path = None\n",
    "    for subdir in [\"Good\", \"Bad\"]:\n",
    "        candidate = os.path.join(bull_base_dir, f\"Fold{fold}\", subdir, fname)\n",
    "        if os.path.isfile(candidate):\n",
    "            found_path = candidate\n",
    "            break\n",
    "    \n",
    "    if not found_path:\n",
    "        print(f\"❌ Image not found for Fold {fold}: {fname}\")\n",
    "        continue\n",
    "    \n",
    "    # Show image\n",
    "    img = load_img(found_path, target_size=(224, 224))\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Fold {fold} - {fname}\", fontsize=12)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
