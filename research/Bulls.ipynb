{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reanme Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# --- Paths ---\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/BullsAndCows_Final.xlsx\"\n",
    "image_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/Erico\"\n",
    "output_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/RenamedImages\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Load Excel file ---\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Clean column names if needed\n",
    "df = df.rename(columns=lambda x: x.strip())  # Remove spaces in column headers\n",
    "df = df.rename(columns={\"ID\": \"Base_ID\", \"Photo Number\": \"Photo_Number\"})\n",
    "\n",
    "# Filter out any rows with missing photo numbers\n",
    "df = df[df[\"Photo_Number\"].notna()]\n",
    "\n",
    "# --- Copy and rename ---\n",
    "for _, row in df.iterrows():\n",
    "    base_id = row[\"Base_ID\"]\n",
    "    photo_number = int(row[\"Photo_Number\"])\n",
    "    \n",
    "    original_filename = f\"IMG_{str(photo_number)}.jpg\"\n",
    "    new_filename = f\"{base_id}_IMG_{str(photo_number)}.jpg\"\n",
    "\n",
    "    original_path = os.path.join(image_dir, original_filename)\n",
    "    new_path = os.path.join(output_dir, new_filename)\n",
    "\n",
    "    if os.path.exists(original_path):\n",
    "        shutil.copy2(original_path, new_path)\n",
    "        print(f\"Copied: {original_filename} ‚Üí {new_filename}\")\n",
    "    else:\n",
    "        print(f\"Missing: {original_filename}\")\n",
    "\n",
    "print(\"‚úÖ All done! Images copied and renamed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/BullsAndCows_Final.xlsx\"\n",
    "image_folder = \"/Users/suzetteschulenburg/Desktop/Bulls/RenamedImages\"\n",
    "\n",
    "# Load Excel and clean columns\n",
    "df = pd.read_excel(excel_path)\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "df = df.rename(columns={\"ID\": \"Base_ID\", \"Photo Number\": \"Photo_Number\", \"Rating\": \"Rating\"})\n",
    "\n",
    "# Loop through each row to rename accordingly\n",
    "for _, row in df.iterrows():\n",
    "    base_id = row[\"Base_ID\"]\n",
    "    photo_number = int(row[\"Photo_Number\"])\n",
    "    rating = row[\"Rating\"]\n",
    "\n",
    "    original_filename = f\"{base_id}_IMG_{photo_number}.jpg\"\n",
    "    new_filename = f\"{base_id}_IMG_{photo_number}_Rating{rating}.jpg\"\n",
    "\n",
    "    original_path = os.path.join(image_folder, original_filename)\n",
    "    new_path = os.path.join(image_folder, new_filename)\n",
    "\n",
    "    if os.path.exists(original_path):\n",
    "        os.rename(original_path, new_path)\n",
    "        print(f\"Renamed: {original_filename} ‚Üí {new_filename}\")\n",
    "    else:\n",
    "        print(f\"Not found: {original_filename}\")\n",
    "\n",
    "print(\"‚úÖ Done renaming with ratings!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Paths\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/UselessExcel/Martiens.xlsx\"  # adjust if needed\n",
    "image_folder = \"/Users/suzetteschulenburg/Desktop/Bulls/RenamedImages\"\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(excel_path)\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "df = df.rename(columns={\"Id\": \"Base_ID\", \"Rating\": \"Rating\"})\n",
    "\n",
    "# Loop through each ID in the Excel\n",
    "for _, row in df.iterrows():\n",
    "    base_id = row[\"Base_ID\"]\n",
    "    rating = row[\"Rating\"]\n",
    "\n",
    "    # Search for images that start with the ID\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.startswith(base_id) and filename.endswith(\".jpg\"):\n",
    "            match = re.search(rf\"{base_id}_(\\d+)\", filename)\n",
    "            if match:\n",
    "                img_number = match.group(1)\n",
    "                new_name = f\"{base_id}_IMG_{img_number}_Rating{rating}.jpg\"\n",
    "                original_path = os.path.join(image_folder, filename)\n",
    "                new_path = os.path.join(image_folder, new_name)\n",
    "\n",
    "                os.rename(original_path, new_path)\n",
    "                print(f\"Renamed: {filename} ‚Üí {new_name}\")\n",
    "            else:\n",
    "                print(f\"Couldn't extract image number from: {filename}\")\n",
    "\n",
    "print(\"‚úÖ Done renaming based on ID and adding rating.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/3vdBestes.xlsx\"\n",
    "image_folder = \"/Users/suzetteschulenburg/Desktop/Masters/Beeste/Backup/3VDFOTOS\"\n",
    "\n",
    "# === Load and clean Excel ===\n",
    "df = pd.read_excel(excel_path)\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "df = df.rename(columns={\"Photo number\": \"Photo_Number\", \"Base id\": \"Base_ID\", \"Rating\": \"Rating\"})\n",
    "\n",
    "# === Sort by Photo_Number to ensure correct sequence ===\n",
    "df = df.sort_values(\"Photo_Number\")\n",
    "\n",
    "# === Set the first image number in the folder ===\n",
    "current_image_number = 1119\n",
    "\n",
    "# === Go through each animal ===\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        end_number = int(row[\"Photo_Number\"])\n",
    "        base_id = str(row[\"Base_ID\"]).strip()\n",
    "        rating = int(row[\"Rating\"])\n",
    "\n",
    "        img_index = 1\n",
    "        for number in range(current_image_number, end_number + 1):\n",
    "            original_name = f\"IMG_{number}.jpg\"\n",
    "            new_name = f\"{base_id}_{img_index}_Rating{rating}.jpg\"\n",
    "\n",
    "            original_path = os.path.join(image_folder, original_name)\n",
    "            new_path = os.path.join(image_folder, new_name)\n",
    "\n",
    "            if os.path.exists(original_path):\n",
    "                os.rename(original_path, new_path)\n",
    "                print(f\"‚úÖ Renamed: {original_name} ‚Üí {new_name}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Not found: {original_name} ‚Äî skipping\")\n",
    "\n",
    "            img_index += 1\n",
    "\n",
    "        # Move the counter to the next starting image\n",
    "        current_image_number = end_number + 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipped row due to error: {row.to_dict()} ‚Üí {e}\")\n",
    "\n",
    "print(\"üéâ All done renaming based on Base ID, image sequence, and rating!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# === Paths ===\n",
    "excel_path = \"/Users/suzetteschulenburg/Desktop/Masters/Data/Martiens_later.xlsx\"\n",
    "image_folder = \"/Users/suzetteschulenburg/Desktop/Bulls/Martiens\"\n",
    "output_folder = \"/Users/suzetteschulenburg/Desktop/Bulls/RenamedMartiens\"\n",
    "\n",
    "# === Create output directory ===\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === Load and clean Excel ===\n",
    "df = pd.read_excel(excel_path)\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "df = df.rename(columns={\"Photo number\": \"Photo_Number\", \"Id\": \"ID\", \"Rating\": \"Rating\"})\n",
    "\n",
    "# === Sort to ensure correct order ===\n",
    "df = df.sort_values(\"Photo_Number\")\n",
    "\n",
    "# === Starting image number ===\n",
    "current_image_number = 2828  # You can change this if needed\n",
    "\n",
    "# === Rename and copy ===\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        end_number = int(row[\"Photo_Number\"])\n",
    "        photo_id = str(row[\"ID\"]).strip()\n",
    "        rating = int(row[\"Rating\"])\n",
    "\n",
    "        # === Skip if 'los' in ID ===\n",
    "        if \"los\" in photo_id.lower():\n",
    "            print(f\"‚è© Skipped '{photo_id}' due to 'los'\")\n",
    "            continue\n",
    "\n",
    "        img_index = 1\n",
    "        for number in range(current_image_number, end_number + 1):\n",
    "            original_name = f\"IMG_{number}.jpg\"\n",
    "            new_name = f\"{photo_id}_{img_index}_IMG_{number}_Rating{rating}.jpg\"\n",
    "\n",
    "            original_path = os.path.join(image_folder, original_name)\n",
    "            new_path = os.path.join(output_folder, new_name)\n",
    "\n",
    "            if os.path.exists(original_path):\n",
    "                shutil.copy(original_path, new_path)\n",
    "                print(f\"‚úÖ Copied: {original_name} ‚Üí {new_name}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Missing: {original_name}\")\n",
    "\n",
    "            img_index += 1\n",
    "\n",
    "        # Move pointer to next batch\n",
    "        current_image_number = end_number + 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error on row {row.to_dict()} ‚Üí {e}\")\n",
    "\n",
    "print(\"üéâ All done! Multiple images per animal copied and renamed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort into Good and Bad folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "# === Paths ===\n",
    "source_folder = \"/Users/suzetteschulenburg/Desktop/Bulls/Copy/All Bulls\"\n",
    "bad_folder = \"/Users/suzetteschulenburg/Desktop/Bulls/Bad\"\n",
    "good_folder = \"/Users/suzetteschulenburg/Desktop/Bulls/Good\"\n",
    "\n",
    "# === Create folders if they don't exist ===\n",
    "os.makedirs(bad_folder, exist_ok=True)\n",
    "os.makedirs(good_folder, exist_ok=True)\n",
    "\n",
    "# === Go through each image in the source folder ===\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.lower().endswith(\".jpg\"):\n",
    "        match = re.search(r\"Rating(\\d+)\", filename)\n",
    "        if match:\n",
    "            rating = int(match.group(1))\n",
    "            source_path = os.path.join(source_folder, filename)\n",
    "\n",
    "            if rating in [1, 2, 3, 4, 5]:\n",
    "                dest_path = os.path.join(bad_folder, filename)\n",
    "                shutil.copy2(source_path, dest_path)\n",
    "                print(f\"üì• Copied to Bad: {filename}\")\n",
    "\n",
    "            elif rating in [8, 9]:\n",
    "                dest_path = os.path.join(good_folder, filename)\n",
    "                shutil.copy2(source_path, dest_path)\n",
    "                print(f\"üì• Copied to Good: {filename}\")\n",
    "\n",
    "print(\"üéâ Done copying based on ratings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort into Folds + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Paths ===\n",
    "good_dir = \"/Users/suzetteschulenburg/Desktop/Split/Good\"\n",
    "bad_dir = \"/Users/suzetteschulenburg/Desktop/Bad\"\n",
    "split_base = \"/Users/suzetteschulenburg/Desktop/Split\"\n",
    "test_dir = os.path.join(split_base, \"Test\")\n",
    "folds_dir = os.path.join(split_base, \"Folds\")\n",
    "num_folds = 5\n",
    "test_ratio = 0.25\n",
    "\n",
    "# === Group by Base ID ===\n",
    "def group_by_base_id(directory):\n",
    "    base_id_groups = defaultdict(list)\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            base_id = filename.split(\"_\")[0]\n",
    "            base_id_groups[base_id].append(os.path.join(directory, filename))\n",
    "    return base_id_groups\n",
    "\n",
    "good_groups = group_by_base_id(good_dir)\n",
    "bad_groups = group_by_base_id(bad_dir)\n",
    "\n",
    "# === Split Base IDs into test/train sets ===\n",
    "def split_ids(groups, test_ratio=0.25):\n",
    "    ids = list(groups.keys())\n",
    "    random.shuffle(ids)\n",
    "    test_size = int(len(ids) * test_ratio)\n",
    "    test_ids = ids[:test_size]\n",
    "    train_ids = ids[test_size:]\n",
    "    return train_ids, test_ids\n",
    "\n",
    "good_train_ids, good_test_ids = split_ids(good_groups, test_ratio)\n",
    "bad_train_ids, bad_test_ids = split_ids(bad_groups, test_ratio)\n",
    "\n",
    "# === Helper to copy grouped images ===\n",
    "def copy_group(ids, group_dict, dest_dir):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    for base_id in ids:\n",
    "        for file_path in group_dict[base_id]:\n",
    "            shutil.copy2(file_path, os.path.join(dest_dir, os.path.basename(file_path)))\n",
    "\n",
    "# === Copy Test set ===\n",
    "copy_group(good_test_ids, good_groups, os.path.join(test_dir, \"Good\"))\n",
    "copy_group(bad_test_ids, bad_groups, os.path.join(test_dir, \"Bad\"))\n",
    "print(f\"‚úÖ Test Set: {len(good_test_ids)} Good IDs, {len(bad_test_ids)} Bad IDs\")\n",
    "\n",
    "# === Split remaining training base IDs into folds ===\n",
    "def split_into_folds(ids, n_folds):\n",
    "    random.shuffle(ids)\n",
    "    folds = [[] for _ in range(n_folds)]\n",
    "    for i, base_id in enumerate(ids):\n",
    "        folds[i % n_folds].append(base_id)\n",
    "    return folds\n",
    "\n",
    "good_folds = split_into_folds(good_train_ids, num_folds)\n",
    "bad_folds = split_into_folds(bad_train_ids, num_folds)\n",
    "\n",
    "# === Create Fold directories and copy ===\n",
    "for i in range(num_folds):\n",
    "    fold_path = os.path.join(folds_dir, f\"Fold{i+1}\")\n",
    "    good_dest = os.path.join(fold_path, \"Good\")\n",
    "    bad_dest = os.path.join(fold_path, \"Bad\")\n",
    "    os.makedirs(good_dest, exist_ok=True)\n",
    "    os.makedirs(bad_dest, exist_ok=True)\n",
    "\n",
    "    copy_group(good_folds[i], good_groups, good_dest)\n",
    "    copy_group(bad_folds[i], bad_groups, bad_dest)\n",
    "\n",
    "    print(f\"‚úÖ Fold{i+1}: {len(good_folds[i])} Good IDs, {len(bad_folds[i])} Bad IDs\")\n",
    "\n",
    "print(\"\\nüéâ Completed 25% Test split and 5-fold split for remaining 75% Train data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# === Base folds path ===\n",
    "base_folds_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds\"\n",
    "num_folds = 5\n",
    "\n",
    "# === Count images ===\n",
    "print(\"üìä Image Counts Per Fold (excluding Test Set):\\n\")\n",
    "for i in range(1, num_folds + 1):\n",
    "    fold_name = f\"Fold{i}\"\n",
    "    fold_dir = os.path.join(base_folds_dir, fold_name)\n",
    "    \n",
    "    good_dir = os.path.join(fold_dir, \"Good\")\n",
    "    bad_dir = os.path.join(fold_dir, \"Bad\")\n",
    "\n",
    "    # Count only JPG images in the top-level (not in subfolders)\n",
    "    good_images = [f for f in os.listdir(good_dir) \n",
    "                   if f.endswith('.jpg') and os.path.isfile(os.path.join(good_dir, f))]\n",
    "    bad_images = [f for f in os.listdir(bad_dir) \n",
    "                  if f.endswith('.jpg') and os.path.isfile(os.path.join(bad_dir, f))]\n",
    "\n",
    "    print(f\"üìÅ {fold_name}: üü¢ Good = {len(good_images)} | üî¥ Bad = {len(bad_images)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Done counting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Settings ===\n",
    "history_save_dir = '/Users/suzetteschulenburg/Desktop/MainUse/LearningRate_HistoriesResNetCropped'\n",
    "learning_rates = [1e-6, 5e-7, 1e-7, 5e-8, 1e-8, 5e-9]\n",
    "\n",
    "# === Initialize plots ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ö†Ô∏è Missing file: {path}\")\n",
    "        continue\n",
    "    with open(path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    \n",
    "    plt.plot(history['val_loss'], label=f'Val Loss LR={lr:.0e}', linestyle='--')\n",
    "    plt.plot(history['loss'], label=f'Train Loss LR={lr:.0e}', linestyle='-')\n",
    "\n",
    "plt.title('Training vs. Validation Loss Across Learning Rates')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Accuracy Plot ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_save_dir, f'history_resnet_lr{lr}_fold1.pkl')\n",
    "    if not os.path.exists(path):\n",
    "        continue\n",
    "    with open(path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    \n",
    "    plt.plot(history['val_accuracy'], label=f'Val Acc LR={lr:.0e}', linestyle='--')\n",
    "    plt.plot(history['accuracy'], label=f'Train Acc LR={lr:.0e}', linestyle='-')\n",
    "\n",
    "plt.title('Training vs. Validation Accuracy Across Learning Rates')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# === Original and copy paths ===\n",
    "original_test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "copied_test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Create a new copy of the Test folder ===\n",
    "if not os.path.exists(original_test_dir):\n",
    "    raise FileNotFoundError(f\"Original test directory not found: {original_test_dir}\")\n",
    "\n",
    "if os.path.exists(copied_test_dir):\n",
    "    print(f\"Copy directory already exists at {copied_test_dir}. Remove it first if you want a clean copy.\")\n",
    "else:\n",
    "    shutil.copytree(original_test_dir, copied_test_dir)\n",
    "    print(f\"Copied test directory to: {copied_test_dir}\")\n",
    "\n",
    "# === Count files in Good and Bad ===\n",
    "good_dir = os.path.join(copied_test_dir, 'Good')\n",
    "bad_dir = os.path.join(copied_test_dir, 'Bad')\n",
    "\n",
    "good_images = [f for f in os.listdir(good_dir) if f.lower().endswith('.jpg')]\n",
    "bad_images = [f for f in os.listdir(bad_dir) if f.lower().endswith('.jpg')]\n",
    "\n",
    "num_good = len(good_images)\n",
    "num_bad = len(bad_images)\n",
    "print(f\"Good images: {num_good}, Bad images: {num_bad}\")\n",
    "\n",
    "# === Randomly delete excess 'Bad' images ===\n",
    "num_to_delete = num_bad - num_good\n",
    "if num_to_delete <= 0:\n",
    "    print(\"No images need to be deleted from 'Bad'.\")\n",
    "else:\n",
    "    images_to_delete = random.sample(bad_images, num_to_delete)\n",
    "    for fname in images_to_delete:\n",
    "        file_path = os.path.join(bad_dir, fname)\n",
    "        os.remove(file_path)\n",
    "    print(f\"Deleted {num_to_delete} excess 'Bad' images. Final count should now match 'Good'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# === Test directory path ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Initialize containers ===\n",
    "class_individuals = {'Good': set(), 'Bad': set()}\n",
    "\n",
    "# === Loop through both classes ===\n",
    "for label in ['Good', 'Bad']:\n",
    "    class_dir = os.path.join(test_dir, label)\n",
    "    if not os.path.exists(class_dir):\n",
    "        print(f\"Folder missing: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    for fname in os.listdir(class_dir):\n",
    "        if fname.lower().endswith('.jpg'):\n",
    "            base_id = fname.split('_')[0]  # e.g., 'ADC123' from 'ADC123_1.jpg'\n",
    "            class_individuals[label].add(base_id)\n",
    "\n",
    "# === Print results ===\n",
    "for label in ['Good', 'Bad']:\n",
    "    count = len(class_individuals[label])\n",
    "    print(f\"Number of individual animals in '{label}': {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths to your folds and test set\n",
    "fold_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "test_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# Function to collect base IDs from a directory\n",
    "def collect_base_ids(directory, categories=['Good', 'Bad']):\n",
    "    base_ids = defaultdict(list)\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(directory, category)\n",
    "        if not os.path.exists(category_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(category_dir):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                base_id = fname.split('_')[0]  # Extract base ID\n",
    "                base_ids[base_id].append(os.path.join(category_dir, fname))\n",
    "    return base_ids\n",
    "\n",
    "# Collect base IDs from folds\n",
    "fold_base_ids = {}\n",
    "for fold in range(1, 6):  # Assuming 5 folds\n",
    "    fold_dir = os.path.join(fold_base_dir, f'Fold{fold}')\n",
    "    fold_base_ids[f'Fold{fold}'] = set(collect_base_ids(fold_dir).keys())\n",
    "\n",
    "# Collect base IDs from test set\n",
    "test_base_ids = set(collect_base_ids(test_base_dir).keys())\n",
    "\n",
    "# Check for overlaps between folds\n",
    "overlap_found = False\n",
    "print(\"Checking for overlaps between folds:\")\n",
    "for fold1 in fold_base_ids:\n",
    "    for fold2 in fold_base_ids:\n",
    "        if fold1 != fold2:\n",
    "            overlap = fold_base_ids[fold1].intersection(fold_base_ids[fold2])\n",
    "            if overlap:\n",
    "                overlap_found = True\n",
    "                print(f\"Overlap found between {fold1} and {fold2}: {overlap}\")\n",
    "\n",
    "if not overlap_found:\n",
    "    print(\"No overlap detected between folds!\")\n",
    "\n",
    "# Check for overlaps between test set and folds\n",
    "test_overlap_found = False\n",
    "print(\"\\nChecking for overlaps between test set and folds:\")\n",
    "for fold, fold_ids in fold_base_ids.items():\n",
    "    overlap = fold_ids.intersection(test_base_ids)\n",
    "    if overlap:\n",
    "        test_overlap_found = True\n",
    "        print(f\"Overlap found between test set and {fold}: {overlap}\")\n",
    "\n",
    "if not test_overlap_found:\n",
    "    print(\"No overlap detected between test set and any folds!\")\n",
    "\n",
    "# Example: Print a few base IDs from each fold and the test set\n",
    "print(\"\\nExample Base IDs from Each Fold and Test Set:\")\n",
    "for fold, base_ids in fold_base_ids.items():\n",
    "    print(f\"{fold}: {list(base_ids)[:5]}\")  # Print first 5 base IDs for each fold\n",
    "print(f\"Test Set: {list(test_base_ids)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmente images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
    "\n",
    "# === Custom safe augmentation functions ===\n",
    "def add_gaussian_noise(img, mean=0, std=25):\n",
    "    np_img = np.array(img.convert(\"RGB\"))  # Ensure RGB for noise\n",
    "    noise = np.random.normal(mean, std, np_img.shape).astype(np.uint8)\n",
    "    noisy_img = np_img + noise\n",
    "    noisy_img = np.clip(noisy_img, 0, 255)\n",
    "    return Image.fromarray(noisy_img)\n",
    "\n",
    "def adjust_gamma(img, gamma=1.5):\n",
    "    img = img.convert(\"RGB\")  # Ensure image is in RGB mode\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = [((i / 255.0) ** inv_gamma) * 255 for i in range(256)]\n",
    "    return img.point(table * 3)  # Apply LUT to all 3 RGB channels\n",
    "\n",
    "def adjust_hue(img, hue_factor=0.5):\n",
    "    img_hsv = np.array(img.convert(\"HSV\"))\n",
    "    img_hsv[..., 0] = (img_hsv[..., 0].astype(int) + int(hue_factor * 255)) % 255\n",
    "    return Image.fromarray(img_hsv, \"HSV\").convert(\"RGB\")\n",
    "\n",
    "def get_augmentations(img):\n",
    "    img = img.convert(\"RGB\")  # Ensure consistent mode\n",
    "    return [\n",
    "        ('Flipped', ImageOps.mirror(img)),\n",
    "        ('Grayscale', ImageOps.grayscale(img).convert(\"RGB\")),\n",
    "        ('FlippedGrayscale', ImageOps.mirror(ImageOps.grayscale(img)).convert(\"RGB\")),\n",
    "        ('Noisy', add_gaussian_noise(img)),\n",
    "        ('Sharpened', ImageEnhance.Sharpness(img).enhance(2.0)),\n",
    "        ('Contrast', ImageEnhance.Contrast(img).enhance(1.5)),\n",
    "        ('Blurred', img.filter(ImageFilter.GaussianBlur(radius=2))),\n",
    "        ('GammaCorrected', adjust_gamma(img)),\n",
    "        ('HueAdjusted', adjust_hue(img))\n",
    "    ]\n",
    "\n",
    "# === Base directory ===\n",
    "base_folds_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds\"\n",
    "num_folds = 5\n",
    "\n",
    "for i in range(1, num_folds + 1):\n",
    "    print(f\"\\nüîÅ Processing Fold{i}\")\n",
    "    fold_dir = os.path.join(base_folds_dir, f\"Fold{i}\")\n",
    "    good_dir = os.path.join(fold_dir, \"Good\")\n",
    "    bad_dir = os.path.join(fold_dir, \"Bad\")\n",
    "\n",
    "    good_images = [f for f in os.listdir(good_dir) if f.endswith('.jpg')]\n",
    "    bad_images = [f for f in os.listdir(bad_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    # Step 1: Augment every Good image 9 times (original + 9 = 10x per image)\n",
    "    print(f\"‚ú® Augmenting {len(good_images)} Good images √ó9\")\n",
    "    for file in good_images:\n",
    "        try:\n",
    "            img_path = os.path.join(good_dir, file)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            base = os.path.splitext(file)[0]\n",
    "\n",
    "            for name, aug_img in get_augmentations(img):\n",
    "                aug_filename = f\"{base}_aug{name}.jpg\"\n",
    "                aug_img.save(os.path.join(good_dir, aug_filename))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed on Good image {file}: {e}\")\n",
    "\n",
    "    # Step 2: Calculate how many Bad augmentations are needed to match Good total\n",
    "    total_good = len(good_images) * 10  # original + 9 augmentations per image\n",
    "    total_bad = len(bad_images)\n",
    "    needed_bad_augmentations = total_good - total_bad\n",
    "    print(f\"‚ú® Need to generate {needed_bad_augmentations} Bad augmentations\")\n",
    "\n",
    "    augmented = 0\n",
    "    aug_index = 0\n",
    "    while augmented < needed_bad_augmentations:\n",
    "        for file in bad_images:\n",
    "            if augmented >= needed_bad_augmentations:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                img_path = os.path.join(bad_dir, file)\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                base = os.path.splitext(file)[0]\n",
    "                aug_name, aug_img = get_augmentations(img)[aug_index % 9]\n",
    "                aug_filename = f\"{base}_aug{aug_name}_{augmented+1}.jpg\"\n",
    "                aug_img.save(os.path.join(bad_dir, aug_filename))\n",
    "\n",
    "                augmented += 1\n",
    "                aug_index += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Failed on Bad image {file}: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Final count in Fold{i}: Good = {total_good}, Bad = {total_bad + augmented}\")\n",
    "\n",
    "print(\"\\nüéâ All folds processed using custom augmentation logic without PIL errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count base ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds'\n",
    "\n",
    "# Function to count unique base IDs in each class per fold\n",
    "def count_unique_base_ids_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):  # Iterate over folds 1 to 5\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_base_id_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:  # Check for 'Good' and 'Bad' classes\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                base_ids = set()\n",
    "                for filename in os.listdir(class_dir):\n",
    "                    if filename.lower().endswith('.jpg'):\n",
    "                        # Extract base ID (e.g., E2025 from E2025_IMG_8469_sharp.jpg)\n",
    "                        base_id = filename.split('_')[0]\n",
    "                        base_ids.add(base_id)\n",
    "                class_base_id_counts[class_name] = len(base_ids)\n",
    "            else:\n",
    "                class_base_id_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_base_id_counts\n",
    "    return folds_data\n",
    "\n",
    "# Get unique base ID counts per fold\n",
    "folds_data = count_unique_base_ids_per_fold(base_directory)\n",
    "\n",
    "# Print the results\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Base directory containing folds\n",
    "base_directory = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "\n",
    "# Function to count images in each class per fold\n",
    "def count_images_per_fold(base_directory):\n",
    "    folds_data = {}\n",
    "    for fold in range(1, 6):  # Iterate over folds 1 to 5\n",
    "        fold_dir = os.path.join(base_directory, f'Fold{fold}')\n",
    "        class_counts = {}\n",
    "        for class_name in ['Good', 'Bad']:  # Check for 'Good' and 'Bad' classes\n",
    "            class_dir = os.path.join(fold_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                num_images = len([f for f in os.listdir(class_dir) if f.lower().endswith('.jpg')])\n",
    "                class_counts[class_name] = num_images\n",
    "            else:\n",
    "                class_counts[class_name] = 0\n",
    "        folds_data[f'Fold{fold}'] = class_counts\n",
    "    return folds_data\n",
    "\n",
    "# Get image counts per fold\n",
    "folds_data = count_images_per_fold(base_directory)\n",
    "\n",
    "# Print the results\n",
    "for fold, counts in folds_data.items():\n",
    "    print(f\"{fold}: {counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show augmented images for one bull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# === Base image path\n",
    "base_image_path = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold1/Good/MAD21259_IMG_4_Rating8.jpg\"\n",
    "base_dir = os.path.dirname(base_image_path)\n",
    "base_filename = os.path.splitext(os.path.basename(base_image_path))[0]\n",
    "\n",
    "# === Augmentation suffixes\n",
    "aug_suffixes = [\n",
    "    \"augFlipped\",\n",
    "    \"augGrayscale\",\n",
    "    \"augFlippedGrayscale\",\n",
    "    \"augNoisy\",\n",
    "    \"augSharpened\",\n",
    "    \"augContrast\",\n",
    "    \"augBlurred\",\n",
    "    \"augGammaCorrected\",\n",
    "    \"augHueAdjusted\"\n",
    "]\n",
    "\n",
    "# === Title formatter to insert spaces before capital letters\n",
    "def clean_title(s):\n",
    "    return ''.join([' ' + c if c.isupper() else c for c in s]).strip()\n",
    "\n",
    "# === Collect image paths and cleaned titles\n",
    "image_versions = [(\"Original\", base_image_path)]\n",
    "for suffix in aug_suffixes:\n",
    "    aug_path = os.path.join(base_dir, f\"{base_filename}_{suffix}.jpg\")\n",
    "    readable_name = clean_title(suffix.replace(\"aug\", \"\"))\n",
    "    image_versions.append((readable_name, aug_path))\n",
    "\n",
    "# === Plot with increased font sizes and spacing\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(22, 12))\n",
    "fig.suptitle(\"Original and Augmented Images\", fontsize=32)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.75)\n",
    "\n",
    "for ax, (title, img_path) in zip(axes.flatten(), image_versions):\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title, fontsize=26)\n",
    "        ax.axis('off')\n",
    "    except Exception as e:\n",
    "        ax.set_title(f\"{title}\\n(Not Found)\", fontsize=30)\n",
    "        ax.axis('off')\n",
    "        print(f\"‚ö†Ô∏è Failed to load {img_path}: {e}\")\n",
    "\n",
    "# Hide any unused axes\n",
    "for ax in axes.flatten()[len(image_versions):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.91])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# === Base image path\n",
    "base_image_path = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold1/Good/MAD21259_IMG_4_Rating8.jpg\"\n",
    "base_dir = os.path.dirname(base_image_path)\n",
    "base_filename = os.path.splitext(os.path.basename(base_image_path))[0]\n",
    "\n",
    "# === Augmentation suffixes\n",
    "aug_suffixes = [\n",
    "    \"augFlipped\",\n",
    "    \"augGrayscale\",\n",
    "    \"augFlippedGrayscale\",\n",
    "    \"augNoisy\",\n",
    "    \"augSharpened\",\n",
    "    \"augContrast\",\n",
    "    \"augBlurred\",\n",
    "    \"augGammaCorrected\",\n",
    "    \"augHueAdjusted\"\n",
    "]\n",
    "\n",
    "# === Title formatter to insert spaces before capital letters\n",
    "def clean_title(s):\n",
    "    return ''.join([' ' + c if c.isupper() else c for c in s]).strip()\n",
    "\n",
    "# === Collect image paths and cleaned titles\n",
    "image_versions = [(\"Original\", base_image_path)]\n",
    "for suffix in aug_suffixes:\n",
    "    aug_path = os.path.join(base_dir, f\"{base_filename}_{suffix}.jpg\")\n",
    "    readable_name = clean_title(suffix.replace(\"aug\", \"\"))\n",
    "    image_versions.append((readable_name, aug_path))\n",
    "\n",
    "# === Plot with increased font sizes and spacing\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(22, 12))\n",
    "fig.suptitle(\"Original and Augmented Images\", fontsize=36)  # Main title larger\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.75)\n",
    "\n",
    "for ax, (title, img_path) in zip(axes.flatten(), image_versions):\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title, fontsize=30)  # Larger title font\n",
    "        ax.axis('off')\n",
    "    except Exception as e:\n",
    "        ax.set_title(f\"{title}\\n(Not Found)\", fontsize=30)\n",
    "        ax.axis('off')\n",
    "        print(f\"‚ö†Ô∏è Failed to load {img_path}: {e}\")\n",
    "\n",
    "# Hide any unused axes\n",
    "for ax in axes.flatten()[len(image_versions):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.91])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# === Function to resize with padding ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "\n",
    "    # Create new image and center the resized image on it\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    color = [255, 255, 255]  # White background\n",
    "    new_im = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return new_im\n",
    "\n",
    "# === Load YOLO segmentation model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "# === Paths ===\n",
    "input_base = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold5\"\n",
    "output_base = \"/Users/suzetteschulenburg/Desktop/BullsProcessed/Fold5\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# === Subfolders to process ===\n",
    "classes = ['Good', 'Bad']\n",
    "\n",
    "for cls in classes:\n",
    "    input_folder = os.path.join(input_base, cls)\n",
    "    output_folder = os.path.join(output_base, cls)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.endswith('.jpg'):\n",
    "            continue\n",
    "\n",
    "        # === Load image ===\n",
    "        image_path = os.path.join(input_folder, fname)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"‚ö†Ô∏è Could not read: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_h, image_w = image_rgb.shape[:2]\n",
    "\n",
    "        # === Run YOLO segmentation ===\n",
    "        results = model(image_rgb)\n",
    "        masks = results[0].masks\n",
    "        boxes = results[0].boxes\n",
    "        names = results[0].names\n",
    "\n",
    "        if masks is None or len(masks.data) == 0:\n",
    "            print(f\"‚ùå No cow mask found in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Get largest cow ===\n",
    "        best_index = None\n",
    "        largest_area = 0\n",
    "        for i, cls_id in enumerate(boxes.cls.cpu().numpy()):\n",
    "            name = names[int(cls_id)]\n",
    "            if name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                if area > largest_area:\n",
    "                    best_index = i\n",
    "                    largest_area = area\n",
    "\n",
    "        if best_index is None:\n",
    "            print(f\"‚ùå No valid cow class in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Resize mask to image ===\n",
    "        mask = masks.data[best_index].cpu().numpy()\n",
    "        resized_mask = cv2.resize(mask, (image_w, image_h), interpolation=cv2.INTER_NEAREST)\n",
    "        mask_3ch = np.stack([resized_mask] * 3, axis=-1)\n",
    "\n",
    "        # === Apply mask to full image ===\n",
    "        masked_image = np.where(mask_3ch > 0.5, image_rgb, 255)\n",
    "\n",
    "        # === Crop, remove bottom 30%, add margin ===\n",
    "        x1, y1, x2, y2 = map(int, boxes.xyxy[best_index].cpu().numpy())\n",
    "        margin = 0.1\n",
    "        x1 = max(0, x1 - int((x2 - x1) * margin))\n",
    "        x2 = min(image_w, x2 + int((x2 - x1) * margin))\n",
    "        y2 = y1 + int((y2 - y1) * 0.7)  # remove bottom 30%\n",
    "\n",
    "        cropped = masked_image[y1:y2, x1:x2]\n",
    "\n",
    "        # === Resize with padding to 224x224 ===\n",
    "        resized = resize_with_padding(cropped, desired_size=224)\n",
    "\n",
    "        # === Save final image ===\n",
    "        output_path = os.path.join(output_folder, fname.replace(\".jpg\", \"_processed.jpg\"))\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        print(f\"‚úÖ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# === Function to resize with padding ===\n",
    "def resize_with_padding(image, desired_size=224):\n",
    "    old_size = image.shape[:2]  # (height, width)\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "\n",
    "    # Resize image\n",
    "    resized_image = cv2.resize(image, (new_size[1], new_size[0]))\n",
    "\n",
    "    # Create new image and center the resized image on it\n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "\n",
    "    color = [255, 255, 255]  # White background\n",
    "    new_im = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return new_im\n",
    "\n",
    "# === Load YOLO segmentation model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "# === Paths ===\n",
    "input_base = \"/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Test\"\n",
    "output_base = \"/Users/suzetteschulenburg/Desktop/BullsProcessed/Test\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# === Subfolders to process ===\n",
    "classes = ['Good', 'Bad']\n",
    "\n",
    "for cls in classes:\n",
    "    input_folder = os.path.join(input_base, cls)\n",
    "    output_folder = os.path.join(output_base, cls)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(input_folder):\n",
    "        if not fname.endswith('.jpg'):\n",
    "            continue\n",
    "\n",
    "        # === Load image ===\n",
    "        image_path = os.path.join(input_folder, fname)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"‚ö†Ô∏è Could not read: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_h, image_w = image_rgb.shape[:2]\n",
    "\n",
    "        # === Run YOLO segmentation ===\n",
    "        results = model(image_rgb)\n",
    "        masks = results[0].masks\n",
    "        boxes = results[0].boxes\n",
    "        names = results[0].names\n",
    "\n",
    "        if masks is None or len(masks.data) == 0:\n",
    "            print(f\"‚ùå No cow mask found in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Get largest cow ===\n",
    "        best_index = None\n",
    "        largest_area = 0\n",
    "        for i, cls_id in enumerate(boxes.cls.cpu().numpy()):\n",
    "            name = names[int(cls_id)]\n",
    "            if name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                if area > largest_area:\n",
    "                    best_index = i\n",
    "                    largest_area = area\n",
    "\n",
    "        if best_index is None:\n",
    "            print(f\"‚ùå No valid cow class in: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # === Resize mask to image ===\n",
    "        mask = masks.data[best_index].cpu().numpy()\n",
    "        resized_mask = cv2.resize(mask, (image_w, image_h), interpolation=cv2.INTER_NEAREST)\n",
    "        mask_3ch = np.stack([resized_mask] * 3, axis=-1)\n",
    "\n",
    "        # === Apply mask to full image ===\n",
    "        masked_image = np.where(mask_3ch > 0.5, image_rgb, 255)\n",
    "\n",
    "        # === Crop, remove bottom 30%, add margin ===\n",
    "        x1, y1, x2, y2 = map(int, boxes.xyxy[best_index].cpu().numpy())\n",
    "        margin = 0.1\n",
    "        x1 = max(0, x1 - int((x2 - x1) * margin))\n",
    "        x2 = min(image_w, x2 + int((x2 - x1) * margin))\n",
    "        y2 = y1 + int((y2 - y1) * 0.7)  # remove bottom 30%\n",
    "\n",
    "        cropped = masked_image[y1:y2, x1:x2]\n",
    "\n",
    "        # === Resize with padding to 224x224 ===\n",
    "        resized = resize_with_padding(cropped, desired_size=224)\n",
    "\n",
    "        # === Save final image ===\n",
    "        output_path = os.path.join(output_folder, fname.replace(\".jpg\", \"_processed.jpg\"))\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        print(f\"‚úÖ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with LR at layers unfrozen 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# === Load Cow Model ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "cow_model = load_model(cow_model_path)\n",
    "\n",
    "# === Print Layer Index, Name, and Output Shape (if available) ===\n",
    "print(\"üìã Cow Model Architecture:\")\n",
    "for i, layer in enumerate(cow_model.layers):\n",
    "    output_shape = getattr(layer, 'output_shape', 'N/A')\n",
    "    print(f\"{i:2d}: {layer.name:40s} | Output shape: {output_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_Transfer_Fold2345'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_Transfer_Fold2345'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6]\n",
    "\n",
    "# === Run for Each Learning Rate ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "\n",
    "    # === Load Pre-trained Cow Model ===\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Freeze All Layers ===\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # === Compile for Bull Training ===\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # === Set Unique Paths ===\n",
    "    model_name = f'bull_model2_fold2345_val1_transfer_lr{lr}.keras'\n",
    "    history_name = f'history2_bull_fold2345_val1_transfer_lr{lr}.pkl'\n",
    "    model_path = os.path.join(save_model_dir, model_name)\n",
    "    history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "    # === Callbacks ===\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(model_path, save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train ===\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "    # === Save History ===\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate ===\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    # === Print Results ===\n",
    "    print(f\"\\nüìä Evaluation for LR {lr}:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_Transfer_FineTune'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_Transfer_FineTune'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Model with New Head + Fine-Tuning ===\n",
    "def rebuild_model_from_cow(cow_model_path, image_shape, learning_rate=1e-4, unfreeze_from_layer=-20):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        layer.trainable = (i >= len(base_model.layers) + unfreeze_from_layer)  # e.g. unfreeze top 20\n",
    "\n",
    "    x = base_model.layers[-5].output  # Remove original classification head\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]\n",
    "\n",
    "# === Run Training for Each LR ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "\n",
    "    model = rebuild_model_from_cow(cow_model_path, X_train.shape[1:], learning_rate=lr, unfreeze_from_layer=-20)\n",
    "\n",
    "    model_name = f'bull_model_fold2345_val1_finetune_lr{lr}.keras'\n",
    "    history_name = f'history_bull_fold2345_val1_finetune_lr{lr}.pkl'\n",
    "    model_path = os.path.join(save_model_dir, model_name)\n",
    "    history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(model_path, save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "\n",
    "    prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "    print(f\"\\nüìä Evaluation for LR {lr}:\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    precision_recall_curve, auc, confusion_matrix\n",
    ")\n",
    "\n",
    "# === Paths ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_Transfer_FineTune'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Learning Rates to evaluate ===\n",
    "learning_rates = ['0.001', '0.0005', '0.0001', '5e-05']\n",
    "\n",
    "# === Load test images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for label_name in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, label_name)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        label = 1 if label_name == 'Good' else 0\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = tf.keras.preprocessing.image.load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each model ===\n",
    "for lr in learning_rates:\n",
    "    model_filename = f\"bull_model_fold2345_val1_finetune_lr{lr}.keras\"\n",
    "    model_path = os.path.join(model_dir, model_filename)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model file not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüìä Evaluating Model: LR={lr}\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    y_probs = model.predict(X_test)\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds, zero_division=1)\n",
    "    precision = precision_score(y_test, y_preds, zero_division=1)\n",
    "    recall = recall_score(y_test, y_preds, zero_division=1)\n",
    "\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "    print(f\"Accuracy:      {acc:.4f}\")\n",
    "    print(f\"F1 Score:      {f1:.4f}\")\n",
    "    print(f\"Precision:     {precision:.4f}\")\n",
    "    print(f\"Recall:        {recall:.4f}\")\n",
    "    print(f\"AUC-PR:        {auc_pr:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"Bad\", \"Good\"], yticklabels=[\"Bad\", \"Good\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"Confusion Matrix (LR={lr})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with unfreezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-3, 5e-4, 2e-4, 1e-4, 5e-5, 2e-5, 1e-5, 5e-6]\n",
    "unfreeze_configs = [10, 20, 40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# === Paths ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Fold1'\n",
    "\n",
    "# === Load Validation Data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = tf.keras.preprocessing.image.load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Sweep Settings ===\n",
    "learning_rates = [1e-3, 5e-4, 2e-4, 1e-4, 5e-5, 2e-5, 1e-5, 5e-6]\n",
    "unfreeze_configs = [10, 20, 40]\n",
    "\n",
    "results = []\n",
    "\n",
    "# === Loop Through Models ===\n",
    "for lr in learning_rates:\n",
    "    for unfrozen in unfreeze_configs:\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfrozen}.keras'\n",
    "        model_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"‚ùå Model not found: {model_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüìä Evaluating model: LR={lr}, Unfrozen={unfrozen}\")\n",
    "\n",
    "        try:\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            y_probs = model.predict(X_val)\n",
    "            y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "            # === Metrics ===\n",
    "            acc = accuracy_score(y_val, y_preds)\n",
    "            f1 = f1_score(y_val, y_preds, zero_division=1)\n",
    "            prec = precision_score(y_val, y_preds, zero_division=1)\n",
    "            rec = recall_score(y_val, y_preds, zero_division=1)\n",
    "            prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_probs)\n",
    "            auc_pr = auc(rec_vals, prec_vals)\n",
    "            cm = confusion_matrix(y_val, y_preds)\n",
    "\n",
    "            # === Confusion Matrix ===\n",
    "            plt.figure(figsize=(4, 3))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                        xticklabels=[\"Bad\", \"Good\"], yticklabels=[\"Bad\", \"Good\"])\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.title(f\"Confusion Matrix | LR={lr}, Unfreeze={unfrozen}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # === Add to Summary ===\n",
    "            results.append({\n",
    "                \"Learning Rate\": lr,\n",
    "                \"Unfrozen Layers\": unfrozen,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1 Score\": f1,\n",
    "                \"Precision\": prec,\n",
    "                \"Recall\": rec,\n",
    "                \"AUC-PR\": auc_pr\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with model LR={lr}, Unfrozen={unfrozen}: {e}\")\n",
    "\n",
    "# === Summary Table ===\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=\"F1 Score\", ascending=False)\n",
    "print(\"\\nüìã Evaluation Summary:\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Path to histories ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "\n",
    "# === Existing configurations ===\n",
    "configs = [\n",
    "    (1e-3, 10), (1e-3, 20), (1e-3, 40),\n",
    "    (5e-4, 10), (5e-4, 20), (5e-4, 40),\n",
    "    (2e-4, 40)\n",
    "]\n",
    "\n",
    "# === Storage ===\n",
    "labels = []\n",
    "val_accs = []\n",
    "val_losses = []\n",
    "\n",
    "for lr, unfrozen in configs:\n",
    "    history_name = f'history_bull_lr{lr}_unf{unfrozen}.pkl'\n",
    "    path = os.path.join(history_dir, history_name)\n",
    "\n",
    "    label = f\"{lr:.0e} / {unfrozen}\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "        val_accs.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        labels.append(label)\n",
    "        print(f\"‚úÖ Loaded: {label} | Acc={best_val_acc:.4f}, Loss={avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Missing: {label}\")\n",
    "        continue\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# Accuracy on left axis\n",
    "ax1.set_xlabel(\"Learning Rate / Unfrozen Layers\")\n",
    "ax1.set_ylabel(\"Best Validation Accuracy\", color=\"blue\")\n",
    "ax1.plot(x, val_accs, 'o-', color='blue', label='Val Accuracy')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "# Loss on right axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Average Validation Loss\", color=\"red\")\n",
    "ax2.plot(x, val_losses, 's--', color='red', label='Val Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Title and layout\n",
    "plt.title(\"Validation Accuracy and Loss per LR/Unfreeze Configuration\")\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Paths ===\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "\n",
    "# === Learning Rate Configs ===\n",
    "learning_rates = [1e-3, 5e-4, 2e-4, 1e-4, 5e-5, 2e-5, 1e-5, 5e-6]\n",
    "unfreeze_n = 40  # You only used 40\n",
    "\n",
    "# === Reload validation data ===\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Loop Through Models and Evaluate ===\n",
    "for lr in learning_rates:\n",
    "    model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Skipping LR {lr}: Model not found.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüìÇ Evaluating Model: LR={lr}, Unfreeze={unfreeze_n}\")\n",
    "\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_probs = model.predict(X_val)\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val, y_preds)\n",
    "    f1 = f1_score(y_val, y_preds, zero_division=1)\n",
    "    precision = precision_score(y_val, y_preds, zero_division=1)\n",
    "    recall = recall_score(y_val, y_preds, zero_division=1)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "    cm = confusion_matrix(y_val, y_preds)\n",
    "\n",
    "    # Print\n",
    "    print(f\"Accuracy:      {acc:.4f}\")\n",
    "    print(f\"F1 Score:      {f1:.4f}\")\n",
    "    print(f\"Precision:     {precision:.4f}\")\n",
    "    print(f\"Recall:        {recall:.4f}\")\n",
    "    print(f\"AUC-PR:        {auc_pr:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Optional: plot confusion matrix\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=[\"Bad\", \"Good\"], yticklabels=[\"Bad\", \"Good\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"LR={lr}, Unfrozen={unfreeze_n}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramter tuning Again run rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-4]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-4, 1e-4, 5e-5, 2e-5, 1e-5, 5e-6]\n",
    "unfreeze_configs = [10, 20, 40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-4]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-4, 5e-5, 2e-5, 1e-5, 5e-6]\n",
    "unfreeze_configs = [10, 20, 40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-5]\n",
    "unfreeze_configs = [20, 40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-5]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-5]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-5]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-5]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-5]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-5]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-6]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-6]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-6]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-5]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-6]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-6]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-6]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-6]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-6]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [1e-6]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-7]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-7]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [5e-7]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-7]\n",
    "unfreeze_configs = [10]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-7]\n",
    "unfreeze_configs = [20]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "save_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "save_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# === Load Bull Images and Labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                try:\n",
    "                    image = load_img(image_path, target_size=(224, 224))\n",
    "                    image = img_to_array(image) / 255.0\n",
    "                    images.append(image)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Skipped {fname} due to error: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# === Load Training Data (Folds 2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold}')\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Data (Fold 1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Function to Rebuild Cow Model with New Head and Fine-Tuning ===\n",
    "def rebuild_model(cow_model_path, image_shape, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze everything first\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Then unfreeze the top N layers\n",
    "    for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Rebuild top classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# === Sweep Configurations ===\n",
    "learning_rates = [2e-7]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# === Run Training ===\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        print(f\"\\nüöÄ LR={lr} | Unfreeze Last {unfreeze_n} Layers\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            image_shape=X_train.shape[1:],\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n\n",
    "        )\n",
    "\n",
    "        model_name = f'bull_model_lr{lr}_unf{unfreeze_n}.keras'\n",
    "        history_name = f'history_bull_lr{lr}_unf{unfreeze_n}.pkl'\n",
    "        model_path = os.path.join(save_model_dir, model_name)\n",
    "        history_path = os.path.join(save_history_dir, history_name)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN()\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è Training Time: {elapsed:.2f} seconds\")\n",
    "\n",
    "        with open(history_path, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # === Evaluation ===\n",
    "        y_pred_probs = model.predict(X_val)\n",
    "        y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "        precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "        recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "        accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_vals, prec_vals)\n",
    "\n",
    "        print(f\"\\nüìä Evaluation | LR {lr} | Unfrozen {unfreeze_n} layers:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze layers and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Set font sizes for plots\n",
    "plt.rcParams.update({\n",
    "    'font.size': 13,\n",
    "    'axes.titlesize': 15,\n",
    "    'axes.labelsize': 13,\n",
    "    'xtick.labelsize': 11,\n",
    "    'ytick.labelsize': 11,\n",
    "    'legend.fontsize': 11\n",
    "})\n",
    "\n",
    "# Folder containing histories\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "\n",
    "# Loop through all matching files\n",
    "for fname in sorted(os.listdir(history_dir)):\n",
    "    if not fname.endswith('.pkl'):\n",
    "        continue\n",
    "\n",
    "    # Extract learning rate and unfrozen layers from filename\n",
    "    match = re.search(r'lr([\\de\\.-]+)_unf(\\d+)', fname)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    lr_str = match.group(1)\n",
    "    unfrozen = int(match.group(2))\n",
    "    lr = float(lr_str.replace('-', 'e-')) if 'e' not in lr_str else float(lr_str)\n",
    "\n",
    "    # Load the history\n",
    "    history_path = os.path.join(history_dir, fname)\n",
    "    with open(history_path, 'rb') as f:\n",
    "        hist = pickle.load(f)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hist['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(hist['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy (LR={lr:.0e}, Unf={unfrozen})')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist['loss'], label='Train Loss')\n",
    "    plt.plot(hist['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Loss (LR={lr:.0e}, Unf={unfrozen})')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Optional: save each plot\n",
    "    # save_path = os.path.join(history_dir, f'plot_lr{lr:.0e}_unf{unfrozen}.png')\n",
    "    # plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import re\n",
    "\n",
    "# === Update this path ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "\n",
    "# === Helper: Smooth Curve ===\n",
    "def smooth_curve(x, y, factor=300):\n",
    "    if len(x) < 4:\n",
    "        return x, y\n",
    "    x_new = np.linspace(min(x), max(x), factor)\n",
    "    spline = make_interp_spline(x, y)\n",
    "    y_smooth = spline(x_new)\n",
    "    return x_new, y_smooth\n",
    "\n",
    "# === Storage for Summary ===\n",
    "summary_data = []\n",
    "\n",
    "# === Plot Setup ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# === Load Histories and Plot ===\n",
    "for fname in sorted(os.listdir(history_dir)):\n",
    "    if not fname.endswith('.pkl'):\n",
    "        continue\n",
    "\n",
    "    match = re.search(r'lr([\\de\\-]+)_unf(\\d+)', fname)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    lr = match.group(1).replace('-', 'e-') if 'e-' not in match.group(1) else match.group(1)\n",
    "    unfreeze = int(match.group(2))\n",
    "\n",
    "    history_path = os.path.join(history_dir, fname)\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    val_acc = history.get('val_accuracy', [])\n",
    "    val_loss = history.get('val_loss', [])\n",
    "    if not val_acc or not val_loss:\n",
    "        continue\n",
    "\n",
    "    best_val_acc = np.max(val_acc)\n",
    "    avg_val_loss = np.mean(val_loss)\n",
    "\n",
    "    summary_data.append({\n",
    "        'Learning Rate': lr,\n",
    "        'Unfrozen Layers': unfreeze,\n",
    "        'Best Val Accuracy': round(best_val_acc, 4),\n",
    "        'Avg Val Loss': round(avg_val_loss, 4)\n",
    "    })\n",
    "\n",
    "    epochs = list(range(1, len(val_acc) + 1))\n",
    "    x_smooth, y_smooth = smooth_curve(epochs, val_acc)\n",
    "    plt.plot(x_smooth, y_smooth, label=f'LR={lr}, Unf={unfreeze}')\n",
    "\n",
    "# === Finalize Plot ===\n",
    "plt.title('Validation Accuracy Curves for All Configs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Summary Table ===\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values(by='Best Val Accuracy', ascending=False)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import re\n",
    "\n",
    "# === Font config ===\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# === Path where all history files are stored ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "\n",
    "# === Containers ===\n",
    "combinations = []\n",
    "val_accuracies = []\n",
    "avg_val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"üìä Validation Results:\")\n",
    "print(f\"{'LR':>8} | {'Unfrozen':>8} | {'Best Val Acc':>13} | {'Avg Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for fname in sorted(os.listdir(history_dir)):\n",
    "    if not fname.endswith('.pkl'):\n",
    "        continue\n",
    "\n",
    "    match = re.search(r'lr([\\de\\.-]+)_unf(\\d+)', fname)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    lr_str = match.group(1)\n",
    "    lr = float(lr_str.replace('-', 'e-')) if 'e' not in lr_str else float(lr_str)\n",
    "    unfrozen = int(match.group(2))\n",
    "\n",
    "    history_path = os.path.join(history_dir, fname)\n",
    "    with open(history_path, 'rb') as f:\n",
    "        hist = pickle.load(f)\n",
    "\n",
    "    best_val_acc = max(hist['val_accuracy'])\n",
    "    avg_val_acc = np.mean(hist['val_accuracy'])\n",
    "    avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "    combinations.append((lr, unfrozen))\n",
    "    val_accuracies.append(best_val_acc)\n",
    "    avg_val_accuracies.append(avg_val_acc)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"{lr:>8.0e} | {unfrozen:>8} | {best_val_acc:>13.4f} | {avg_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "\n",
    "# === Convert to numpy arrays ===\n",
    "log_lrs = np.log10([lr for lr, _ in combinations])\n",
    "unfrozen_layers = np.array([unf for _, unf in combinations])\n",
    "val_accuracies = np.array(val_accuracies)\n",
    "avg_val_accuracies = np.array(avg_val_accuracies)\n",
    "val_losses = np.array(val_losses)\n",
    "\n",
    "# === Sort by log LR then unfreeze ===\n",
    "sorted_idx = np.lexsort((unfrozen_layers, log_lrs))\n",
    "log_lrs = log_lrs[sorted_idx]\n",
    "unfrozen_layers = unfrozen_layers[sorted_idx]\n",
    "val_accuracies = val_accuracies[sorted_idx]\n",
    "avg_val_accuracies = avg_val_accuracies[sorted_idx]\n",
    "val_losses = val_losses[sorted_idx]\n",
    "\n",
    "# === Label x-axis as \"LR | Unf\" ===\n",
    "x_labels = [f\"{10**lr:.0e} | {unf}\" for lr, unf in zip(log_lrs, unfrozen_layers)]\n",
    "x_pos = np.arange(len(x_labels))\n",
    "\n",
    "# === Smooth curves ===\n",
    "x_smooth = np.linspace(0, len(x_pos)-1, 300)\n",
    "acc_smooth = make_interp_spline(x_pos, val_accuracies, k=2)(x_smooth)\n",
    "avg_acc_smooth = make_interp_spline(x_pos, avg_val_accuracies, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x_pos, val_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Accuracy axis\n",
    "ax1.set_xlabel('Learning Rate | Unfrozen Layers')\n",
    "ax1.set_ylabel('Validation Accuracy', color='blue')\n",
    "ax1.plot(x_smooth, acc_smooth, color='blue', label='Best Val Accuracy')\n",
    "ax1.plot(x_smooth, avg_acc_smooth, color='cyan', linestyle='--', label='Avg Val Accuracy')\n",
    "ax1.scatter(x_pos, val_accuracies, color='blue')\n",
    "ax1.scatter(x_pos, avg_val_accuracies, color='cyan', marker='x')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(x_pos, val_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Combined legend\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "plt.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2)\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs LR & Unfreeze Config (Fine-tuning Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import re\n",
    "\n",
    "# === Font config ===\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# === Path where all history files are stored ===\n",
    "history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep'\n",
    "\n",
    "# === Containers ===\n",
    "combinations = []\n",
    "val_accuracies = []\n",
    "avg_val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"üìä Validation Results:\")\n",
    "print(f\"{'LR':>8} | {'Unfrozen':>8} | {'Best Val Acc':>13} | {'Avg Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for fname in sorted(os.listdir(history_dir)):\n",
    "    if not fname.endswith('.pkl'):\n",
    "        continue\n",
    "\n",
    "    match = re.search(r'lr([\\de\\.-]+)_unf(\\d+)', fname)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    lr_str = match.group(1)\n",
    "    lr = float(lr_str.replace('-', 'e-')) if 'e' not in lr_str else float(lr_str)\n",
    "    unfrozen = int(match.group(2))\n",
    "\n",
    "    history_path = os.path.join(history_dir, fname)\n",
    "    with open(history_path, 'rb') as f:\n",
    "        hist = pickle.load(f)\n",
    "\n",
    "    best_val_acc = max(hist['val_accuracy'])\n",
    "    avg_val_acc = np.mean(hist['val_accuracy'])\n",
    "    avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "    combinations.append((lr, unfrozen))\n",
    "    val_accuracies.append(best_val_acc)\n",
    "    avg_val_accuracies.append(avg_val_acc)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"{lr:>8.0e} | {unfrozen:>8} | {best_val_acc:>13.4f} | {avg_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "\n",
    "# === Convert to numpy arrays ===\n",
    "log_lrs = np.log10([lr for lr, _ in combinations])\n",
    "unfrozen_layers = np.array([unf for _, unf in combinations])\n",
    "val_accuracies = np.array(val_accuracies)\n",
    "avg_val_accuracies = np.array(avg_val_accuracies)\n",
    "val_losses = np.array(val_losses)\n",
    "\n",
    "# === Sort by Unfrozen Layers first, then by Learning Rate ===\n",
    "sorted_idx = np.lexsort((log_lrs, unfrozen_layers))\n",
    "\n",
    "log_lrs = log_lrs[sorted_idx]\n",
    "unfrozen_layers = unfrozen_layers[sorted_idx]\n",
    "val_accuracies = val_accuracies[sorted_idx]\n",
    "avg_val_accuracies = avg_val_accuracies[sorted_idx]\n",
    "val_losses = val_losses[sorted_idx]\n",
    "\n",
    "# === Label x-axis as \"LR | Unf\" ===\n",
    "x_labels = [f\"{10**lr:.0e} | {unf}\" for lr, unf in zip(log_lrs, unfrozen_layers)]\n",
    "x_pos = np.arange(len(x_labels))\n",
    "\n",
    "# === Smooth curves ===\n",
    "x_smooth = np.linspace(0, len(x_pos)-1, 300)\n",
    "acc_smooth = make_interp_spline(x_pos, val_accuracies, k=2)(x_smooth)\n",
    "avg_acc_smooth = make_interp_spline(x_pos, avg_val_accuracies, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x_pos, val_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Accuracy axis\n",
    "ax1.set_xlabel('Learning Rate | Unfrozen Layers')\n",
    "ax1.set_ylabel('Validation Accuracy', color='blue')\n",
    "ax1.plot(x_smooth, acc_smooth, color='blue', label='Best Val Accuracy')\n",
    "ax1.plot(x_smooth, avg_acc_smooth, color='cyan', linestyle='--', label='Avg Val Accuracy')\n",
    "ax1.scatter(x_pos, val_accuracies, color='blue')\n",
    "ax1.scatter(x_pos, avg_val_accuracies, color='cyan', marker='x')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(x_labels, rotation=45, ha='right')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(x_pos, val_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Combined legend\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "plt.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=2)\n",
    "\n",
    "plt.title('Validation Accuracy and Loss vs LR & Unfreeze Config (Grouped by Layers)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### others - no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set on layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, precision_recall_curve, auc\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_lr1e-05_unf40.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Load Test Images and Individual IDs ===\n",
    "def load_images_labels_ids(image_dir):\n",
    "    images, labels, ids = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        class_label = 1 if subdir == 'Good' else 0\n",
    "        class_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(class_path):\n",
    "            continue\n",
    "        for fname in os.listdir(class_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img_path = os.path.join(class_path, fname)\n",
    "                    img = load_img(img_path, target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(class_label)\n",
    "                    cow_id = fname.split('_')[0]  # \"ADC123\" from \"ADC123_1.jpg\"\n",
    "                    ids.append(cow_id)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels), ids\n",
    "\n",
    "X_test, y_test, ids = load_images_labels_ids(test_dir)\n",
    "\n",
    "# === Load Model ===\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"‚ùå Model not found: {model_path}\")\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# === Predict on Test Images ===\n",
    "y_probs = model.predict(X_test).flatten()\n",
    "y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Group Predictions by Cow ID and Vote ===\n",
    "individual_votes = defaultdict(list)\n",
    "true_labels_by_id = {}\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    cow_id = ids[i]\n",
    "    individual_votes[cow_id].append(y_preds[i])\n",
    "    if cow_id not in true_labels_by_id:\n",
    "        true_labels_by_id[cow_id] = y_test[i]\n",
    "\n",
    "voted_preds = []\n",
    "voted_truths = []\n",
    "\n",
    "for cow_id, preds in individual_votes.items():\n",
    "    majority_vote = Counter(preds).most_common(1)[0][0]\n",
    "    voted_preds.append(majority_vote)\n",
    "    voted_truths.append(true_labels_by_id[cow_id])\n",
    "\n",
    "voted_preds = np.array(voted_preds)\n",
    "voted_truths = np.array(voted_truths)\n",
    "\n",
    "# === Compute Evaluation Metrics ===\n",
    "acc = accuracy_score(voted_truths, voted_preds)\n",
    "f1 = f1_score(voted_truths, voted_preds, zero_division=1)\n",
    "precision = precision_score(voted_truths, voted_preds, zero_division=1)\n",
    "recall = recall_score(voted_truths, voted_preds, zero_division=1)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(voted_truths, voted_preds)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "cm = confusion_matrix(voted_truths, voted_preds)\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"üìä Evaluation on Test Set (Majority Vote per Individual Cow)\")\n",
    "print(f\"Accuracy:      {acc:.4f}\")\n",
    "print(f\"F1 Score:      {f1:.4f}\")\n",
    "print(f\"Precision:     {precision:.4f}\")\n",
    "print(f\"Recall:        {recall:.4f}\")\n",
    "print(f\"AUC-PR:        {auc_pr:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# === Plot Confusion Matrix ===\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"Bad\", \"Good\"], yticklabels=[\"Bad\", \"Good\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Test Set | Majority Vote per Cow\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "import os\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_lr1e-06_unf40.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è {fname} skipped due to error: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load model and test data ===\n",
    "model = load_model(model_path)\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Predict ===\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüßÆ Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# === AUC-PR ===\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "print(f\"\\nüîç AUC-PR: {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    ModelCheckpoint,\n",
    "    TerminateOnNaN,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1. TensorFlow / GPU setup\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  GPU memory-growth setting error: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2. Paths\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cow_model_path = (\n",
    "    \"/Users/suzetteschulenburg/Desktop/MainUse/\"\n",
    "    \"MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras\"\n",
    ")\n",
    "base_fold_dir = \"/Users/suzetteschulenburg/Desktop/BullsProcessed\"\n",
    "save_model_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep\"\n",
    "save_history_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep\"\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3. Utility ‚Äì load images + labels\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def load_images_and_labels(image_dir):\n",
    "    \"\"\"Return images (N, 224, 224, 3) and binary labels (N,) for a fold directory.\"\"\"\n",
    "    images, labels = [], []\n",
    "    for subdir in (\"Good\", \"Bad\"):\n",
    "        class_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if not fname.lower().endswith(\".jpg\"):\n",
    "                continue\n",
    "            try:\n",
    "                img = load_img(os.path.join(class_dir, fname), target_size=(224, 224))\n",
    "                img = img_to_array(img) / 255.0\n",
    "                images.append(img)\n",
    "                labels.append(1 if subdir == \"Good\" else 0)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Skipped {fname}: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 4. Define which fold acts as validation\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "VAL_FOLD = 2\n",
    "ALL_FOLDS = [1, 2, 3, 4, 5]\n",
    "TRAIN_FOLDS = [fold for fold in ALL_FOLDS if fold != VAL_FOLD]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 5. Load train / validation data\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"üìÇ Loading training folds {TRAIN_FOLDS} ‚Ä¶\")\n",
    "X_train, y_train = [], []\n",
    "for fold in TRAIN_FOLDS:\n",
    "    fold_dir = os.path.join(base_fold_dir, f\"Fold{fold}\")\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"üìÇ Loading validation fold {VAL_FOLD} ‚Ä¶\")\n",
    "val_dir = os.path.join(base_fold_dir, f\"Fold{VAL_FOLD}\")\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "print(f\"‚úÖ Data loaded | train {X_train.shape[0]} imgs | val {X_val.shape[0]} imgs\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 6. Model-rebuild helper\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def rebuild_model(cow_model_path, learning_rate, unfreeze_last_n):\n",
    "    \"\"\"\n",
    "    Load the pretrained cow model, unfreeze last N layers, attach a new head,\n",
    "    and compile.\n",
    "    \"\"\"\n",
    "    base_model = load_model(cow_model_path)\n",
    "\n",
    "    # Freeze all layers, then selectively unfreeze\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    if unfreeze_last_n > 0:\n",
    "        for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "    # Replace the classification head\n",
    "    x = base_model.layers[-5].output  # adapt if architecture changes\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 7. Hyper-parameter sweep\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "learning_rates = [1e-6]   # extend as needed\n",
    "unfreeze_configs = [40]   # layers to unfreeze\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 8. Training loop\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        tag = f\"lr{lr}_unf{unfreeze_n}\"\n",
    "        print(f\"\\nüöÄ Training model ({tag}) ‚Äì unfreeze_last={unfreeze_n}\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n,\n",
    "        )\n",
    "\n",
    "        model_path = os.path.join(save_model_dir, f\"bull_model_{tag}.keras\")\n",
    "        history_path = os.path.join(save_history_dir, f\"history_{tag}.pkl\")\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN(),\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2,\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è  Training time: {elapsed/60:.1f} min\")\n",
    "\n",
    "        # Save training history\n",
    "        with open(history_path, \"wb\") as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # ‚îÄ‚îÄ Validation metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        y_pred_probs = model.predict(X_val, verbose=0).ravel()\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=1)\n",
    "        rec = recall_score(y_val, y_pred, zero_division=1)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "        print(\"üìä Validation metrics:\")\n",
    "        print(f\"  Accuracy : {acc:.4f}\")\n",
    "        print(f\"  F1 score : {f1:.4f}\")\n",
    "        print(f\"  Precision: {prec:.4f}\")\n",
    "        print(f\"  Recall   : {rec:.4f}\")\n",
    "        print(f\"  AUC-PR   : {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "import os\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_lr1e-06_unf40.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è {fname} skipped due to error: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load model and test data ===\n",
    "model = load_model(model_path)\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Predict ===\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Evaluation ===\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nüßÆ Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# === AUC-PR ===\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "print(f\"\\nüîç AUC-PR: {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ReduceLROnPlateau,\n",
    "    ModelCheckpoint,\n",
    "    TerminateOnNaN,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    ")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1. TensorFlow / GPU setup\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è  GPU memory-growth setting error: {e}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 2. Paths\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cow_model_path = (\n",
    "    \"/Users/suzetteschulenburg/Desktop/MainUse/\"\n",
    "    \"MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras\"\n",
    ")\n",
    "base_fold_dir = \"/Users/suzetteschulenburg/Desktop/BullsProcessed\"\n",
    "save_model_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep\"\n",
    "save_history_dir = \"/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep\"\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_history_dir, exist_ok=True)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3. Utility ‚Äì load images + labels\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in (\"Good\", \"Bad\"):\n",
    "        class_dir = os.path.join(image_dir, subdir)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if not fname.lower().endswith(\".jpg\"):\n",
    "                continue\n",
    "            try:\n",
    "                img = load_img(os.path.join(class_dir, fname), target_size=(224, 224))\n",
    "                img = img_to_array(img) / 255.0\n",
    "                images.append(img)\n",
    "                labels.append(1 if subdir == \"Good\" else 0)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Skipped {fname}: {e}\")\n",
    "    if not images:\n",
    "        raise ValueError(f\"‚ùå No valid images found in {image_dir}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 4. Define which fold acts as validation\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "VAL_FOLD = 3\n",
    "ALL_FOLDS = [1, 2, 3, 4, 5]\n",
    "TRAIN_FOLDS = [fold for fold in ALL_FOLDS if fold != VAL_FOLD]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 5. Load train / validation data\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(f\"üìÇ Loading training folds {TRAIN_FOLDS} ‚Ä¶\")\n",
    "X_train, y_train = [], []\n",
    "for fold in TRAIN_FOLDS:\n",
    "    fold_dir = os.path.join(base_fold_dir, f\"Fold{fold}\")\n",
    "    imgs, lbls = load_images_and_labels(fold_dir)\n",
    "    X_train.append(imgs)\n",
    "    y_train.append(lbls)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "print(f\"üìÇ Loading validation fold {VAL_FOLD} ‚Ä¶\")\n",
    "val_dir = os.path.join(base_fold_dir, f\"Fold{VAL_FOLD}\")\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "print(f\"‚úÖ Data loaded | train {X_train.shape[0]} imgs | val {X_val.shape[0]} imgs\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 6. Model-rebuild helper\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def rebuild_model(cow_model_path, learning_rate, unfreeze_last_n):\n",
    "    base_model = load_model(cow_model_path)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    if unfreeze_last_n > 0:\n",
    "        for layer in base_model.layers[-unfreeze_last_n:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "    # Replace classification head\n",
    "    x = base_model.layers[-5].output\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 7. Hyper-parameter sweep\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "learning_rates = [1e-6]\n",
    "unfreeze_configs = [40]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 8. Training loop\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for lr in learning_rates:\n",
    "    for unfreeze_n in unfreeze_configs:\n",
    "        tag = f\"val3_lr{lr}_unf{unfreeze_n}\"\n",
    "        print(f\"\\nüöÄ Training model ({tag}) ‚Äì unfreeze_last={unfreeze_n}\")\n",
    "\n",
    "        model = rebuild_model(\n",
    "            cow_model_path=cow_model_path,\n",
    "            learning_rate=lr,\n",
    "            unfreeze_last_n=unfreeze_n,\n",
    "        )\n",
    "\n",
    "        model_path = os.path.join(save_model_dir, f\"bull_model_{tag}.keras\")\n",
    "        history_path = os.path.join(save_history_dir, f\"history_{tag}.pkl\")\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=25, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=15, min_lr=1e-7),\n",
    "            ModelCheckpoint(model_path, save_best_only=True),\n",
    "            TerminateOnNaN(),\n",
    "        ]\n",
    "\n",
    "        start = time.time()\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=1000,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2,\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚è±Ô∏è  Training time: {elapsed / 60:.1f} min\")\n",
    "\n",
    "        # Save training history\n",
    "        with open(history_path, \"wb\") as f:\n",
    "            pickle.dump(history.history, f)\n",
    "\n",
    "        # ‚îÄ‚îÄ Validation metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        y_pred_probs = model.predict(X_val, verbose=0).ravel()\n",
    "        y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "        prec = precision_score(y_val, y_pred, zero_division=1)\n",
    "        rec = recall_score(y_val, y_pred, zero_division=1)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "        auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "        print(\"üìä Validation metrics:\")\n",
    "        print(f\"  Accuracy : {acc:.4f}\")\n",
    "        print(f\"  F1 score : {f1:.4f}\")\n",
    "        print(f\"  Precision: {prec:.4f}\")\n",
    "        print(f\"  Recall   : {rec:.4f}\")\n",
    "        print(f\"  AUC-PR   : {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test - bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, precision_recall_curve, auc\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_val3_lr1e-06_unf40.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Load Test Images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load Model ===\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"‚ùå Model not found: {model_path}\")\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# === Predict and Evaluate ===\n",
    "y_probs = model.predict(X_test)\n",
    "y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Metrics ===\n",
    "acc = accuracy_score(y_test, y_preds)\n",
    "f1 = f1_score(y_test, y_preds, zero_division=1)\n",
    "precision = precision_score(y_test, y_preds, zero_division=1)\n",
    "recall = recall_score(y_test, y_preds, zero_division=1)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"üìä Evaluation on Test Set (LR=0.005, Unfrozen=40)\")\n",
    "print(f\"Accuracy:      {acc:.4f}\")\n",
    "print(f\"F1 Score:      {f1:.4f}\")\n",
    "print(f\"Precision:     {precision:.4f}\")\n",
    "print(f\"Recall:        {recall:.4f}\")\n",
    "print(f\"AUC-PR:        {auc_pr:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# === Plot Confusion Matrix ===\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"Bad\", \"Good\"], yticklabels=[\"Bad\", \"Good\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Test Set | LR=0.005, Unfrozen=40\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, precision_recall_curve, auc\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_lr0.001_unf10.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "\n",
    "# === Load Test Images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load Model ===\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"‚ùå Model not found: {model_path}\")\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# === Predict and Evaluate ===\n",
    "y_probs = model.predict(X_test)\n",
    "y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Metrics ===\n",
    "acc = accuracy_score(y_test, y_preds)\n",
    "f1 = f1_score(y_test, y_preds, zero_division=1)\n",
    "precision = precision_score(y_test, y_preds, zero_division=1)\n",
    "recall = recall_score(y_test, y_preds, zero_division=1)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"üìä Evaluation on Test Set (LR=0.005, Unfrozen=40)\")\n",
    "print(f\"Accuracy:      {acc:.4f}\")\n",
    "print(f\"F1 Score:      {f1:.4f}\")\n",
    "print(f\"Precision:     {precision:.4f}\")\n",
    "print(f\"Recall:        {recall:.4f}\")\n",
    "print(f\"AUC-PR:        {auc_pr:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# === Plot Confusion Matrix ===\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"Bad\", \"Good\"], yticklabels=[\"Bad\", \"Good\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Test Set | LR=0.005, Unfrozen=40\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, precision_recall_curve, auc\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep/bull_model_lr0.001_unf10.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy'\n",
    "\n",
    "# === Load Test Images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load Model ===\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"‚ùå Model not found: {model_path}\")\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# === Predict and Evaluate ===\n",
    "y_probs = model.predict(X_test)\n",
    "y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Metrics ===\n",
    "acc = accuracy_score(y_test, y_preds)\n",
    "f1 = f1_score(y_test, y_preds, zero_division=1)\n",
    "precision = precision_score(y_test, y_preds, zero_division=1)\n",
    "recall = recall_score(y_test, y_preds, zero_division=1)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# === Print Metrics ===\n",
    "print(f\"üìä Evaluation on Test Set (LR=0.005, Unfrozen=40)\")\n",
    "print(f\"Accuracy:      {acc:.4f}\")\n",
    "print(f\"F1 Score:      {f1:.4f}\")\n",
    "print(f\"Precision:     {precision:.4f}\")\n",
    "print(f\"Recall:        {recall:.4f}\")\n",
    "print(f\"AUC-PR:        {auc_pr:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# === Plot Confusion Matrix ===\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"Bad\", \"Good\"], yticklabels=[\"Bad\", \"Good\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Test Set | LR=0.005, Unfrozen=40\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, precision_recall_curve, auc\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Trained_Bull_Models_FineTuneSweep'\n",
    "configs = [\n",
    "    (1e-3, 10), (1e-3, 20), (1e-3, 40),\n",
    "    (5e-4, 10), (5e-4, 20), (5e-4, 40),\n",
    "    (2e-4, 40)\n",
    "]\n",
    "\n",
    "# === Load Test Images ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    img = load_img(os.path.join(full_path, fname), target_size=(224, 224))\n",
    "                    img = img_to_array(img) / 255.0\n",
    "                    images.append(img)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipped {fname}: {e}\")\n",
    "    return np.stack(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate all models ===\n",
    "results = []\n",
    "for lr, unfrozen in configs:\n",
    "    model_name = f'bull_model_lr{lr}_unf{unfrozen}.keras'\n",
    "    model_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "    label = f\"{lr:.0e}/{unfrozen}\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Missing model: {label}\")\n",
    "        results.append((label, 'Missing', '', '', '', ''))\n",
    "        continue\n",
    "\n",
    "    print(f\"‚úÖ Evaluating: {label}\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    y_probs = model.predict(X_test)\n",
    "    y_preds = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds, zero_division=1)\n",
    "    precision = precision_score(y_test, y_preds, zero_division=1)\n",
    "    recall = recall_score(y_test, y_preds, zero_division=1)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    results.append((label, acc, f1, precision, recall, auc_pr))\n",
    "\n",
    "# === Display Table ===\n",
    "df = pd.DataFrame(results, columns=[\"Config\", \"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"AUC-PR\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Path to history file ===\n",
    "history_path = '/Users/suzetteschulenburg/Desktop/Bulls/History_Bull_Models_FineTuneSweep/history_bull_lr0.0005_unf40.pkl'\n",
    "\n",
    "# === Load history ===\n",
    "if not os.path.exists(history_path):\n",
    "    raise FileNotFoundError(f\"‚ùå History file not found: {history_path}\")\n",
    "\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# --- Accuracy ---\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Train vs Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# --- Loss ---\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle('Training History (LR=0.005, Unfrozen=40)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    1e-5,\n",
    "    2e-5,\n",
    "    5e-5,\n",
    "    1e-4,\n",
    "    2e-4,\n",
    "    5e-4,\n",
    "    1e-3,\n",
    "    2e-3,\n",
    "    3e-3,\n",
    "    5e-3,\n",
    "    7e-3,\n",
    "    1e-2,\n",
    "    2e-2,\n",
    "    5e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    5e-4,\n",
    "    1e-3,\n",
    "    2e-3,\n",
    "    3e-3,\n",
    "    5e-3,\n",
    "    7e-3,\n",
    "    1e-2,\n",
    "    2e-2,\n",
    "    5e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# === Base history directory ===\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Histories'\n",
    "\n",
    "# === Learning Rates to include (‚â§ 5e-3) ===\n",
    "learning_rates = [lr for lr in [\n",
    "     1e-5,\n",
    "    2e-5,\n",
    "    5e-5,\n",
    "    1e-4, 5e-4, 1e-3, 2e-3, 3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "] if lr <= 5e-3]\n",
    "\n",
    "# === Display metrics ===\n",
    "print(\"üìä Validation Results (LR ‚â§ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More layers compare lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    5e-4,\n",
    "    1e-3,\n",
    "    2e-3,\n",
    "    3e-3,\n",
    "    5e-3,\n",
    "    7e-3,\n",
    "    1e-2,\n",
    "    2e-2,\n",
    "    5e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    2e-3,\n",
    "    3e-3,\n",
    "    5e-3,\n",
    "    7e-3,\n",
    "    1e-2,\n",
    "    2e-2,\n",
    "    5e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    7e-3,\n",
    "    1e-2,\n",
    "    2e-2,\n",
    "    5e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates to include (‚â§ 5e-3) ===\n",
    "learning_rates = [\n",
    "    5e-4,\n",
    "    1e-3,\n",
    "    2e-3,\n",
    "    3e-3,\n",
    "    5e-3,\n",
    "    7e-3,\n",
    "    1e-2\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Histories'\n",
    "\n",
    "# === Collect metrics ===\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "print(\"üìä Validation Results (LR ‚â§ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and remove duplicate learning rates ===\n",
    "filtered_lrs = np.array(filtered_lrs)\n",
    "filtered_accs = np.array(filtered_accs)\n",
    "filtered_losses = np.array(filtered_losses)\n",
    "\n",
    "# Use log scale for sorting and de-duplication\n",
    "log_lrs = np.log10(filtered_lrs)\n",
    "log_lrs, unique_indices = np.unique(log_lrs, return_index=True)\n",
    "\n",
    "# Apply unique index filtering\n",
    "filtered_lrs = filtered_lrs[unique_indices]\n",
    "filtered_accs = filtered_accs[unique_indices]\n",
    "filtered_losses = filtered_losses[unique_indices]\n",
    "\n",
    "# === Smooth interpolation ===\n",
    "x_smooth = np.linspace(log_lrs.min(), log_lrs.max(), 300)\n",
    "acc_smooth = make_interp_spline(log_lrs, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(log_lrs, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy axis\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (Transfer to Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 layers 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Models/lr_1e03/bull_transfer_model.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "\n",
    "# === Load Test Data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load Trained Model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Predict & Evaluate ===\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"üìä Test Set Results (LR = 1e-3)\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 30 layers more LR and more patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    5e-4,\n",
    "    7e-4,\n",
    "    1e-3,\n",
    "    1.5e-3,\n",
    "    2e-3,\n",
    "    2.5e-3,\n",
    "    3e-3,\n",
    "    4e-3,\n",
    "    5e-3,\n",
    "    6e-3,\n",
    "    7e-3,\n",
    "    8e-3,\n",
    "    9e-3,\n",
    "    1e-2,\n",
    "    1.5e-2,\n",
    "    2e-2,\n",
    "    3e-2,\n",
    "    4e-2,\n",
    "    5e-2,\n",
    "    7e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    7e-4,\n",
    "    1e-3,\n",
    "    1.5e-3,\n",
    "    2e-3,\n",
    "    2.5e-3,\n",
    "    3e-3,\n",
    "    4e-3,\n",
    "    5e-3,\n",
    "    6e-3,\n",
    "    7e-3,\n",
    "    8e-3,\n",
    "    9e-3,\n",
    "    1e-2,\n",
    "    1.5e-2,\n",
    "    2e-2,\n",
    "    3e-2,\n",
    "    4e-2,\n",
    "    5e-2,\n",
    "    7e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    1.5e-3,\n",
    "    2e-3,\n",
    "    2.5e-3,\n",
    "    3e-3,\n",
    "    4e-3,\n",
    "    5e-3,\n",
    "    6e-3,\n",
    "    7e-3,\n",
    "    8e-3,\n",
    "    9e-3,\n",
    "    1e-2,\n",
    "    1.5e-2,\n",
    "    2e-2,\n",
    "    3e-2,\n",
    "    4e-2,\n",
    "    5e-2,\n",
    "    7e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    2e-3,\n",
    "    2.5e-3,\n",
    "    3e-3,\n",
    "    4e-3,\n",
    "    5e-3,\n",
    "    6e-3,\n",
    "    7e-3,\n",
    "    8e-3,\n",
    "    9e-3,\n",
    "    1e-2,\n",
    "    1.5e-2,\n",
    "    2e-2,\n",
    "    3e-2,\n",
    "    4e-2,\n",
    "    5e-2,\n",
    "    7e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    3e-3,\n",
    "    4e-3,\n",
    "    5e-3,\n",
    "    6e-3,\n",
    "    7e-3,\n",
    "    8e-3,\n",
    "    9e-3,\n",
    "    1e-2,\n",
    "    1.5e-2,\n",
    "    2e-2,\n",
    "    3e-2,\n",
    "    4e-2,\n",
    "    5e-2,\n",
    "    7e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    6e-3,\n",
    "    7e-3,\n",
    "    8e-3,\n",
    "    9e-3,\n",
    "    1e-2,\n",
    "    1.5e-2,\n",
    "    2e-2,\n",
    "    3e-2,\n",
    "    4e-2,\n",
    "    5e-2,\n",
    "    7e-2,\n",
    "    1e-1\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    8e-3\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    9e-3\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    1e-2,\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    2e-2\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates to include (‚â§ 5e-3) ===\n",
    "learning_rates = [\n",
    "     5e-4,\n",
    "    7e-4,\n",
    "    1e-3,\n",
    "    1.5e-3,\n",
    "    2e-3,\n",
    "    2.5e-3,\n",
    "    3e-3,\n",
    "    4e-3,\n",
    "    5e-3,\n",
    "    6e-3,\n",
    "    7e-3,\n",
    "    8e-3,\n",
    "    9e-3,\n",
    "    1e-2,\n",
    "    1.5e-2,\n",
    "    2e-2,\n",
    "    3e-2,\n",
    "    4e-2,\n",
    "    5e-2,\n",
    "    7e-2,\n",
    "    1e-1\n",
    "\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Histories'\n",
    "\n",
    "# === Collect metrics ===\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "print(\"üìä Validation Results (LR ‚â§ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and remove duplicate learning rates ===\n",
    "filtered_lrs = np.array(filtered_lrs)\n",
    "filtered_accs = np.array(filtered_accs)\n",
    "filtered_losses = np.array(filtered_losses)\n",
    "\n",
    "# Use log scale for sorting and de-duplication\n",
    "log_lrs = np.log10(filtered_lrs)\n",
    "log_lrs, unique_indices = np.unique(log_lrs, return_index=True)\n",
    "\n",
    "# Apply unique index filtering\n",
    "filtered_lrs = filtered_lrs[unique_indices]\n",
    "filtered_accs = filtered_accs[unique_indices]\n",
    "filtered_losses = filtered_losses[unique_indices]\n",
    "\n",
    "# === Smooth interpolation ===\n",
    "x_smooth = np.linspace(log_lrs.min(), log_lrs.max(), 300)\n",
    "acc_smooth = make_interp_spline(log_lrs, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(log_lrs, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy axis\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (Transfer to Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments30/Models/lr_5e04/bull_transfer_model.keras'\n",
    "\n",
    "\n",
    "# === Load test data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"üìä Test Evaluation for LR = 1e-5\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Models/lr_2e05/bull_transfer_model.keras'\n",
    "\n",
    "\n",
    "# === Load test data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"üìä Test Evaluation for LR = 1e-5\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Models/lr_2e05/bull_transfer_model.keras'\n",
    "\n",
    "# === Load test images ===\n",
    "def load_images_labels_and_filenames(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "X_test, y_test, filenames = load_images_labels_and_filenames(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Extract metadata and group ===\n",
    "data = []\n",
    "for fname, true_label, prob, pred in zip(filenames, y_test, y_pred_probs, y_pred):\n",
    "    match = re.match(r'([A-Z]+\\d+).*Rating(\\d+)', fname)\n",
    "    if match:\n",
    "        indiv_id, rating = match.groups()\n",
    "        data.append((indiv_id, fname, int(rating), true_label, prob, pred))\n",
    "\n",
    "# === Create and sort DataFrame by Individual ID ===\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    'IndividualID', 'Filename', 'TrueRating', 'TrueLabel', 'PredictedProbability', 'PredictedLabel'\n",
    "])\n",
    "df = df.sort_values(by=['IndividualID', 'Filename'])\n",
    "\n",
    "# === Show the grouped table ===\n",
    "print(df.to_string(index=False))\n",
    "# Optional: save to CSV\n",
    "# df.to_csv(\"grouped_by_individual_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Models/lr_2e05/bull_transfer_model.keras'\n",
    "\n",
    "# === Load test images ===\n",
    "def load_images_labels_and_filenames(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "X_test, y_test, filenames = load_images_labels_and_filenames(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Extract metadata ===\n",
    "data = []\n",
    "for fname, true_label, prob, pred in zip(filenames, y_test, y_pred_probs, y_pred):\n",
    "    match = re.match(r'([A-Z]+\\d+).*Rating(\\d+)', fname)\n",
    "    if match:\n",
    "        indiv_id, rating = match.groups()\n",
    "        data.append((indiv_id, fname, int(rating), true_label, prob, pred))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    'IndividualID', 'Filename', 'TrueRating', 'TrueLabel', 'PredictedProbability', 'PredictedLabel'\n",
    "])\n",
    "\n",
    "# === Group by individual and compute majority vote ===\n",
    "majority_df = (\n",
    "    df.groupby('IndividualID')\n",
    "    .agg({\n",
    "        'TrueLabel': lambda x: Counter(x).most_common(1)[0][0],\n",
    "        'PredictedLabel': lambda x: Counter(x).most_common(1)[0][0],\n",
    "        'TrueRating': 'first'  # optional\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# === Compute metrics ===\n",
    "y_true = majority_df['TrueLabel']\n",
    "y_pred = majority_df['PredictedLabel']\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# === Display results ===\n",
    "print(\"\\nüìä Per-Individual Evaluation (Majority Vote)\")\n",
    "print(f\"Accuracy  : {acc:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1 Score  : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# === Optional: Save the per-individual majority vote results ===\n",
    "# majority_df.to_csv(\"per_individual_majority_vote_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One image per individual best conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Models/lr_2e05/bull_transfer_model.keras'\n",
    "\n",
    "# === Load test images ===\n",
    "def load_images_labels_and_filenames(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "X_test, y_test, filenames = load_images_labels_and_filenames(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Extract metadata ===\n",
    "data = []\n",
    "for fname, true_label, prob, pred in zip(filenames, y_test, y_pred_probs, y_pred):\n",
    "    match = re.match(r'([A-Z]+\\d+).*Rating(\\d+)', fname)\n",
    "    if match:\n",
    "        indiv_id, rating = match.groups()\n",
    "        confidence = abs(prob - 0.5)  # how far it is from uncertainty\n",
    "        data.append((indiv_id, fname, int(rating), true_label, prob, pred, confidence))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    'IndividualID', 'Filename', 'TrueRating', 'TrueLabel', 'PredictedProbability', 'PredictedLabel', 'Confidence'\n",
    "])\n",
    "\n",
    "# === Select one image per individual: the most confident\n",
    "top_conf_df = (\n",
    "    df.sort_values(by='Confidence', ascending=False)\n",
    "    .groupby('IndividualID')\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# === Compute metrics ===\n",
    "y_true = top_conf_df['TrueLabel']\n",
    "y_pred = top_conf_df['PredictedLabel']\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# === Display results ===\n",
    "print(\"\\nüìä Per-Individual Evaluation (Most Confident Image)\")\n",
    "print(f\"Accuracy  : {acc:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1 Score  : {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# === Optional: Save this table\n",
    "# top_conf_df.to_csv(\"most_confident_image_per_individual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Models/lr_2e05/bull_transfer_model.keras'\n",
    "\n",
    "\n",
    "# === Load test data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"üìä Test Evaluation for LR = 1e-5\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates to include (‚â§ 5e-3) ===\n",
    "learning_rates = [\n",
    "    1e-5, 2e-5, 5e-5, 1e-4, 5e-4,\n",
    "    1e-3, 2e-3, 3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Histories'\n",
    "\n",
    "# === Collect metrics ===\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "print(\"üìä Validation Results (LR ‚â§ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for plotting ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth interpolation ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy axis\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (Transfer to Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "  1e-6,\n",
    "    2e-6,\n",
    "    3e-6,\n",
    "    5e-6,\n",
    "    7e-6,\n",
    "    1e-6,\n",
    "    2e-7,\n",
    "    3e-7,\n",
    "    5e-7,\n",
    "    7e-7,\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    2e-7,\n",
    "    3e-7,\n",
    "    5e-7,\n",
    "    7e-7,\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    3e-7,\n",
    "    5e-7,\n",
    "    7e-7,\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments'\n",
    "\n",
    "# === Learning Rates to Try ===\n",
    "learning_rates = [\n",
    "    7e-7,\n",
    "]\n",
    "\n",
    "\n",
    "# === Image Loading Function ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Data ===\n",
    "X_train, y_train = [], []\n",
    "for fold in [2, 3, 4, 5]:\n",
    "    fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "    X, y = load_images_and_labels(fold_dir)\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "val_path = os.path.join(bull_base_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_path)\n",
    "\n",
    "# === Loop Over Learning Rates ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with learning rate: {lr}\")\n",
    "\n",
    "    # === Load pretrained cow model\n",
    "    model = tf.keras.models.load_model(cow_model_path)\n",
    "\n",
    "    # === Unfreeze last 10 layers\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # === Compile\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # === Prepare output dirs\n",
    "    lr_tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    model_dir = os.path.join(output_base, 'Models', lr_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', lr_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    # === Callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # === Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # === Save History\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # === Evaluate\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates to include (‚â§ 5e-3) ===\n",
    "learning_rates = [\n",
    "    1e-5, 2e-5, 5e-5, 1e-4, 5e-4,\n",
    "    1e-3, 2e-3, 3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1,  1e-6,\n",
    "    2e-6,\n",
    "    3e-6,\n",
    "    5e-6,\n",
    "    7e-6,\n",
    "    1e-6,\n",
    "    2e-7,\n",
    "    3e-7,\n",
    "    5e-7,\n",
    "    7e-7,\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Histories'\n",
    "\n",
    "# === Collect metrics ===\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "print(\"üìä Validation Results (LR ‚â§ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort for plotting ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "# === Smooth interpolation ===\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy axis\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (Transfer to Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates to include (‚â§ 5e-3) ===\n",
    "learning_rates = [\n",
    "    1e-5, 2e-5, 5e-5, 1e-4, 5e-4,\n",
    "    1e-3, 2e-3, 3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1,  1e-6,\n",
    "    2e-6,\n",
    "    3e-6,\n",
    "    5e-6,\n",
    "    7e-6,\n",
    "    1e-6,\n",
    "    2e-7,\n",
    "    3e-7,\n",
    "    5e-7,\n",
    "    7e-7,\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Histories'\n",
    "\n",
    "# === Collect metrics ===\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "print(\"üìä Validation Results (LR ‚â§ 5e-3):\")\n",
    "print(f\"{'LR':>8} | {'Best Val Acc':>13} | {'Avg Val Loss':>13}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    tag = f\"lr_{lr:.0e}\".replace(\"-\", \"\")\n",
    "    history_path = os.path.join(history_base_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        with open(history_path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "\n",
    "        best_val_acc = max(hist['val_accuracy'])\n",
    "        avg_val_loss = np.mean(hist['val_loss'])\n",
    "\n",
    "        val_accuracies.append(best_val_acc)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"{lr:>8.0e} | {best_val_acc:>13.4f} | {avg_val_loss:>13.4f}\")\n",
    "    else:\n",
    "        print(f\"{lr:>8.0e} | {'MISSING':>13} | {'MISSING':>13}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Filter out missing entries ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and remove duplicate learning rates ===\n",
    "filtered_lrs = np.array(filtered_lrs)\n",
    "filtered_accs = np.array(filtered_accs)\n",
    "filtered_losses = np.array(filtered_losses)\n",
    "\n",
    "# Use log scale for sorting and de-duplication\n",
    "log_lrs = np.log10(filtered_lrs)\n",
    "log_lrs, unique_indices = np.unique(log_lrs, return_index=True)\n",
    "\n",
    "# Apply unique index filtering\n",
    "filtered_lrs = filtered_lrs[unique_indices]\n",
    "filtered_accs = filtered_accs[unique_indices]\n",
    "filtered_losses = filtered_losses[unique_indices]\n",
    "\n",
    "# === Smooth interpolation ===\n",
    "x_smooth = np.linspace(log_lrs.min(), log_lrs.max(), 300)\n",
    "acc_smooth = make_interp_spline(log_lrs, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(log_lrs, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy axis\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue', label='Val Accuracy')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red', label='Avg Val Loss')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (Transfer to Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments/Models/lr_1e05/bull_transfer_model.keras'\n",
    "\n",
    "\n",
    "# === Load test data ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load model and predict ===\n",
    "model = load_model(model_path)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"üìä Test Evaluation for LR = 1e-5\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "# === Paths ===\n",
    "cow_model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "bull_base_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "output_base = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_2e5'\n",
    "\n",
    "# === Learning rate ===\n",
    "lr = 2e-5\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === 5-Fold Cross Validation ===\n",
    "for val_fold in range(1, 6):\n",
    "    print(f\"\\nüöÄ Fold {val_fold}: Training on all except Fold{val_fold}, validating on Fold{val_fold}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    X_train, y_train = [], []\n",
    "    for fold in range(1, 6):\n",
    "        if fold == val_fold:\n",
    "            continue\n",
    "        fold_dir = os.path.join(bull_base_dir, f'Fold{fold}')\n",
    "        X, y = load_images_and_labels(fold_dir)\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Validation data\n",
    "    val_dir = os.path.join(bull_base_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load and modify model\n",
    "    model = load_model(cow_model_path)\n",
    "    for layer in model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Create output directories\n",
    "    fold_tag = f'fold{val_fold}'\n",
    "    model_dir = os.path.join(output_base, 'Models', fold_tag)\n",
    "    history_dir = os.path.join(output_base, 'Histories', fold_tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'bull_transfer_model.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚è±Ô∏è Training time: {elapsed:.2f}s\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    print(f\"üìä Fold {val_fold} Results (LR = 2e-5):\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_2e5/Models'\n",
    "\n",
    "# === Load test images with filenames ===\n",
    "def load_images_labels_and_filenames(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        subdir_path = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(subdir_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "X_test, y_test, filenames = load_images_labels_and_filenames(test_dir)\n",
    "\n",
    "# === Loop through folds ===\n",
    "fold_metrics = []\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\nüìÇ Fold {fold} Evaluation\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found at {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics across all test images\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ConfusionMatrix': conf_mat.tolist(),\n",
    "        'NumSamples': len(y_test)\n",
    "    })\n",
    "\n",
    "    print(f\"‚úÖ Accuracy  : {acc:.4f}\")\n",
    "    print(f\"‚úÖ Precision : {precision:.4f}\")\n",
    "    print(f\"‚úÖ Recall    : {recall:.4f}\")\n",
    "    print(f\"‚úÖ F1 Score  : {f1:.4f}\")\n",
    "    print(f\"‚úÖ Confusion Matrix:\\n{conf_mat}\")\n",
    "\n",
    "# === Print average results ===\n",
    "print(\"\\nüìä Average Per-Image Metrics Across Folds:\")\n",
    "df_metrics = pd.DataFrame(fold_metrics)\n",
    "mean_vals = df_metrics[['Accuracy', 'Precision', 'Recall', 'F1 Score']].mean()\n",
    "print(mean_vals.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take most confident and show on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_2e5/Models'\n",
    "\n",
    "# === Load test images with filenames ===\n",
    "def load_images_labels_and_filenames(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        subdir_path = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(subdir_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "X_test, y_test, filenames = load_images_labels_and_filenames(test_dir)\n",
    "\n",
    "# === Loop through folds ===\n",
    "fold_metrics = []\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\nüìÇ Fold {fold} Evaluation\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found at {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Extract per-image metadata\n",
    "    data = []\n",
    "    for fname, true_label, prob, pred in zip(filenames, y_test, y_pred_probs, y_pred):\n",
    "        match = re.match(r'([A-Z]+\\d+).*Rating(\\d+)', fname)\n",
    "        if match:\n",
    "            indiv_id, rating = match.groups()\n",
    "            confidence = abs(prob - 0.5)\n",
    "            data.append((indiv_id, fname, int(rating), true_label, prob, pred, confidence))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'IndividualID', 'Filename', 'TrueRating', 'TrueLabel',\n",
    "        'PredictedProbability', 'PredictedLabel', 'Confidence'\n",
    "    ])\n",
    "\n",
    "    # Pick most confident image per individual\n",
    "    top_conf_df = (\n",
    "        df.sort_values(by='Confidence', ascending=False)\n",
    "        .groupby('IndividualID')\n",
    "        .first()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    y_true = top_conf_df['TrueLabel']\n",
    "    y_pred = top_conf_df['PredictedLabel']\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ConfusionMatrix': conf_mat.tolist(),\n",
    "        'NumIndividuals': len(top_conf_df)\n",
    "    })\n",
    "\n",
    "    print(f\"‚úÖ Accuracy  : {acc:.4f}\")\n",
    "    print(f\"‚úÖ Precision : {precision:.4f}\")\n",
    "    print(f\"‚úÖ Recall    : {recall:.4f}\")\n",
    "    print(f\"‚úÖ F1 Score  : {f1:.4f}\")\n",
    "    print(f\"‚úÖ Confusion Matrix:\\n{conf_mat}\")\n",
    "\n",
    "# === Print average results ===\n",
    "print(\"\\nüìä Average Per-Individual Metrics Across Folds:\")\n",
    "df_metrics = pd.DataFrame(fold_metrics)\n",
    "mean_vals = df_metrics[['Accuracy', 'Precision', 'Recall', 'F1 Score']].mean()\n",
    "print(mean_vals.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take max vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# === Paths ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_2e5/Models'\n",
    "\n",
    "# === Load test images with filenames ===\n",
    "def load_images_labels_and_filenames(image_dir):\n",
    "    images, labels, filenames = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        subdir_path = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(subdir_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(subdir_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "                filenames.append(fname)\n",
    "    return np.array(images), np.array(labels), filenames\n",
    "\n",
    "X_test, y_test, filenames = load_images_labels_and_filenames(test_dir)\n",
    "\n",
    "# === Loop through folds ===\n",
    "fold_metrics = []\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\nüìÇ Fold {fold} Evaluation\")\n",
    "\n",
    "    model_path = os.path.join(base_model_dir, f'fold{fold}', 'bull_transfer_model.keras')\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found at {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test).flatten()\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Extract per-image metadata\n",
    "    data = []\n",
    "    for fname, true_label, prob, pred in zip(filenames, y_test, y_pred_probs, y_pred):\n",
    "        match = re.match(r'([A-Z]+\\d+).*Rating(\\d+)', fname)\n",
    "        if match:\n",
    "            indiv_id, rating = match.groups()\n",
    "            confidence = abs(prob - 0.5)\n",
    "            data.append((indiv_id, fname, int(rating), true_label, prob, pred, confidence))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'IndividualID', 'Filename', 'TrueRating', 'TrueLabel',\n",
    "        'PredictedProbability', 'PredictedLabel', 'Confidence'\n",
    "    ])\n",
    "\n",
    "    # === Majority vote per individual\n",
    "    majority_vote_df = (\n",
    "        df.groupby('IndividualID')\n",
    "        .agg({\n",
    "            'TrueLabel': 'first',\n",
    "            'PredictedLabel': lambda x: int(np.sum(x) >= (len(x) / 2))\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    y_true = majority_vote_df['TrueLabel']\n",
    "    y_pred = majority_vote_df['PredictedLabel']\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'Fold': fold,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ConfusionMatrix': conf_mat.tolist(),\n",
    "        'NumIndividuals': len(majority_vote_df)\n",
    "    })\n",
    "\n",
    "    print(f\"‚úÖ Accuracy  : {acc:.4f}\")\n",
    "    print(f\"‚úÖ Precision : {precision:.4f}\")\n",
    "    print(f\"‚úÖ Recall    : {recall:.4f}\")\n",
    "    print(f\"‚úÖ F1 Score  : {f1:.4f}\")\n",
    "    print(f\"‚úÖ Confusion Matrix:\\n{conf_mat}\")\n",
    "\n",
    "# === Print average results ===\n",
    "print(\"\\nüìä Average Per-Individual Metrics Across Folds:\")\n",
    "df_metrics = pd.DataFrame(fold_metrics)\n",
    "mean_vals = df_metrics[['Accuracy', 'Precision', 'Recall', 'F1 Score']].mean()\n",
    "print(mean_vals.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze loss train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to Fold 1 history file\n",
    "history_path = '/Users/suzetteschulenburg/Desktop/BullsTransfer/LR_Experiments_2e5/Histories/fold1/history.pkl'\n",
    "\n",
    "# Load history\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy (Fold 1)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss (Fold 1)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsP'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsP'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1e-1,    # 0.1\n",
    "    5e-2,    # 0.05\n",
    "    2e-2,    # 0.02\n",
    "    1e-2,    # 0.01\n",
    "    7e-3,    # 0.007\n",
    "    5e-3,    # 0.005\n",
    "    3e-3,    # 0.003\n",
    "    2e-3,    # 0.002\n",
    "    1e-3,    # 0.001\n",
    "    7e-4,    # 0.0007\n",
    "    5e-4,    # 0.0005\n",
    "    3e-4,    # 0.0003\n",
    "    2e-4,    # 0.0002\n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsP'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsP'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    5e-2,    # 0.05\n",
    "    2e-2,    # 0.02\n",
    "    1e-2,    # 0.01\n",
    "    7e-3,    # 0.007\n",
    "    5e-3,    # 0.005\n",
    "    3e-3,    # 0.003\n",
    "    2e-3,    # 0.002\n",
    "    1e-3,    # 0.001\n",
    "    7e-4,    # 0.0007\n",
    "    5e-4,    # 0.0005\n",
    "    3e-4,    # 0.0003\n",
    "    2e-4,    # 0.0002\n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates and History Directory ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsP'\n",
    "\n",
    "# === Collect validation metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))\n",
    "        print(f\"‚úÖ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Remove missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and interpolate ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (Left Axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (Right Axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2 on Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val and train graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12\n",
    "})\n",
    "\n",
    "# === Learning Rates and Directory\n",
    "learning_rates = [ 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsP'\n",
    "\n",
    "# === Split LRs into 4 groups\n",
    "lr_groups = [\n",
    "    learning_rates[0:4],\n",
    "    learning_rates[4:8],\n",
    "    learning_rates[8:12],\n",
    "    learning_rates[12:]\n",
    "]\n",
    "\n",
    "# === Plot each group\n",
    "for idx, group in enumerate(lr_groups, 1):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # === Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for lr in group:\n",
    "        path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'rb') as f:\n",
    "                hist = pickle.load(f)\n",
    "            plt.plot(hist['accuracy'], label=f'Train {lr:.0e}')\n",
    "            plt.plot(hist['val_accuracy'], linestyle='--', label=f'Val {lr:.0e}')\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing file for LR={lr:.0e}\")\n",
    "    plt.title(f'Accuracy (Group {idx})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(ncol=2)\n",
    "\n",
    "    # === Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for lr in group:\n",
    "        path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'rb') as f:\n",
    "                hist = pickle.load(f)\n",
    "            plt.plot(hist['loss'], label=f'Train {lr:.0e}')\n",
    "            plt.plot(hist['val_loss'], linestyle='--', label=f'Val {lr:.0e}')\n",
    "    plt.title(f'Loss (Group {idx})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(ncol=2)\n",
    "\n",
    "    plt.suptitle(f'LR Group {idx}: {\", \".join([f\"{lr:.0e}\" for lr in group])}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Test directory ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'  \n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load trained model ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsP/LR_7e-03/model_fold245_val1_frozen.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Predict on test set ===\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"üìä Evaluation on Test Set (LR = 2e-03)\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBulls'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUlls'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1e-1,    # 0.1\n",
    "    5e-2,    # 0.05\n",
    "    2e-2,    # 0.02\n",
    "    1e-2,    # 0.01\n",
    "    7e-3,    # 0.007\n",
    "    5e-3,    # 0.005\n",
    "    3e-3,    # 0.003\n",
    "    2e-3,    # 0.002\n",
    "    1e-3,    # 0.001\n",
    "    7e-4,    # 0.0007\n",
    "    5e-4,    # 0.0005\n",
    "    3e-4,    # 0.0003\n",
    "    2e-4,    # 0.0002\n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBulls'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUlls'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    \n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze - choose 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates and History Directory ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUlls'\n",
    "\n",
    "# === Collect validation metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))\n",
    "        print(f\"‚úÖ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Remove missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and interpolate ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (Left Axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (Right Axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2 on Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates and History Directory ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUlls'\n",
    "\n",
    "# === Collect validation metrics ===\n",
    "val_accuracies, val_losses = [], []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))\n",
    "        print(f\"‚úÖ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Remove missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and interpolate ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Formatters and tick selection ===\n",
    "def scientific_fmt(x, _):\n",
    "    return r\"$10^{%d}$\" % int(np.log10(x))\n",
    "\n",
    "# Keep only one tick per power of ten\n",
    "unique_exponents = sorted(set(int(np.log10(lr)) for lr in filtered_lrs))\n",
    "xticks = [10**exp for exp in unique_exponents]\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (Left Axis)\n",
    "ax1.set_xlabel('Learning Rate', fontsize=18)\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue', fontsize=18)\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.xaxis.set_major_formatter(FuncFormatter(scientific_fmt))\n",
    "ax1.tick_params(axis='x', labelsize=14)\n",
    "ax1.tick_params(axis='y', labelcolor='blue', labelsize=14)\n",
    "plt.setp(ax1.get_xticklabels(), rotation=0)\n",
    "\n",
    "# Loss (Right Axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red', fontsize=18)\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red', labelsize=14)\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2 on Bulls)', fontsize=18)\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Test directory ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'  \n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load trained model ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBulls/LR_1e-03/model_fold245_val1_frozen.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Predict on test set ===\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"üìä Evaluation on Test Set (LR = 2e-03)\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMoreP'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMoreP'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1e-1,    # 0.1\n",
    "    5e-2,    # 0.05\n",
    "    2e-2,    # 0.02\n",
    "    1e-2,    # 0.01\n",
    "    7e-3,    # 0.007\n",
    "    5e-3,    # 0.005\n",
    "    3e-3,    # 0.003\n",
    "    2e-3,    # 0.002\n",
    "    1e-3,    # 0.001\n",
    "    7e-4,    # 0.0007\n",
    "    5e-4,    # 0.0005\n",
    "    3e-4,    # 0.0003\n",
    "    2e-4,    # 0.0002\n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMoreP'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMoreP'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1e-3,    # 0.001\n",
    "    7e-4,    # 0.0007\n",
    "    5e-4,    # 0.0005\n",
    "    3e-4,    # 0.0003\n",
    "    2e-4,    # 0.0002\n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates and History Directory ===\n",
    "learning_rates = [\n",
    "\n",
    "        1e-1,    # 0.1\n",
    "    5e-2,    # 0.05\n",
    "    2e-2,    # 0.02\n",
    "    1e-2,    # 0.01\n",
    "    7e-3,    # 0.007\n",
    "    5e-3,    # 0.005\n",
    "    3e-3,    # 0.003\n",
    "    2e-3,    # 0.002\n",
    "    1e-3,    # 0.001\n",
    "    7e-4,    # 0.0007\n",
    "    5e-4,    # 0.0005\n",
    "    3e-4,    # 0.0003\n",
    "    2e-4,    # 0.0002\n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMoreP'\n",
    "\n",
    "# === Collect validation metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))\n",
    "        print(f\"‚úÖ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Remove missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and interpolate ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (Left Axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (Right Axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2 on Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\n",
    "\n",
    "# === Test directory ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'  \n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load trained model ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMoreP/LR_2e-02/model_fold245_val1_frozen.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Predict on test set ===\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display ===\n",
    "print(f\"üìä Evaluation on Test Set (LR = 2e-03)\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Folds Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsFinalP'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsFinalP'\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_lr = 2e-2\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 5-Fold Training ===\n",
    "for val_fold in folds:\n",
    "    print(f\"\\n================ Fold {val_fold} =================\")\n",
    "\n",
    "    # Load validation set\n",
    "    val_dir = os.path.join(base_fold_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load training set (other folds)\n",
    "    X_train, y_train = [], []\n",
    "    train_folds = [f for f in folds if f != val_fold]\n",
    "    for fold_num in train_folds:\n",
    "        fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "        images, labels = load_images_and_labels(fold_dir)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Create model\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=chosen_lr)\n",
    "\n",
    "    # Set up directories\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    model_dir = os.path.join(base_model_dir, tag)\n",
    "    history_dir = os.path.join(base_history_dir, tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_best.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(f\"‚è±Ô∏è Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    print(f\"üìä Fold {val_fold} Evaluation\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Paths ===\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsFinalP'\n",
    "chosen_lr = 2e-2\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Plotting ===\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for val_fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    history_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if not os.path.exists(history_path):\n",
    "        print(f\"‚ùå History not found for Fold {val_fold}: {history_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(history['accuracy'], label=f'Fold {val_fold} Train')\n",
    "    plt.plot(history['val_accuracy'], linestyle='--', label=f'Fold {val_fold} Val')\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(history['loss'], label=f'Fold {val_fold} Train')\n",
    "    plt.plot(history['val_loss'], linestyle='--', label=f'Fold {val_fold} Val')\n",
    "\n",
    "# === Finalize Accuracy Plot ===\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training and Validation Accuracy per Fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# === Finalize Loss Plot ===\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Training and Validation Loss per Fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# === Confirmed Directories ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsFinalP'\n",
    "chosen_lr = 2e-2\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Test Set Once ===\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's best model ===\n",
    "print(\"\\n================ Final Test Set Evaluation =================\")\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"  # e.g., LR_2e-03_Fold1\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüß™ Evaluating Fold {fold} Model on Test Set\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"üìä Fold {fold} Test Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Config ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsFinalP'\n",
    "chosen_lr = 2e-2\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Load test images grouped by bull ID ===\n",
    "def load_images_grouped_by_bull(image_dir):\n",
    "    grouped = defaultdict(list)\n",
    "    true_labels = {}\n",
    "    for label_name, label_val in [('Good', 1), ('Bad', 0)]:\n",
    "        folder = os.path.join(image_dir, label_name)\n",
    "        if not os.path.exists(folder):\n",
    "            continue\n",
    "        for fname in os.listdir(folder):\n",
    "            if not fname.endswith('.jpg'):\n",
    "                continue\n",
    "            img_path = os.path.join(folder, fname)\n",
    "            image = load_img(img_path, target_size=(224, 224))\n",
    "            image_array = img_to_array(image) / 255.0\n",
    "            bull_id = fname.split('_')[0]  # e.g., MAD2188\n",
    "            grouped[bull_id].append((image_array, fname))\n",
    "            true_labels[bull_id] = label_val\n",
    "    return grouped, true_labels\n",
    "\n",
    "# === Load data once ===\n",
    "grouped_images, bull_true_labels = load_images_grouped_by_bull(test_dir)\n",
    "bull_ids = list(grouped_images.keys())\n",
    "\n",
    "# === Evaluate each fold separately ===\n",
    "print(\"\\n================ Per-Fold Bull-Level Metrics =================\")\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüìÇ Fold {fold} Evaluation\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Store per-image predictions\n",
    "    bull_image_preds = defaultdict(list)\n",
    "\n",
    "    # Predict all images and group by bull\n",
    "    for bull_id in bull_ids:\n",
    "        for image_array, fname in grouped_images[bull_id]:\n",
    "            x = np.expand_dims(image_array, axis=0)\n",
    "            prob = model.predict(x, verbose=0)[0][0]\n",
    "            pred = int(prob > 0.5)\n",
    "            bull_image_preds[bull_id].append(pred)\n",
    "\n",
    "    # Apply majority vote per bull\n",
    "    bull_preds = {}\n",
    "    for bull_id, preds in bull_image_preds.items():\n",
    "        majority_vote = int(sum(preds) >= (len(preds) / 2))\n",
    "        bull_preds[bull_id] = majority_vote\n",
    "\n",
    "    # Get true and predicted labels per bull\n",
    "    y_true = [bull_true_labels[bull_id] for bull_id in bull_ids]\n",
    "    y_pred = [bull_preds[bull_id] for bull_id in bull_ids]\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "\n",
    "    # Output\n",
    "    print(f\"  Bulls evaluated: {len(bull_ids)}\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBulls'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUlls'\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 5-Fold Training ===\n",
    "for val_fold in folds:\n",
    "    print(f\"\\n================ Fold {val_fold} =================\")\n",
    "\n",
    "    # Load validation set\n",
    "    val_dir = os.path.join(base_fold_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load training set (other folds)\n",
    "    X_train, y_train = [], []\n",
    "    train_folds = [f for f in folds if f != val_fold]\n",
    "    for fold_num in train_folds:\n",
    "        fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "        images, labels = load_images_and_labels(fold_dir)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Create model\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=chosen_lr)\n",
    "\n",
    "    # Set up directories\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    model_dir = os.path.join(base_model_dir, tag)\n",
    "    history_dir = os.path.join(base_history_dir, tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_best.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(f\"‚è±Ô∏è Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    print(f\"üìä Fold {val_fold} Evaluation\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show training graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 16,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 16\n",
    "})\n",
    "\n",
    "# === Directory where your history.pkl files are saved\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUlls'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load history file\n",
    "def load_history(fold):\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    file_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"‚ùå History not found for Fold {fold}: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# === Load all fold histories\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    hist = load_history(fold)\n",
    "    if hist:\n",
    "        fold_histories[fold] = hist\n",
    "\n",
    "# === Plotting function\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # --- Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color='blue', alpha=0.5, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Loss Across Folds (MobileNetV2)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # --- Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], color='blue', alpha=0.5, label=f'Fold {fold} Train Accuracy' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Accuracy' if fold == 1 else \"\")\n",
    "    plt.title('Training and Validation Accuracy Across Folds (MobileNetV2)')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Plot if histories are available\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"üö´ No valid history files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMore'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 5-Fold Training ===\n",
    "for val_fold in folds:\n",
    "    print(f\"\\n================ Fold {val_fold} =================\")\n",
    "\n",
    "    # Load validation set\n",
    "    val_dir = os.path.join(base_fold_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load training set (other folds)\n",
    "    X_train, y_train = [], []\n",
    "    train_folds = [f for f in folds if f != val_fold]\n",
    "    for fold_num in train_folds:\n",
    "        fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "        images, labels = load_images_and_labels(fold_dir)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Create model\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=chosen_lr)\n",
    "\n",
    "    # Set up directories\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    model_dir = os.path.join(base_model_dir, tag)\n",
    "    history_dir = os.path.join(base_history_dir, tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_best.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(f\"‚è±Ô∏è Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    print(f\"üìä Fold {val_fold} Evaluation\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMore'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 5-Fold Training ===\n",
    "for val_fold in folds:\n",
    "    print(f\"\\n================ Fold {val_fold} =================\")\n",
    "\n",
    "    # Load validation set\n",
    "    val_dir = os.path.join(base_fold_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load training set (other folds)\n",
    "    X_train, y_train = [], []\n",
    "    train_folds = [f for f in folds if f != val_fold]\n",
    "    for fold_num in train_folds:\n",
    "        fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "        images, labels = load_images_and_labels(fold_dir)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Create model\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=chosen_lr)\n",
    "\n",
    "    # Set up directories\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    model_dir = os.path.join(base_model_dir, tag)\n",
    "    history_dir = os.path.join(base_history_dir, tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_best.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(f\"‚è±Ô∏è Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    print(f\"üìä Fold {val_fold} Evaluation\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings (consistent with other plot)\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 18\n",
    "})\n",
    "\n",
    "# === Paths\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load history\n",
    "def load_history(fold):\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    file_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"‚ùå History not found for Fold {fold}: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# === Load histories\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    hist = load_history(fold)\n",
    "    if hist:\n",
    "        fold_histories[fold] = hist\n",
    "\n",
    "# === Plotting\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # === Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color='blue', alpha=0.5, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    plt.title(f'Training and Validation Loss Across Folds (LR={chosen_lr:.0e})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # === Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], color='blue', alpha=0.5, label=f'Fold {fold} Train Acc' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Acc' if fold == 1 else \"\")\n",
    "    plt.title(f'Training and Validation Accuracy Across Folds (LR={chosen_lr:.0e})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Plot if available\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"üö´ No valid history files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Paths ===\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Plotting Setup ===\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# === Subplot for Accuracy\n",
    "plt.subplot(2, 1, 1)\n",
    "for val_fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    history_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if not os.path.exists(history_path):\n",
    "        print(f\"‚ùå Missing history file: {history_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    plt.plot(history['accuracy'], label=f'Fold {val_fold} Train')\n",
    "    plt.plot(history['val_accuracy'], linestyle='--', label=f'Fold {val_fold} Val')\n",
    "\n",
    "plt.title('Train and Validation Accuracy per Fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# === Subplot for Loss\n",
    "plt.subplot(2, 1, 2)\n",
    "for val_fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    history_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if not os.path.exists(history_path):\n",
    "        continue\n",
    "\n",
    "    with open(history_path, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "\n",
    "    plt.plot(history['loss'], label=f'Fold {val_fold} Train')\n",
    "    plt.plot(history['val_loss'], linestyle='--', label=f'Fold {val_fold} Val')\n",
    "\n",
    "plt.title('Train and Validation Loss per Fold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMore'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 5-Fold Training ===\n",
    "for val_fold in folds:\n",
    "    print(f\"\\n================ Fold {val_fold} =================\")\n",
    "\n",
    "    # Load validation set\n",
    "    val_dir = os.path.join(base_fold_dir, f'Fold{val_fold}')\n",
    "    X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "    # Load training set (other folds)\n",
    "    X_train, y_train = [], []\n",
    "    train_folds = [f for f in folds if f != val_fold]\n",
    "    for fold_num in train_folds:\n",
    "        fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "        images, labels = load_images_and_labels(fold_dir)\n",
    "        X_train.append(images)\n",
    "        y_train.append(labels)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    # Create model\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=chosen_lr)\n",
    "\n",
    "    # Set up directories\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "    model_dir = os.path.join(base_model_dir, tag)\n",
    "    history_dir = os.path.join(base_history_dir, tag)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=45, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=35, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_best.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=1000,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    print(f\"‚è±Ô∏è Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    print(f\"üìä Fold {val_fold} Evaluation\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nalayze graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings (consistent with other plot)\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 18\n",
    "})\n",
    "\n",
    "# === Paths\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load history\n",
    "def load_history(fold):\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    file_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"‚ùå History not found for Fold {fold}: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# === Load histories\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    hist = load_history(fold)\n",
    "    if hist:\n",
    "        fold_histories[fold] = hist\n",
    "\n",
    "# === Plotting\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # === Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color='blue', alpha=0.5, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    plt.title(f'Training and Validation Loss Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # === Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['accuracy'], color='blue', alpha=0.5, label=f'Fold {fold} Train Acc' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_accuracy'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Acc' if fold == 1 else \"\")\n",
    "    plt.title(f'Training and Validation Accuracy Across Folds (LR={chosen_lr:.0e})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Plot if available\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"üö´ No valid history files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minim loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Font settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18,\n",
    "    'legend.fontsize': 18\n",
    "})\n",
    "\n",
    "# === Paths\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load history\n",
    "def load_history(fold):\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    file_path = os.path.join(base_history_dir, tag, 'history.pkl')\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(f\"‚ùå History not found for Fold {fold}: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# === Load histories\n",
    "fold_histories = {}\n",
    "for fold in folds:\n",
    "    hist = load_history(fold)\n",
    "    if hist:\n",
    "        fold_histories[fold] = hist\n",
    "\n",
    "# === Print metrics at min val_loss\n",
    "print(\"\\nüìâ Metrics at Minimum Validation Loss Per Fold\")\n",
    "print(f\"{'Fold':<6} {'Epoch':<6} {'Val Loss':<10} {'Val Acc':<10} {'Train Loss':<11} {'Train Acc':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for fold, history in fold_histories.items():\n",
    "    val_losses = history['val_loss']\n",
    "    min_idx = int(np.argmin(val_losses))\n",
    "\n",
    "    val_loss = val_losses[min_idx]\n",
    "    val_acc = history['val_accuracy'][min_idx]\n",
    "    train_loss = history['loss'][min_idx]\n",
    "    train_acc = history['accuracy'][min_idx]\n",
    "\n",
    "    # Correct if stored as percentages\n",
    "    if val_acc > 1.5: val_acc /= 100.0\n",
    "    if train_acc > 1.5: train_acc /= 100.0\n",
    "\n",
    "    print(f\"{fold:<6} {min_idx:<6} {val_loss:<10.4f} {val_acc:<10.4f} {train_loss:<11.4f} {train_acc:<10.4f}\")\n",
    "\n",
    "# === Plotting\n",
    "def plot_train_val_graphs(fold_histories):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # === Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for fold, history in fold_histories.items():\n",
    "        plt.plot(history['loss'], color='blue', alpha=0.5, label=f'Fold {fold} Train Loss' if fold == 1 else \"\")\n",
    "        plt.plot(history['val_loss'], linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Loss' if fold == 1 else \"\")\n",
    "    plt.title(f'Training and Validation Loss Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train Loss', 'Val Loss'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # === Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for fold, history in fold_histories.items():\n",
    "        acc = np.array(history['accuracy'])\n",
    "        val_acc = np.array(history['val_accuracy'])\n",
    "\n",
    "        # Auto-scale if saved as percentage\n",
    "        if np.nanmax(acc) > 1.5:\n",
    "            acc = acc / 100.0\n",
    "        if np.nanmax(val_acc) > 1.5:\n",
    "            val_acc = val_acc / 100.0\n",
    "\n",
    "        plt.plot(acc, color='blue', alpha=0.5, label=f'Fold {fold} Train Acc' if fold == 1 else \"\")\n",
    "        plt.plot(val_acc, linestyle='--', color='red', alpha=0.5, label=f'Fold {fold} Val Acc' if fold == 1 else \"\")\n",
    "    plt.title(f'Training and Validation Accuracy Across Folds (LR={chosen_lr:.0e})')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train Accuracy', 'Val Accuracy'], loc='upper left', bbox_to_anchor=(0.01, 0.99), frameon=True)\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Run\n",
    "if fold_histories:\n",
    "    plot_train_val_graphs(fold_histories)\n",
    "else:\n",
    "    print(\"üö´ No valid history files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# === Confirmed Directories ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMore' \n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Test Set Once ===\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's best model ===\n",
    "print(\"\\n================ Final Test Set Evaluation =================\")\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"  # e.g., LR_2e-03_Fold1\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüß™ Evaluating Fold {fold} Model on Test Set\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"üìä Fold {fold} Test Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict, Counter\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# === Directories ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMore'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Load test images, labels, and bull IDs ===\n",
    "def load_images_labels_ids(image_dir):\n",
    "    images, labels, ids = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                path = os.path.join(full_path, fname)\n",
    "                img = load_img(path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                bull_id = fname.split('_')[0]  # Assumes 'ABC123_IMG_1.jpg'\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "                ids.append(bull_id)\n",
    "    return np.array(images), np.array(labels), ids\n",
    "\n",
    "X_test, y_test, bull_ids = load_images_labels_ids(test_dir)\n",
    "\n",
    "print(\"\\n================ Final Test Set Evaluation (Majority Vote) =================\")\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüß™ Evaluating Fold {fold} Model on Test Set (Majority Voting)\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_probs = model.predict(X_test, verbose=0)\n",
    "    y_preds = (y_probs > 0.5).astype(int).flatten()\n",
    "\n",
    "    # Group by bull ID\n",
    "    votes = defaultdict(list)\n",
    "    true_labels = {}\n",
    "\n",
    "    for pred, prob, label, bull_id in zip(y_preds, y_probs.flatten(), y_test, bull_ids):\n",
    "        votes[bull_id].append(pred)\n",
    "        true_labels[bull_id] = label  # Assumes all images of a bull have same label\n",
    "\n",
    "    # Majority vote\n",
    "    y_true_majority, y_pred_majority = [], []\n",
    "\n",
    "    for bull_id, preds in votes.items():\n",
    "        final_pred = Counter(preds).most_common(1)[0][0]\n",
    "        y_pred_majority.append(final_pred)\n",
    "        y_true_majority.append(true_labels[bull_id])\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_true_majority, y_pred_majority)\n",
    "    f1 = f1_score(y_true_majority, y_pred_majority)\n",
    "    prec = precision_score(y_true_majority, y_pred_majority)\n",
    "    rec = recall_score(y_true_majority, y_pred_majority)\n",
    "\n",
    "    # AUC-PR (using probabilities is not meaningful with majority vote, so skip or set to -)\n",
    "    print(f\"üìä Fold {fold} Majority-Vote Test Metrics:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  AUC-PR:    --- (N/A for majority voting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsMore'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsMore'\n",
    "\n",
    "# === Parameters ===\n",
    "chosen_lr = 2e-3\n",
    "val_fold = 1\n",
    "train_folds = [2, 3, 4, 5]\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Fold 1 Training ===\n",
    "print(f\"\\n================ Fold {val_fold} =================\")\n",
    "\n",
    "# Load validation set\n",
    "val_dir = os.path.join(base_fold_dir, f'Fold{val_fold}')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# Load training set (Folds 2‚Äì5)\n",
    "X_train, y_train = [], []\n",
    "for fold_num in train_folds:\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# Create model\n",
    "model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=chosen_lr)\n",
    "\n",
    "# Set up directories\n",
    "tag = f\"LR_{chosen_lr:.0e}_Fold{val_fold}\"\n",
    "model_dir = os.path.join(base_model_dir, tag)\n",
    "history_dir = os.path.join(base_history_dir, tag)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, min_lr=1e-7),\n",
    "    ModelCheckpoint(os.path.join(model_dir, 'model_best.keras'), save_best_only=True),\n",
    "    TerminateOnNaN()\n",
    "]\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "print(f\"‚è±Ô∏è Training Time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Save training history\n",
    "with open(os.path.join(history_dir, 'history.pkl'), 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred_probs = model.predict(X_val)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred, zero_division=1)\n",
    "precision = precision_score(y_val, y_pred, zero_division=1)\n",
    "recall = recall_score(y_val, y_pred, zero_division=1)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "print(f\"üìä Fold {val_fold} Evaluation\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score,\n",
    "    precision_recall_curve, auc, confusion_matrix\n",
    ")\n",
    "\n",
    "# === Confirmed Directories ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBulls'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Test Set Once ===\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's best model ===\n",
    "print(\"\\n================ Final Test Set Evaluation =================\")\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"  # e.g., LR_2e-03_Fold1\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüß™ Evaluating Fold {fold} Model on Test Set\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"üìä Fold {fold} Test Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  AUC-PR:    {auc_pr:.4f}\")\n",
    "    print(f\"  Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 16,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'legend.fontsize': 16\n",
    "})\n",
    "\n",
    "# === Fold metrics\n",
    "metrics = [\n",
    "    {'Fold': 1, 'Accuracy': 0.5200, 'F1 Score': 0.4098, 'Precision': 0.3333, 'Recall': 0.5319, 'AUC-PR': 0.2966},\n",
    "    {'Fold': 2, 'Accuracy': 0.5333, 'F1 Score': 0.3750, 'Precision': 0.3231, 'Recall': 0.4468, 'AUC-PR': 0.2959},\n",
    "    {'Fold': 3, 'Accuracy': 0.5667, 'F1 Score': 0.2529, 'Precision': 0.2750, 'Recall': 0.2340, 'AUC-PR': 0.2703},\n",
    "    {'Fold': 4, 'Accuracy': 0.4867, 'F1 Score': 0.3840, 'Precision': 0.3077, 'Recall': 0.5106, 'AUC-PR': 0.2550},\n",
    "    {'Fold': 5, 'Accuracy': 0.5133, 'F1 Score': 0.3540, 'Precision': 0.3030, 'Recall': 0.4255, 'AUC-PR': 0.2773}\n",
    "]\n",
    "\n",
    "# === Convert to long-form DataFrame\n",
    "plot_data = []\n",
    "for m in metrics:\n",
    "    for metric_name in ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'AUC-PR']:\n",
    "        plot_data.append({\n",
    "            'Fold': f\"Fold {m['Fold']}\",\n",
    "            'Metric': metric_name,\n",
    "            'Value': m[metric_name]\n",
    "        })\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "# === Plot violin plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.violinplot(x='Metric', y='Value', data=df_plot, inner='point', palette='muted')\n",
    "plt.title('Distribution of Evaluation Metrics Across Folds')\n",
    "plt.ylim(0.08, 1.0)  # ‚úÖ Lower than 0.1 to prevent Seaborn from cutting off\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# === Confirmed Directories ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBulls'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Function to load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Test Set Once ===\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Evaluate each fold's best model ===\n",
    "print(\"\\n================ Final Test Set Evaluation =================\")\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"  # e.g., LR_2e-03_Fold1\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nüß™ Evaluating Fold {fold} Model on Test Set\")\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_probs = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "    prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "    auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"üìä Fold {fold} Test Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "from PIL import Image\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "\n",
    "# === Load model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Find last Conv2D layer\n",
    "last_conv_layer_name = None\n",
    "for layer in reversed(model.layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        last_conv_layer_name = layer.name\n",
    "        break\n",
    "if not last_conv_layer_name:\n",
    "    raise ValueError(\"No Conv2D layer found in the model.\")\n",
    "\n",
    "# === Load images and labels\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    path = os.path.join(full_path, fname)\n",
    "                    img = load_img(path, target_size=(224, 224))\n",
    "                    img_arr = img_to_array(img) / 255.0\n",
    "                    images.append(img_arr)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                    paths.append(path)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è {fname} skipped due to error: {e}\")\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, image_paths = load_images_and_labels(test_dir)\n",
    "y_probs = model.predict(X_test, verbose=0)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Grad-CAM Function\n",
    "def generate_gradcam(model, img_array, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.expand_dims(img_array, axis=0))\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "# === Heatmap Overlay\n",
    "def display_gradcam(img_array, heatmap, alpha=0.4):\n",
    "    img = np.uint8(255 * img_array)\n",
    "    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (224, 224)).numpy().squeeze()\n",
    "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "    heatmap_color = tf.keras.preprocessing.image.array_to_img(plt.cm.jet(heatmap_resized / 255.0)[..., :3])\n",
    "    overlay = Image.fromarray(img.astype('uint8')).convert('RGBA')\n",
    "    heatmap_img = heatmap_color.convert('RGBA')\n",
    "    blended = Image.blend(overlay, heatmap_img, alpha=alpha)\n",
    "    return blended\n",
    "\n",
    "# === Select 2 True Positives and 2 False Positives\n",
    "tp_idx = [i for i in range(len(y_test)) if y_test[i] == 1 and y_pred[i] == 1]\n",
    "fp_idx = [i for i in range(len(y_test)) if y_test[i] == 0 and y_pred[i] == 1]\n",
    "\n",
    "selected_indices = tp_idx[:2] + fp_idx[:2]\n",
    "\n",
    "# === Plot Results\n",
    "print(\"\\nüì∏ Showing Grad-CAMs:\")\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    img = X_test[idx]\n",
    "    heatmap = generate_gradcam(model, img, last_conv_layer_name)\n",
    "    blended = display_gradcam(img, heatmap)\n",
    "\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(blended)\n",
    "    true_label = \"Good\" if y_test[idx] == 1 else \"Bad\"\n",
    "    pred_label = \"Good\" if y_pred[idx] == 1 else \"Bad\"\n",
    "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from PIL import Image\n",
    "\n",
    "# === Paths ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/MainUse/MobileNet2_Frozen_AllLayersMinus4/model_fold2345_val1_frozen.keras'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/MainUseProcessed/Fold1'\n",
    "\n",
    "# === Load model ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Extract last conv layer name ===\n",
    "last_conv_layer_name = None\n",
    "for layer in reversed(model.layers):\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        last_conv_layer_name = layer.name\n",
    "        break\n",
    "if not last_conv_layer_name:\n",
    "    raise ValueError(\"No Conv2D layer found in the model.\")\n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                try:\n",
    "                    path = os.path.join(full_path, fname)\n",
    "                    img = load_img(path, target_size=(224, 224))\n",
    "                    img_arr = img_to_array(img) / 255.0\n",
    "                    images.append(img_arr)\n",
    "                    labels.append(1 if subdir == 'Good' else 0)\n",
    "                    paths.append(path)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è {fname} skipped due to error: {e}\")\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "X_test, y_test, image_paths = load_images_and_labels(test_dir)\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "# === Grad-CAM function ===\n",
    "def generate_gradcam(model, img_array, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = Model(\n",
    "        [model.inputs], \n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.expand_dims(img_array, axis=0))\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "# === Display Grad-CAM helper ===\n",
    "def display_gradcam(img_array, heatmap, alpha=0.4):\n",
    "    img = np.uint8(255 * img_array)\n",
    "    heatmap_resized = tf.image.resize(heatmap[..., np.newaxis], (224, 224)).numpy().squeeze()\n",
    "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "    heatmap_color = tf.keras.preprocessing.image.array_to_img(plt.cm.jet(heatmap_resized / 255.0)[..., :3])\n",
    "    overlay = Image.fromarray(img.astype('uint8')).convert('RGBA')\n",
    "    heatmap_img = heatmap_color.convert('RGBA')\n",
    "\n",
    "    blended = Image.blend(overlay, heatmap_img, alpha=alpha)\n",
    "    return blended\n",
    "\n",
    "# === Random selection: 2 TP and 2 FP ===\n",
    "tp_idx = [i for i in range(len(y_test)) if y_test[i] == 1 and y_pred[i] == 1]\n",
    "fp_idx = [i for i in range(len(y_test)) if y_test[i] == 0 and y_pred[i] == 1]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(tp_idx)\n",
    "random.shuffle(fp_idx)\n",
    "\n",
    "selected_indices = tp_idx[:2] + fp_idx[:2]\n",
    "\n",
    "# === Plot Grad-CAMs ===\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    img = X_test[idx]\n",
    "    heatmap = generate_gradcam(model, img, last_conv_layer_name)\n",
    "    blended = display_gradcam(img, heatmap)\n",
    "\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(blended)\n",
    "    true_label = \"Good\" if y_test[idx] == 1 else \"Bad\"\n",
    "    pred_label = \"Good\" if y_pred[idx] == 1 else \"Bad\"\n",
    "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\", fontsize=14)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# === Load test data once ===\n",
    "X_test, y_test = load_images_and_labels('/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy')\n",
    "\n",
    "# === Store predictions for each fold ===\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "all_folds = []\n",
    "\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    y_pred_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    \n",
    "    all_probs.extend(y_pred_probs)\n",
    "    all_labels.extend(y_test)\n",
    "    all_folds.extend([fold] * len(y_test))  # track fold index per sample\n",
    "\n",
    "# === Convert to numpy arrays\n",
    "all_probs = np.array(all_probs)\n",
    "all_labels = np.array(all_labels)\n",
    "all_folds = np.array(all_folds)\n",
    "\n",
    "# === Create plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "colors = ['green' if label == 1 else 'red' for label in all_labels]\n",
    "x_indices = []\n",
    "\n",
    "offset = 0\n",
    "gap = 5  # space between fold groups\n",
    "samples_per_fold = len(X_test)\n",
    "\n",
    "for i, fold in enumerate(folds):\n",
    "    start = offset + i * (samples_per_fold + gap)\n",
    "    end = start + samples_per_fold\n",
    "    x_indices.extend(list(range(start, end)))\n",
    "\n",
    "plt.scatter(\n",
    "    x_indices, all_probs,\n",
    "    c=colors, alpha=0.6, edgecolors='k'\n",
    ")\n",
    "\n",
    "# Threshold line\n",
    "plt.axhline(0.5, color='gray', linestyle='--', linewidth=1, label='Threshold = 0.5')\n",
    "\n",
    "# Vertical lines separating folds\n",
    "for i in range(1, len(folds)):\n",
    "    plt.axvline(i * (samples_per_fold + gap) - gap // 2, color='black', linestyle=':', linewidth=0.5)\n",
    "\n",
    "# Legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', label='Good (1)', markerfacecolor='green', markersize=10, markeredgecolor='k'),\n",
    "    Line2D([0], [0], marker='o', color='w', label='Bad (0)', markerfacecolor='red', markersize=10, markeredgecolor='k'),\n",
    "    Line2D([0], [0], color='gray', lw=1, linestyle='--', label='Threshold = 0.5')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "# Labels and formatting\n",
    "plt.title('Predicted Probabilities Across Folds (All Models on Same Test Set)')\n",
    "plt.xlabel('Samples (Grouped by Fold)')\n",
    "plt.ylabel('Predicted Probability (Good)')\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# === Directories and Parameters ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBulls'\n",
    "chosen_lr = 2e-3\n",
    "folds = [1, 2, 3, 4, 5]\n",
    "\n",
    "# === Load images, labels, and paths\n",
    "def load_images_and_labels_with_paths(image_dir):\n",
    "    images, labels, paths = [], [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        label = 1 if subdir == 'Good' else 0\n",
    "        folder = os.path.join(image_dir, subdir)\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                fpath = os.path.join(folder, fname)\n",
    "                img = load_img(fpath, target_size=(224, 224))\n",
    "                arr = img_to_array(img) / 255.0\n",
    "                images.append(arr)\n",
    "                labels.append(label)\n",
    "                paths.append(fpath)\n",
    "    return np.array(images), np.array(labels), paths\n",
    "\n",
    "# === Load Test Data\n",
    "X_test, y_test, img_paths = load_images_and_labels_with_paths(test_dir)\n",
    "\n",
    "# === Store misclassification examples across folds\n",
    "categories = {\n",
    "    'TP (Correct Good)': [],\n",
    "    'TN (Correct Bad)': [],\n",
    "    'FP (Incorrect Good)': [],\n",
    "    'FN (Incorrect Bad)': []\n",
    "}\n",
    "\n",
    "# === Evaluate all folds and track categories\n",
    "for fold in folds:\n",
    "    tag = f\"LR_{chosen_lr:.0e}_Fold{fold}\"\n",
    "    model_path = os.path.join(base_model_dir, tag, 'model_best.keras')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found for Fold {fold}: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    y_probs = model.predict(X_test, verbose=0).flatten()\n",
    "    y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        true = y_test[i]\n",
    "        pred = y_pred[i]\n",
    "        path = img_paths[i]\n",
    "\n",
    "        if true == 1 and pred == 1:\n",
    "            categories['TP (Correct Good)'].append(path)\n",
    "        elif true == 0 and pred == 0:\n",
    "            categories['TN (Correct Bad)'].append(path)\n",
    "        elif true == 0 and pred == 1:\n",
    "            categories['FP (Incorrect Good)'].append(path)\n",
    "        elif true == 1 and pred == 0:\n",
    "            categories['FN (Incorrect Bad)'].append(path)\n",
    "\n",
    "# === Randomly select one image from each category\n",
    "selected_paths = {\n",
    "    label: random.choice(paths) if paths else None\n",
    "    for label, paths in categories.items()\n",
    "}\n",
    "\n",
    "# === Display the selected examples\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i, (label, path) in enumerate(selected_paths.items()):\n",
    "    if path is not None:\n",
    "        img = load_img(path, target_size=(224, 224))\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(label, fontsize=10)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No image found for category: {label}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no yolo 2e-3 same as with yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsNoUoYOLO'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1e-1,    # 0.1\n",
    "    5e-2,    # 0.05\n",
    "    2e-2    # 0.02\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsNoUoYOLO'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    1e-2,    # 0.01\n",
    "    7e-3,    # 0.007\n",
    "    5e-3\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsNoUoYOLO'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    3e-3,    # 0.003\n",
    "    2e-3,    # 0.002\n",
    "    1e-3,    # 0.001\n",
    "    7e-4,    # 0.0007\n",
    "    5e-4,    # 0.0005\n",
    "    3e-4,    # 0.0003\n",
    "    2e-4,    # 0.0002\n",
    "    1e-4,    # 0.0001\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === GPU Setup ===\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Memory Growth Setting Error: {e}\")\n",
    "\n",
    "# === Directories ===\n",
    "base_fold_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds'\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO'\n",
    "base_history_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsNoUoYOLO'\n",
    "\n",
    "# === Function to load images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for subdir in ['Good', 'Bad']:\n",
    "        full_path = os.path.join(image_dir, subdir)\n",
    "        if not os.path.exists(full_path):\n",
    "            continue\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                image_path = os.path.join(full_path, fname)\n",
    "                image_array = load_img(image_path, target_size=(224, 224))\n",
    "                images.append(img_to_array(image_array) / 255.0)\n",
    "                labels.append(1 if subdir == 'Good' else 0)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# === Load Train Folds (2‚Äì5) ===\n",
    "X_train, y_train = [], []\n",
    "for fold_num in range(2, 6):\n",
    "    fold_dir = os.path.join(base_fold_dir, f'Fold{fold_num}')\n",
    "    images, labels = load_images_and_labels(fold_dir)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "# === Load Validation Fold (Fold1) ===\n",
    "val_dir = os.path.join(base_fold_dir, 'Fold1')\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Build Model ===\n",
    "def create_mobilenetv2_model(image_shape, learning_rate):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "    base_model.trainable = False  # Freeze all layers\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, clipvalue=1.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Learning rates to test ===\n",
    "learning_rates = [\n",
    "    7e-5,    # 0.00007\n",
    "    5e-5     # 0.00005\n",
    "]\n",
    "\n",
    "\n",
    "# === Training Loop ===\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nüöÄ Training with Learning Rate = {lr}\")\n",
    "    model = create_mobilenetv2_model(X_train.shape[1:], learning_rate=lr)\n",
    "\n",
    "    model_dir = os.path.join(base_model_dir, f\"LR_{lr:.0e}\")\n",
    "    history_dir = os.path.join(base_history_dir, f\"LR_{lr:.0e}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(history_dir, exist_ok=True)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7),\n",
    "        ModelCheckpoint(os.path.join(model_dir, 'model_fold245_val1_frozen.keras'), save_best_only=True),\n",
    "        TerminateOnNaN()\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è Training Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Save training history\n",
    "    with open(os.path.join(history_dir, 'history_fold245_val1_frozen.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred_probs = model.predict(X_val)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred_labels, zero_division=1)\n",
    "    precision = precision_score(y_val, y_pred_labels, zero_division=1)\n",
    "    recall = recall_score(y_val, y_pred_labels, zero_division=1)\n",
    "    accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"üìä Results for LR={lr:.0e}\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"AUC-PR:    {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analayze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates and History Directory ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsNoUoYOLO'\n",
    "\n",
    "# === Collect validation metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))\n",
    "        print(f\"‚úÖ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Remove missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and interpolate ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (Left Axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xticks(filtered_lrs)\n",
    "ax1.set_xticklabels([f\"{lr:.0e}\" for lr in filtered_lrs], rotation=45)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Loss (Right Axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (MobileNetV2 on Bulls)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# === Learning Rates and History Directory ===\n",
    "learning_rates = [\n",
    "    5e-5, 7e-5, 1e-4, 2e-4, 3e-4, 4e-4, 5e-4, 7e-4, 1e-3, 2e-3,\n",
    "    3e-3, 5e-3, 7e-3, 1e-2, 2e-2, 5e-2, 1e-1\n",
    "]\n",
    "history_base_dir = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsNoUoYOLO'\n",
    "\n",
    "# === Collect validation metrics ===\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    path = os.path.join(history_base_dir, f\"LR_{lr:.0e}\", 'history_fold245_val1_frozen.pkl')\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            hist = pickle.load(f)\n",
    "        val_accuracies.append(max(hist['val_accuracy']))\n",
    "        val_losses.append(np.mean(hist['val_loss']))\n",
    "        print(f\"‚úÖ LR={lr:.0e}: Val Acc={val_accuracies[-1]:.4f}, Avg Val Loss={val_losses[-1]:.4f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing history file: {path}\")\n",
    "        val_accuracies.append(None)\n",
    "        val_losses.append(None)\n",
    "\n",
    "# === Remove missing values ===\n",
    "filtered_lrs, filtered_accs, filtered_losses = [], [], []\n",
    "for lr, acc, loss in zip(learning_rates, val_accuracies, val_losses):\n",
    "    if acc is not None and loss is not None:\n",
    "        filtered_lrs.append(lr)\n",
    "        filtered_accs.append(acc)\n",
    "        filtered_losses.append(loss)\n",
    "\n",
    "# === Sort and interpolate ===\n",
    "sorted_idx = np.argsort(filtered_lrs)\n",
    "filtered_lrs = np.array(filtered_lrs)[sorted_idx]\n",
    "filtered_accs = np.array(filtered_accs)[sorted_idx]\n",
    "filtered_losses = np.array(filtered_losses)[sorted_idx]\n",
    "\n",
    "x = np.log10(filtered_lrs)\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "acc_smooth = make_interp_spline(x, filtered_accs, k=2)(x_smooth)\n",
    "loss_smooth = make_interp_spline(x, filtered_losses, k=2)(x_smooth)\n",
    "\n",
    "# === Prepare unique exponent ticks ===\n",
    "exponents = sorted(set(int(np.floor(np.log10(lr))) for lr in filtered_lrs))\n",
    "xticks = [10**e for e in exponents]\n",
    "xticklabels = [f\"$10^{{{e}}}$\" for e in exponents]\n",
    "\n",
    "# === Plot ===\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Accuracy (Left Axis)\n",
    "ax1.set_xlabel('Learning Rate')\n",
    "ax1.set_ylabel('Best Validation Accuracy', color='blue')\n",
    "ax1.plot(10**x_smooth, acc_smooth, color='blue')\n",
    "ax1.scatter(filtered_lrs, filtered_accs, color='blue')\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Set only one tick per exponent\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.set_xticklabels(xticklabels, rotation=0)\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.tick_params(axis='x', labelsize=14)\n",
    "\n",
    "# Loss (Right Axis)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Average Validation Loss', color='red')\n",
    "ax2.plot(10**x_smooth, loss_smooth, color='red')\n",
    "ax2.scatter(filtered_lrs, filtered_losses, color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Validation Accuracy and Average Loss vs Learning Rate (No YOLO)')\n",
    "plt.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Directories ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO'\n",
    "val_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold1'\n",
    "\n",
    "# === Load validation images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for class_name in ['Good', 'Bad']:\n",
    "        label = 1 if class_name == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, class_name)\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_val, y_val = load_images_and_labels(val_dir)\n",
    "\n",
    "# === Load trained model ===\n",
    "model_path = os.path.join(base_model_dir, 'LR_7e-03', 'model_fold245_val1_frozen.keras')\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Predict and compute metrics ===\n",
    "y_pred_probs = model.predict(X_val).flatten()\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "# === Print final metrics ===\n",
    "print(\"üìä Final Validation Metrics (Fold1, LR=7e-3)\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "\n",
    "# === Optional: Plot PR Curve ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(rec_curve, prec_curve, label=f'AUC-PR = {auc_pr:.2f}', color='darkorange')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (Validation Set)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# === Compute all metrics ===\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "# === Print final metrics ===\n",
    "print(\"üìä Final Validation Metrics (Fold1, LR = 7e-3)\")\n",
    "print(f\"Accuracy     : {accuracy:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# === Load Training History ===\n",
    "history_path = '/Users/suzetteschulenburg/Desktop/Bulls/History_MobileNet2_LRBUllsNoUoYOLO/LR_7e-03/history_fold245_val1_frozen.pkl'\n",
    "\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# === Create side-by-side subplots ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# === Accuracy Plot ===\n",
    "axes[0].plot(history['accuracy'], label='Train Accuracy')\n",
    "axes[0].plot(history['val_accuracy'], label='Val Accuracy')\n",
    "axes[0].set_title('Training and Validation Accuracy (LR = 7e-3)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# === Loss Plot ===\n",
    "axes[1].plot(history['loss'], label='Train Loss')\n",
    "axes[1].plot(history['val_loss'], label='Val Loss')\n",
    "axes[1].set_title('Training and Validation Loss (LR = 7e-3)')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === CONFIG ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO/LR_5e-03/model_fold245_val1_frozen.keras'\n",
    "image_paths = [\n",
    "    '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold1/Bad/E22147_3_IMG_8939_Rating5_augFlipped_226.jpg',\n",
    "    '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold1/Bad/JH2128_3_Rating5_augFlipped_1.jpg',\n",
    "    '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold1/Good/MAD22217_8_IMG_3423_Rating8.jpg',\n",
    "    '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Folds/Fold1/Good/NONO1_3_IMG_3055_Rating8_augSharpened.jpg'\n",
    "]\n",
    "target_size = (224, 224)\n",
    "last_conv_layer_name = 'Conv_1'\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === PLOT SETUP ===\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    # === LOAD AND PREPROCESS IMAGE ===\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array_exp = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "    # === BUILD GRAD-CAM MODEL ===\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array_exp)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        class_output = predictions[:, pred_index]\n",
    "\n",
    "    # === COMPUTE GRAD-CAM ===\n",
    "    grads = tape.gradient(class_output, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= tf.math.reduce_max(heatmap) + 1e-8\n",
    "\n",
    "    # === COMBINE WITH ORIGINAL IMAGE ===\n",
    "    img_cv = cv2.imread(image_path)\n",
    "    img_cv = cv2.resize(img_cv, target_size)\n",
    "    heatmap_resized = cv2.resize(heatmap.numpy(), (img_cv.shape[1], img_cv.shape[0]))\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(img_cv, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "    # === SHOW OVERLAY IMAGE ONLY ===\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TerminateOnNaN\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "import time\n",
    "\n",
    "# === Load Test Set ===\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Test'\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load Trained Model (7e-3) ===\n",
    "model_path = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO/LR_5e-03/model_fold245_val1_frozen.keras'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# === Predict on Test Set ===\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# === Compute Metrics ===\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "prec_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(recall_curve, prec_curve)\n",
    "\n",
    "# === Display Metrics ===\n",
    "print(\"\\nüìä Evaluation on Test Set (LR = 7e-3)\")\n",
    "print(f\"Accuracy     : {acc:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# === Plot Confusion Matrix ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix on Test Set (LR = 7e-3)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    accuracy_score, precision_recall_curve, auc\n",
    ")\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# === Directories ===\n",
    "base_model_dir = '/Users/suzetteschulenburg/Desktop/Bulls/MobileNet2_LRBullsNoYOLO'\n",
    "test_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Test'\n",
    "\n",
    "# === Load test images and labels ===\n",
    "def load_images_and_labels(image_dir):\n",
    "    images, labels = [], []\n",
    "    for class_name in ['Good', 'Bad']:\n",
    "        label = 1 if class_name == 'Good' else 0\n",
    "        full_path = os.path.join(image_dir, class_name)\n",
    "        for fname in os.listdir(full_path):\n",
    "            if fname.lower().endswith('.jpg'):\n",
    "                img_path = os.path.join(full_path, fname)\n",
    "                img = load_img(img_path, target_size=(224, 224))\n",
    "                img_array = img_to_array(img) / 255.0\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_test, y_test = load_images_and_labels(test_dir)\n",
    "\n",
    "# === Load trained model ===\n",
    "model_path = os.path.join(base_model_dir, 'LR_7e-03', 'model_fold245_val1_frozen.keras')\n",
    "model = load_model(model_path)\n",
    "\n",
    "# === Predict and compute metrics ===\n",
    "y_pred_probs = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(rec_curve, prec_curve)\n",
    "\n",
    "# === Print final metrics ===\n",
    "print(\"üìä Final Test Metrics (Fold1, LR=7e-3)\")\n",
    "print(f\"Accuracy     : {accuracy:.4f}\")\n",
    "print(f\"F1 Score     : {f1:.4f}\")\n",
    "print(f\"Precision    : {precision:.4f}\")\n",
    "print(f\"Recall       : {recall:.4f}\")\n",
    "print(f\"AUC-PR       : {auc_pr:.4f}\")\n",
    "\n",
    "# === Plot PR Curve ===\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(rec_curve, prec_curve, label=f'AUC-PR = {auc_pr:.2f}', color='darkorange')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve (Test Set)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from ultralytics import YOLO # Import YOLO model\n",
    "\n",
    "# --- Paths for the specific image to test ---\n",
    "# Please double-check these paths are correct for your system\n",
    "labelme_json_path = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1/LabelMe/Good/MAD22382_10_IMG_2952_Rating8.json'\n",
    "# We will NOT use yolo_output_path directly for mask extraction anymore.\n",
    "# We'll run YOLO on the original image.\n",
    "original_image_manual_path = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Test copy/Good/MAD22382_10_IMG_2952_Rating8.jpg'\n",
    "\n",
    "# === Load YOLO segmentation model ===\n",
    "try:\n",
    "    model = YOLO(\"yolov8s-seg.pt\") # Ensure you have this model downloaded or accessible\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLO model: {e}\")\n",
    "    print(\"Please ensure 'yolov8s-seg.pt' is in your current directory or specified path.\")\n",
    "    exit()\n",
    "\n",
    "# --- Load LabelMe JSON and original image ---\n",
    "try:\n",
    "    with open(labelme_json_path, 'r') as f:\n",
    "        labelme_data = json.load(f)\n",
    "\n",
    "    original_img_path = original_image_manual_path\n",
    "    if not os.path.exists(original_img_path):\n",
    "        raise FileNotFoundError(f\"Original image NOT FOUND at {original_img_path}. Please check the path.\")\n",
    "\n",
    "    original_img_pil = Image.open(original_img_path).convert('RGB') # Ensure RGB for YOLO\n",
    "    original_img_np = np.array(original_img_pil) # Original image as NumPy array\n",
    "    original_h, original_w = original_img_np.shape[:2]\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading LabelMe data or original image: {e}\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode LabelMe JSON from {labelme_json_path}. Check file format.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Create binary mask from LabelMe polygon (at original image resolution) ---\n",
    "labelme_mask_pil = Image.new('L', (original_w, original_h), 0)\n",
    "draw = ImageDraw.Draw(labelme_mask_pil)\n",
    "found_polygon = False\n",
    "labelme_polygon_points = []\n",
    "for shape in labelme_data.get('shapes', []):\n",
    "    if shape['shape_type'] == 'polygon' and 'points' in shape:\n",
    "        polygon = [(x, y) for x, y in shape['points']]\n",
    "        if len(polygon) >= 3:\n",
    "            # Ensure points are integers for ImageDraw\n",
    "            int_polygon = [(int(p[0]), int(p[1])) for p in polygon]\n",
    "            draw.polygon(int_polygon, outline=1, fill=1)\n",
    "            labelme_polygon_points.extend(polygon)\n",
    "            found_polygon = True\n",
    "\n",
    "if not found_polygon:\n",
    "    print(f\"Warning: No valid polygon found in LabelMe JSON for {os.path.basename(labelme_json_path)}. IoU will be 0.\")\n",
    "    # Create an empty mask if no polygon is found\n",
    "    labelme_binary_original_res = np.zeros((original_h, original_w), dtype=np.uint8)\n",
    "else:\n",
    "    # Convert PIL mask to a binary NumPy array (0 or 1) at original resolution\n",
    "    labelme_binary_original_res = (np.array(labelme_mask_pil) > 0).astype(np.uint8)\n",
    "\n",
    "# --- Run YOLO segmentation on the ORIGINAL image ---\n",
    "yolo_binary_original_res = np.zeros((original_h, original_w), dtype=np.uint8) # Initialize empty YOLO mask\n",
    "yolo_confidence = 0.0\n",
    "\n",
    "try:\n",
    "    results = model(original_img_np, verbose=False) # Run inference, suppress verbose output\n",
    "    masks = results[0].masks\n",
    "    boxes = results[0].boxes\n",
    "    names = results[0].names\n",
    "\n",
    "    if masks is None or len(masks.data) == 0:\n",
    "        print(f\"‚ùå No cow mask found by YOLO in: {os.path.basename(original_img_path)}\")\n",
    "    else:\n",
    "        # Find the largest 'cow' mask (or similar animal class)\n",
    "        best_index = None\n",
    "        largest_area = 0\n",
    "        for i, cls_id in enumerate(boxes.cls.cpu().numpy()):\n",
    "            name = names[int(cls_id)]\n",
    "            if name in ['cow', 'bull', 'animal', 'cattle']: # Adjust class names if needed\n",
    "                x1, y1, x2, y2 = map(int, boxes.xyxy[i].cpu().numpy())\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                if area > largest_area:\n",
    "                    best_index = i\n",
    "                    largest_area = area\n",
    "        \n",
    "        if best_index is not None:\n",
    "            # Get the mask data, resize to original image dimensions\n",
    "            yolo_mask_data = masks.data[best_index].cpu().numpy()\n",
    "            yolo_mask_resized = cv2.resize(yolo_mask_data, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "            yolo_binary_original_res = (yolo_mask_resized > 0.5).astype(np.uint8) # Threshold to binary\n",
    "            yolo_confidence = float(boxes.conf[best_index].cpu().numpy())\n",
    "            print(f\"‚úÖ YOLO detected a '{names[int(boxes.cls[best_index])]}' with confidence: {yolo_confidence:.2f}\")\n",
    "        else:\n",
    "            print(f\"‚ùå No valid 'cow' class detected by YOLO in: {os.path.basename(original_img_path)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during YOLO inference: {e}\")\n",
    "\n",
    "# --- Compute IoU (both masks are at original image resolution) ---\n",
    "if yolo_binary_original_res.shape != labelme_binary_original_res.shape:\n",
    "    print(f\"Error: Mask shapes do not match for IoU calculation! YOLO: {yolo_binary_original_res.shape}, LabelMe: {labelme_binary_original_res.shape}\")\n",
    "    iou = 0.0\n",
    "else:\n",
    "    intersection = np.logical_and(yolo_binary_original_res, labelme_binary_original_res).sum()\n",
    "    union = np.logical_or(yolo_binary_original_res, labelme_binary_original_res).sum()\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "\n",
    "print(f\"IoU (Intersection over Union): {iou * 100:.2f}%\")\n",
    "\n",
    "# --- Visualization ---\n",
    "fig_title = (f\"IoU: {iou * 100:.2f}% | YOLO Conf: {yolo_confidence:.2f} \"\n",
    "             f\"for {os.path.basename(original_img_path)} \"\n",
    "             f\"(Comparing Full-Image YOLO to Manual Label)\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(28, 10)) # Adjusted figsize for potentially large images\n",
    "\n",
    "# Plot 1: Original Image with Manual Label (Ground Truth)\n",
    "original_img_display_gt = original_img_np.copy()\n",
    "if found_polygon:\n",
    "    temp_pil_gt = Image.fromarray(original_img_display_gt)\n",
    "    temp_draw_gt = ImageDraw.Draw(temp_pil_gt)\n",
    "    int_polygon = [(int(p[0]), int(p[1])) for p in polygon] # Use int_polygon here\n",
    "    temp_draw_gt.polygon(int_polygon, outline=(255, 0, 0), width=5) # Red outline\n",
    "    axs[0].imshow(temp_pil_gt)\n",
    "else:\n",
    "    axs[0].imshow(original_img_display_gt)\n",
    "axs[0].set_title(\"Original Image with Manual Label (Ground Truth)\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "# Plot 2: Original Image with YOLO Segmentation Mask\n",
    "yolo_mask_colored = np.zeros_like(original_img_np, dtype=np.uint8)\n",
    "yolo_mask_colored[yolo_binary_original_res > 0] = [0, 255, 0] # Green for YOLO mask\n",
    "\n",
    "overlay_yolo_on_original = cv2.addWeighted(original_img_np, 0.7, yolo_mask_colored, 0.3, 0)\n",
    "axs[1].imshow(overlay_yolo_on_original)\n",
    "axs[1].set_title(\"Original Image with YOLO Prediction\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Plot 3: Combined Overlay (Manual Red + YOLO Green + Overlap Blue)\n",
    "combined_mask_colored = np.zeros_like(original_img_np, dtype=np.uint8)\n",
    "# Red: LabelMe only\n",
    "combined_mask_colored[np.logical_and(labelme_binary_original_res, ~yolo_binary_original_res) > 0] = [255, 0, 0]\n",
    "# Green: YOLO only\n",
    "combined_mask_colored[np.logical_and(~labelme_binary_original_res, yolo_binary_original_res) > 0] = [0, 255, 0]\n",
    "# Blue: Overlap\n",
    "combined_mask_colored[np.logical_and(labelme_binary_original_res, yolo_binary_original_res) > 0] = [0, 0, 255]\n",
    "\n",
    "final_overlay_display = cv2.addWeighted(original_img_np, 0.7, combined_mask_colored, 0.3, 0)\n",
    "axs[2].imshow(final_overlay_display)\n",
    "axs[2].set_title(\"Overlay: Manual (Red) + YOLO (Green) + Overlap (Blue)\")\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.suptitle(fig_title, fontsize=18, y=0.98) # Adjusted y for title\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# === Base paths ===\n",
    "base_json_dir = '/Users/suzetteschulenburg/Desktop/BullsProcessed/Test_Copy1/LabelMe'\n",
    "base_image_dir = '/Users/suzetteschulenburg/Desktop/Bulls/Split copy 2/Test copy'\n",
    "\n",
    "# === Load YOLO model ===\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "def compute_avg_iou(subfolder):\n",
    "    json_dir = os.path.join(base_json_dir, subfolder)\n",
    "    image_dir = os.path.join(base_image_dir, subfolder)\n",
    "\n",
    "    ious = []\n",
    "    missing_images = 0\n",
    "    total_files = 0\n",
    "\n",
    "    for json_file in sorted(os.listdir(json_dir)):\n",
    "        if not json_file.endswith('.json'):\n",
    "            continue\n",
    "\n",
    "        json_path = os.path.join(json_dir, json_file)\n",
    "        image_name = os.path.splitext(json_file)[0] + '.jpg'\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            missing_images += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                labelme_data = json.load(f)\n",
    "\n",
    "            img_pil = Image.open(image_path).convert('RGB')\n",
    "            img_np = np.array(img_pil)\n",
    "            h, w = img_np.shape[:2]\n",
    "\n",
    "            # Manual mask (already excludes bottom 30%)\n",
    "            labelme_mask = Image.new('L', (w, h), 0)\n",
    "            draw = ImageDraw.Draw(labelme_mask)\n",
    "            for shape in labelme_data.get('shapes', []):\n",
    "                if shape['shape_type'] == 'polygon' and 'points' in shape:\n",
    "                    polygon = [(int(x), int(y)) for x, y in shape['points']]\n",
    "                    if len(polygon) >= 3:\n",
    "                        draw.polygon(polygon, outline=1, fill=1)\n",
    "\n",
    "            label_mask = (np.array(labelme_mask) > 0).astype(np.uint8)\n",
    "\n",
    "            # YOLO\n",
    "            yolo_result = model(img_np, verbose=False)[0]\n",
    "            yolo_mask_bin = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "            if yolo_result.masks and len(yolo_result.masks.data) > 0:\n",
    "                best_index = -1\n",
    "                max_area = 0\n",
    "                for i, cls in enumerate(yolo_result.boxes.cls.cpu().numpy()):\n",
    "                    name = yolo_result.names[int(cls)]\n",
    "                    if name in ['cow', 'bull', 'animal', 'cattle']:\n",
    "                        x1, y1, x2, y2 = map(int, yolo_result.boxes.xyxy[i].cpu().numpy())\n",
    "                        area = (x2 - x1) * (y2 - y1)\n",
    "                        if area > max_area:\n",
    "                            best_index = i\n",
    "                            max_area = area\n",
    "\n",
    "                if best_index != -1:\n",
    "                    yolo_mask = yolo_result.masks.data[best_index].cpu().numpy()\n",
    "                    yolo_mask_resized = cv2.resize(yolo_mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "                    yolo_mask_bin = (yolo_mask_resized > 0.5).astype(np.uint8)\n",
    "\n",
    "            # Crop only YOLO mask to top 70%\n",
    "            cutoff = int(0.7 * h)\n",
    "            yolo_mask_bin = yolo_mask_bin[:cutoff, :]\n",
    "            label_mask_cropped = label_mask[:cutoff, :]\n",
    "\n",
    "            # IoU\n",
    "            intersection = np.logical_and(yolo_mask_bin, label_mask_cropped).sum()\n",
    "            union = np.logical_or(yolo_mask_bin, label_mask_cropped).sum()\n",
    "            iou = intersection / union if union != 0 else 0\n",
    "            ious.append(iou)\n",
    "            total_files += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file} in {subfolder}: {e}\")\n",
    "\n",
    "    avg_iou = (sum(ious) / len(ious)) if ious else 0.0\n",
    "    print(f\"\\nüìÅ {subfolder}:\")\n",
    "    print(f\"Processed: {total_files} files\")\n",
    "    if missing_images > 0:\n",
    "        print(f\"Missing image files: {missing_images}\")\n",
    "    print(f\"‚úÖ Average IoU: {avg_iou * 100:.2f}%\")\n",
    "\n",
    "# === Run for both folders\n",
    "compute_avg_iou('Good')\n",
    "compute_avg_iou('Bad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
